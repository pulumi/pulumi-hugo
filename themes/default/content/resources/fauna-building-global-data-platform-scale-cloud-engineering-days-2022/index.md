---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Fauna - Building a Global Data Platform at Scale | Cloud Engineering Days 2022"
title: "Fauna - Building a Global Data Platform at Scale | Cloud ..."
meta_desc: |
    At Fauna, availability is a top priority. It informs how we build everything, including our infrastructure. I'll discuss how we balance complexity ...
url_slug: fauna-building-global-data-platform-scale-cloud-engineering-days-2022
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Fauna - Building a Global Data Platform at Scale | Cloud Engineering Days 2022"
  description: |
    At Fauna, availability is a top priority. It informs how we build everything, including our infrastructure. I'll discuss how we balance complexity and safety in our infrastructure as code to build, maintain, and scale FaunaDB. They use AWS and Python but soon will use the multi-cloud ability.  ✅ Get Started with Pulumi: https://pulumip.us/Get-Started ✅ Create a Pulumi account. It's free: https://pulumip.us/Sign-Up-OpenSource  00:00 Introduction 01:04 Fauna's Topology 04:56 Our 3 Core Challenges 07:09 Defining Clusters in IaC 08:24 Cluster Definition 10:21 Pulumi Layout 11:52 Pulumi Layout - Projects 14:16 Pulumi Layout - Stacks 14:55 Pulumi Layout - Configuration 15:30 Export/Import via StackReference 17:25 Authorization 21:17 Automated Authorization 22:43 Summary: How we have been working with Pulumi 23:43 Q&A
  sortable_date: 2023-01-19T17:54:44Z
  youtube_url: https://www.youtube.com/embed/NQpDNm9pH7s
transcript: |
    Jeff makes a senior staff engineer at Fauna which makes a distributed serverless database. Uh Jeff and Fauna's mission is to make, working with operational data productive, scalable and secure for every software development team. I think Plumy can sympathize with uh with those objectives. And he's gonna talk today about building a global data platform at scale. So take it away, Jeff. Thanks. All right, thanks Eric. Yeah. So, um I wanna sort of talk through how we're leveraging Halloumi to build and scale uh our data platform um and how we use it to balance safety and operational complexity uh as we do this. So at FAA availability is one of our most important responsibilities that informs every decision we make architecturally policy wise. So we've architected our I to meet this high bar of operational safety and maintain that availability. So I'll walk through kind of how we're doing that and I'm gonna start with our topology since it, it uh informs exactly how we're going to lay out our Pulumi code. Uh Fauna has been architected for fault tolerance. Um We have uh what we call a cluster and within a cluster, we have multiple tenants all of the data for our customer's database is stored in one cluster. Um We have multiple clusters set up or, or could have multiple clusters set up. Uh But to ensure the safety of the data in that cluster, we replicate the data across multiple regions. So each replica holds a full copy of the entire data set replicated geographically. So we have a few clusters right now and some of them are have replicas just in the US. Some are one just in the EU. And then we have a global cluster, we replicate our data to the west coast and the east coast and the EU for a global cluster, the west coast, the central, the central US for the and the east coast for the US cluster. And then uh in the EU, we were kind of balanced across multiple regions. So this setup makes us very resilient to any sort of loss of regional connectivity. If we lose, we can lose an entire region and the database can maintain availability and consistency, we can reroute customers back into a region that's, that's up and running. Um And then within each replica, we we need to split the data into multiple partitions and each partition is going to hold a part of the replica's data. This allows us to provide fault tolerance all the way down to the node level. So if a single node goes down in a replica, only the data for that node is is unavailable in that replica. But the other nodes can reach out to their, their other replicas and find the data. So this allows us to do um kind of day to day maintenance like replacing our machines, um rolling out updates to the database uh and, and maintain that, that high availability that's required. So in originally, uh before we were running with Pulumi, before we sort of started this journey, we only had a single cluster that was globally available. Um And then we started to get more customer requests for data sovereignty. So customers in the EU that needed to adhere to GDP R rules. Um We have customers that didn't want to be in a multi tenant environment, they wanted to leverage fauna for their workloads, but without having to worry about any other customers uh impacting what they're doing. So that made it apparent very quickly that we couldn't, we couldn't maintain a single cluster, we're gonna have to spin up multiple clusters. And since we only had a one cluster, it was managed manually, we point and click in UIs uh we needed to make some real changes to how we were going to operate and maintain our infrastructure. So we set out with kind of three core challenges we needed to increase our operational safety, you know, point and click in new eyes is definitely not a good way to continue going for long term, especially as we build out more clusters as we expand our existing clusters and have to increase the amount of infrastructure that we're managing. We wanted to reduce our operational complexity. Again, kind of going back to the UIs, you know, there's, it's easy to get to get lost, to miss click something um to lose track of where things are to uh you know, not spin up all of the infrastructure infrastructure that's required. For instance, spinning up a cluster can require um you know, networks and security groups and um EC2 instances, low balancers and missing or mis configuring those while manually building things out uh is uh is undesirable from an availability standpoint. And then uh we wanted to make sure that we were speeding up our time to delivery. Um If we get customers coming in, requesting a private region group or a private cluster, we need to be able to spin that cluster up almost instantaneously. We also need to be able to rotate out machines very quickly. So we have clusters with multiple machines, obviously over time, those machines degrade and they have to be replaced, that process needed to get faster and safer. So the first thing we wanted to do, knowing that we had multiple clusters, we needed to move to some sort of infra infrastructure as code solution. Um We wanted to define how we were going to, well, we're gonna configure how, how we're gonna configure our clusters. So we wanted to, we wanted to build out these configurations that were simple and declarative and language agnostic. When a new cluster needs to come online, we want to be able to write out very clearly what that cluster should look like where the replicas should live, how many partitions each replica should have. Uh it needed to be declarative uh so that we could keep it in. Uh We wanted to be able to keep it in github. We want to be able to use version control with it. We wanted to be able to um review it and ensure that we were building out the right thing before, before we got started. And then that configuration needed to be language agnostic because we're using, we're using this configuration to drive several things, not just the infrastructure, but also our deploy process as we roll out the software, um we want to be able to add configuration into that, that dictates how different machines might need to behave. Um If we're trying to say a B test um a new feature or a new process inside the system, we wanted to be able to add that configuration into it. So we came up with this sort of simple Gammel scheme schema um to, to define a cluster um fairly straightforward, you know, you have your cluster cluster name and then the replicas where the replicas going are going to exist the machine type and then the number of nodes uh that we were going to use. Um I'm showing just a short version of this like a condensed version of this because this is what's important for this talk. But we can add into this many different types of configuration and do these, these configurations are much bigger in production. And so if we pair that back with the overview, the quick overview that, that I showed earlier, you can see how these sort of configuration blocks correspond with their uh the replicas that they're going to build or the infrastructure that they're defining. One of the key things that, that we came uh that we came away with as we were working out, this process was um initially, we had just declared the number of nodes that we wanted to run. So three, let's say uh only to realize that if we wanted to replace a single node, we couldn't easily do that because you can't, how's the system going to know what node D needs to be replaced? If you say I want to go down to two and, and back up or if I just need to replace, say node zero because it's, it's been degraded or I want to change the size of it. Uh So we had to expand that into kind of this ID or, or array of I DS. So with that configuration, we had to go into decide how we were going to lay out our Pulumi code. And kind of the simplest, most straightforward way would be to just say, like we have a cluster project and then one stack per cluster, it's very simple, it's very straightforward. Um But it requires each stack to have a lot of infrastructure inside of it. It's maintaining a lot of infrastructure, you know, each cluster gets its own account. Um So that we're maintaining the, the separation between clusters and then there's monitoring in there, there's the VPC S security groups, EC2 instances, load balancers, target groups, health checks on and on and on. That's a lot of infrastructure. There's maybe hundreds of individual resources in a single stack this way. So from an efficiency standpoint, this isn't ideal any time we want to make a change to say an E two instance, Pulumi has to go out and check on every single resource in that stack which is going to take, take a while. It also means any bug that we happen to introduce into the code is going to immediately go out everywhere. So if we have, if we're trying to change something in one replica, and there's a bug that affects all of our replicas, we now run the risk of taking down the entire service. So we needed to make sure that we were reducing the number of resources affected by any one change. Uh And to do that, we split out our infrastructure into sort of three core projects. And these projects are based around uh how often we have to manage the infrastructure in that project, um how often changes need to be made and how large an impact that project could have on the overall health of the service. So we went with account for one network for the other than our replicas for the last one. In our account, we spin up one account. Like as I mentioned, we've spent up one account per cluster. We configure a bunch of roles to enable access. We configure vault integration so that we can handle authentication and authorization. We have some monitoring that's, that's account wide, all set up. And then that doesn't have to be touched. And most of our account stacks haven't been touched in years. They're, they're up, they're good to go. We don't ever have to touch them again. Network is similar. Um We get the kind of based network built out. Um We have one network stack per region. So for every region that our cluster is going to be in, we have a network stack that sets up the vpc's subnets, gateways, route tables, kind of all the basic networking bits and pieces. And that's another one that really doesn't have to be touched once it's up, then we get to our replicas which handle the actual EC2 instances, security groups, target checks or target groups, health checks. And then our, our lbs um we have one stack per replica in this case. And so whenever we do uh an update on any of our infrastructure, we're only really touching one replica at a time. And as I said before, we can handle a single replica going down. It's not ideal obviously, but it's also not catastrophic. So with that in mind, we needed to just sort of define how we were going to tie all the pieces together. And the first, the first thing we did was define kind of a naming scheme for our stacks. So our cluster account stack gets like the environment and the cluster name as its stack name, networks get the environment, the cluster name, and then the region that they're going to be in and our replicas get environment cluster and then the replica name. And what this means is that we can um ref use the names, we can kind of split those names uh in our case by the period by the dot um and then reference back to our original configuration. So we can see here, you know, the the prod cluster can, can grab the cluster. Uh the the main cluster configuration, the network can refer back to can kind of search through the through the configuration and find all of the regions that it's going to be a part of. And then the replica can refer directly to its configuration um by sort of drilling down from environment to cluster to replica. And then to further tie those pieces together, we've taken advantage of Pulumi stack references. So each project will now export the necessary bits and pieces that other projects will need to import in order to continue building out the infrastructure that they need. So in this example, we have the cluster account project is going to export the account ID and all of the projects after that are going to import it for authentication purposes or authorization purposes. The network is going to export its VPC ID and subnet IDS and then the replica is going to export its its target group iron and, and maybe some other, it produces a few other exports that we use for just um being able to monitor things. And then for the imports, as I said, each, each project is going to import the account ID so it can run authorization. And then the replica project for instance, is going to have to import the VPC ID and Subnet IDS in order to build the, the E two instances on the network from the previous project. So this gives us a nice sort of view of the dependencies uh and the dependency chain. Um We intend to use that uh use the API to build checks to ensure we're not accidentally creating circular dependencies. It's pretty easy to kind of get a bunch of stacks built up and then uh over time, modify them. So they're accidentally um depending on, on each other or how building a circular dependency. But for now we're just really careful in code reviews. So I kind of touched on authorization I think that's another really important part of all of this. We have multiple projects, multiple stacks. How do we ensure we're authorizing changes to those stacks and changes to the resources owned by those stacks? Like I said, the first part of it is that we have this account ID and we use that account ID um as, as part of the authorization process. So we kind of had three thoughts of how we might do this. You know, we can store long lived credentials in each stack's secrets. Uh We can require credentials to get put into the environment before any changes are made or we can somehow automate credentials management. We thought, well, storing long long lived credentials is certainly a dangerous thing to be doing any time those leak get out somehow. Um You're now having to revoke them and then update everything that, that use them. Uh which in the past is can be almost impossible to really maintain unless you're very diligent about what you're um how you're tracking those things. So that adds a lot of complexity and reduces our safety. The next thing we could do is require credentials in the environment and use plume's sort of implicit providers. But that added a whole other dimension of complexity. And that now before you run any changes to the code or to the infrastructure, you have to make sure you're pulling the correct credentials into the environment. Um It also makes reaching across accounts very difficult. Um There are times when we, we may need to reach into a separate account to pull some resource information. But mostly this can be a very dangerous thing if I pull the wrong credentials. If I pull in like the product, the production credentials and attempt to make changes in a development stack, I'm going to push those changes into the production environment, which is certainly not desirable. So we went with automating credentials management. This allows us to use short lived credentials, pull them and expire them. Um um You know, as, as soon as we're done with them, um we can pull those credentials for whichever account we need to pull them for. So that if we have to reach across accounts, it's much simpler. Um And then it, it, it offloads all of the, the need to know which credentials to pull the safety of pulling the correct credentials at the right time. Uh And um uh sorry, um pull the credit, the correct credentials for the, for the right stack uh in the, in the right environment each time. Um The, the only challenge with this scheme is that it requires us to use explicit providers, um which we've, we've gotten into trouble once or twice with when we've forgotten to add the provider into the resource. Um And then it may pull out uh uh uh an implicit uh provider from the environment. But again, it's something we can be very cautious of in, in code review. And so the steps that we're taking internally to get these credentials is, is we, as I mentioned, we're using vault, um, so we can use vault to authenticate either the engineer or the system. When we automate these processes and let vault handle all of the access controls for these credentials, then we request temporary. I am credentials based on the account ID. We add them into the provider and then we add that provider to all of our resources. So that's, that's been great so far. It's worked really well for us these past couple of years. Um There's 11 area where we, we found kind of a sticking point with this process is that if we go to destroy uh a stack, the provider still has the old expired credentials in it and it won't update them before it tries to destroy. So we have to go and run an update first and then we can do it destroy. That hasn't happened very often. Um It was more, it was happening more as we were kind of building all of this out but day to day it, it hasn't been a problem. Um And the benefits of this have far outweighed any of the potential downsides. So, you know, in summary, that's kind of, that's how we're um that's how we've been working with Pulumi. Um That's how we've been working with Pulumi to, to make all this work. Uh we defined this declarative simple configuration that can drive our deployments and can drive our infrastructure changes. We've split into multiple projects and multiple stacks to ensure our operational safety. And we've taken advantage of Pulumi automation to manage all those stacks. You know, we can uh we can run a deploy to a single region, make sure everything's safe and then use automation to just blast it out to all the other regions. And finally, we've automated the use of short lived credentials for safety and simplicity. So thanks for listening. Um There's one question about using vault with Pulumi. Um the way that we're doing it is using uh the, well, we use Python. So we use the HV AC sort of um vault library to pull credentials and then we build an AWS provider and explicitly uh add those credentials into the provider. Um I know that you can, our Pulumi has resources for managing vault. Um But we haven't seen the, the ability to, to, well, I guess, yeah, that's anyway, that's, that's how we're doing it. Thanks Jeff. It's awesome to, to be so transparent about how fauna works. And uh it's obviously you guys have spent a lot of time thinking about the, the architecture overall. I 11 of the questions I always get is uh is, you know, you spend a lot of time in architecture, do you spend as much time on sort of some of the uh operational aspects like do you practice, do you run fire drills on availability or things like that? Uh uh The, the world of Amazon has, has kind of given us some, some of our own fire drills. In fact, like just this morning, we had the US one region suddenly blipped out for some reason. Um And so we've, we've had that, we've, we haven't had a lot of time to really run, um, exploit like purposeful fire drills. Um But that, that is definitely has, has been a plan of ours is, is to be able to do that sort of thing. Yeah, I think we're hosting the Pulumi conference in that region and it's probably all the traffic that caused the outer. So we, we apologize to. But, um, the other, the other question I get asked a lot about is, um, you talked a little bit about code reviews and, and how cautious you are with that. Um But you also spend a lot of time talking about security and authorization in particular. Do you guys take any specific uh, actions or care, you know, with security through the, the DEV stack that, uh, that's different from a normal code review? Um I wouldn't say anything different from the normal code review. I, I think that the, the use of vault for all of our authentication, um or rather well authentication and authorization, um, gives us a, a really strong sense of security that, um, you know, all of our credentials are short lived, like across the board, everything we use is short lived. It's always pull a new set of credentials that are going to either expire quickly or that we're going to expire as soon as we're done with them so that we never have anything long lived hanging around. Um, that's, that's kind of a big part of it. And then, uh, aside aside from that, um, you know, the reviews and ensuring that we're watching for the sort of the security groups, the ports that we're opening and the firewalls that we're putting up and making sure that those uh those are sane, sort of the other part of it. So there's a, I wanna, sorry, I wanted to, I wanted to speak to Tim's question about doing multi cloud deployment with Pulumi. So that was actually one of the key reasons that we went with Pulumi. I didn't talk about it here. It's mostly focused on our AWS architecture, but uh we do have the capabilities of spinning these clusters up in GCP. Um pretty soon Azure and, and being able to, to very quickly kind of go anywhere we need to go. Um And because it's code, it's just for us again, Python, um all of the stacks look the same but can kind of switch some of the small differences based on the provider that they're going out to. That's awesome. Thanks, sir.

---
