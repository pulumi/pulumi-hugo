---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Automation API Under the Hood | Cloud Engineering Days 2022"
title: "Automation API Under the Hood | Cloud Engineering Days..."
meta_desc: |
    Evan Boyle and Casey Huang give you a guided tour of the Pulumi Automation API and Pulumi Deployments.
url_slug: automation-api-under-hood-cloud-engineering-days-2022
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Automation API Under the Hood | Cloud Engineering Days 2022"
  description: |
    Evan Boyle and Casey Huang give you a guided tour of the Pulumi Automation API and Pulumi Deployments. Pulumi's Automation API allows you to embed Pulumi within your application code, making it easy to create custom experiences on top of Pulumi that are tailored to your use case, domain, and team.   ► Automation API: https://www.pulumi.com/docs/guides/automation-api/ ► Pulumi Deployment: https://www.pulumi.com/product/pulumi-deployments/  Automation API makes Pulumi just another SDK. ✅ Get Started with Pulumi: https://pulumip.us/Get-Started ✅ Create a Pulumi account. It's free: https://pulumip.us/Sign-Up-OpenSource  00:00 Introduction 00:30 Custom infrastructure tooling 01:26 Integrate with other tools 02:07 What is Automation API? 04:35 How does this enable me in my processes? 05:33 Why use Automation API? 06:24 Wouldn't it be nice if... 07:10 Pulumi Deployments 07:41 Popping the hood 09:27 Deployment API 11:24 'pulumi-deplpy-executor pulumi' 13:12 Pulumi Deployments recap 14:05 But wait, there's more 14:56 Automation API remote deployments 15:41 Automation API is a building block 16:22 Do more with less
  sortable_date: 2023-01-12T13:04:53Z
  youtube_url: https://www.youtube.com/embed/8nAbrJg6KFM
transcript: |
    My name is Casey and this is Evan and thank you so much for joining us today as we talk now about how automation API is used here internally at Blooming. All right. So if you have stumbled on to this talk and you have Miss Dan's talk about how Altana uses automation API and you are wondering why you are here and uh why you should care. That's all right. I'm gonna send a quick minute uh going over a quick recap of what automation API is. But before I do that, uh let's talk about a few scenarios, you might find yourself when you are using gloomy. For example, imagine you've got a pluming program far reach and you find yourself wishing that you had more visibility and tooling around it. So maybe in your developer workflow, you have some tests that you want to always run before you actually deploy your infrastructure or your deployment pipeline. You want to be able to not use AC I I know Dan loves it, but uh maybe you want to be able to use a U I or ping it with an API hall or maybe your pluming program is just not doing what you're expecting it to be doing. And you really wish you could step it through a debugger to actually see how this infrastructure is being spun up underneath the hood. And so for a lot of these things, there's your obvious heavyweight workarounds, you can add logs. Like Dan mentioned, you can write a bash script, which is, you know, everyone's favorite. We can write a whole service architecture on top of fluy, but these aren't particularly great developer experiences and we can do better other things that you might want to do. You might want to integrate with other tooling, right? You might want to roll your plumy program across multiple stacks or alongside other workloads that aren't modeled using plumy. And what do you do? Then do you write even more bash scripts? All this to say there's a lot of different ways you can package up your infrastructure code. And there's a lot of ways that overhead might be introduced when you're deploying that infrastructure. And since we love infrastructure as code, I, I hope since we love infrastructure as code, wouldn't it be great if we could use some of this overhead or move some of this overhead into code as well? And that is exactly what automation API does. So what is automation API watch me just read this off the slide here. Automation API is a strongly typed programmatic interface to run Pulumi programs without using the cli. I see in the comment. No dinosaur suit. I actually was looking for it this morning and I have not cleaned my closet out and I got immediately scared. So sorry about that. Uh My quick aside, um So given this, what does that all mean? Here is a super simple skeleton of what automation API usage looks like at its core. So we're here, we're setting up a new Pulumi program. We're defining our project name. We got our stack name, we got our Pulumi source code living in a github repo. Then we have this method. You'll see that's been commented where we want to either create the stack that doesn't exist or select it, right? Given the stack may be conjured up and it's called sert stack remote source, remote source, meaning that this repo actually lives remotely in a github repo, right? It's not the only thing that automation API supports automation. API also supports having your source code live locally uh on a local workspace folder or even in line in the program itself. And we'll touch on both of those bits in just a moment because it's actually pretty interesting. After we select our stack, we can also dynamically set our configuration, then we can actually manage our Pulumi up with the stack dot up line right here at the very bottom. Um And that's actually gonna run our Pulumi up code and that is how you use automation API in a nutshell. So that upstart remote stack uh or upset stack, remote source uh method that I mentioned earlier. What's actually happening there. So you can see here, we have this concept of a workspace and a workspace just captures your state, right? It's gonna capture your runtime environment. It's gonna capture your plumy config it's gonna capture the source code itself, right? And here we have this version called a new local workspace. A local workspace here just means that we're gonna run Pulumi up uh on your local machine. So for this remote source scenario, what we're actually doing is we're cloning your github repository under the temp directory uh on your local machine. And then we're running flu me up locally against that clone. So that is how automation API is able to support remote repositories but having being able to deploy it locally on whatever box you're running automation API from. And that's kind of the gist of it. Oh, did I have this? Right? So tie it all back together. How does automation API solve some of those uh scenarios that we discussed earlier? You can now manage the deployment process in code is pretty much a long and short of it. So your multistage pipeline uh with all of your tooling uh can all be managed from a single repository and you can really layer on top of that gloomy cli as well to fit your custom use case. However, you like it. I also mentioned earlier that you can declare your pluming program, not just in the github repo, but also in line in the same source as your deployment execution code, right? We're circling back to that now. And what this actually means is if you've got a snippet of your pluming program, that's giving you some difficulty, you can just copy a pasta into some automation API code, run your automation API code from your ID or from wherever and actually use the debugger to step through your plumy program and really break down what's happening. So that really gives you a lot more visibility into what is going on. So, Evan, why should we use automation? API? Well, great that you ask Casey. So uh from a analyzing our internal usage data across all plume users, looking at how many resources users are able to manage how many engineers are working in each organization. We found a striking trend uh organizations that go all in on automation API are able to manage 10 times the cloud footprint uh as compared with traditional tools. Uh So this means being able to scale your infrastructure and grow your infrastructure footprint exponentially without really having to grow your team much at all. But wouldn't it be nice if you didn't have to uh build as much software to get there? Um We've worked with industry leading customers uh in, in a and infrastructure to take the lessons that they've learned building on top of automation API and to build it into the Pulumi deploy platform, a set of tools that allows you to execute deployments and Pulumi operations including Pulumi up through the uh the Pulumi service fully managed so that you can scale up your deployments concurrency parallelism without having to worry about the hardware that it runs on. Um Yes. Yeah. Today we've announced Pulumi deployments and in addition to raw APIS primitives, building blocks rest APIS, we've also launched a turn key workflow that is built on top of those APIS. This includes click to deploy from the pluming service console and get pushed to deploy so that you can open a pr get previews, merge that pr have that deployment run automatically so that it's easy to set up a golden path into the production with just a couple of clicks and popping the hood a little bit. You know, all of this Pulumi deployments is built on top of automation API automation API sits at the core. So let's talk through what some of the layers are of the Pulumi deployment system and what we did to turn automation API into a hosted managed service that can run deployments on demand and how you might be able to do this inside of your platform. First on the right, we have the Pulumi workflow layer. The workflow layer is what provides our elastic isolated, secure single use compute. Uh This is where all of the Pulumi programs end up running. Um It's an abstraction that we manage uh measure latency, uh keep a warm pool of, of compute ready to go. Uh so that we can service uh program requests quickly instantaneously. Um Then the deployments layer in the middle, this is a service that actually runs the, that, that, that, that manages the running of plume update operations. Um So this adds r back off queuing concurrency control and logging on top of deployments and work flow. Finally, there's multiple different front ends that plug into the deployment service. There is the rest API that everything else is composed. On top of that allows you to curl or send HP requests to create and run a deployment, refresh operation, et cetera. Um Get push to deploy and click to deploy from the console. Both of those compose directly into the plumbing deployments, rest API and those experiences are built using the same logging API, uh the same API that show you deployment status, the same API that um that and run your deployments. And if we double click on what this looks like a little bit, here's a screenshot of a deployment running in the Plumy console, you can see that we have some logs here. Uh And if you look closely you have logs for deployment execution, uh getting the source downloading dependencies and finally running the plumy operation. You can see that each of these commands actually runs what is called the plume deploy executor. This is the brains of the operation a binary that builds on top of and builds in automation API So this is a program that uh imports automation A I and has the ability to uh run Pulumi operations, run operations through the Pulumi engine dynamically uh based on configuration that we'd set. Um And, and, and do things like acquire source on behalf of users, uh do our back verification, all sorts of other things like that. And so if we go back to our architecture diagram, you can see that our workflow layer on the, on the uh compute that, that runs our updates embeds the executor. So the executor is our automation A P program. So the deployment, the deployment rest api creates a, you know, a JSON payload that's passed along to our deployment service. Our deployment service is able to uh you know, once once queued uh and, and you know, our verification, everything else happens. It translates that deployments payload into a workflow that the workflow service knows how to execute a list of jobs and stuff that workflow executes. Uh And, and once that gets scheduled on workflow, the workflow calls out to the Pulumi deploy executor in order to clone install dependencies uh and run the Pulumi operation. So let's let's look a little bit at what uh what S code might look like. Here is a um help screen from the plume deploy executer. It's actually a uh AC I that we've built um that has some commands, um some flags, some environment variables. Um But again, this is just another higher level program that we've built on top of automation API to be able to embed the Pulumi engine and run deployments dynamically for you based on these rest API requests that we get and to add on. As you can see every one of these commands that you have available, these pretty much map directly to a stack, right? So all the things that you can do and flu me up, you destroy, you preview refresh. Uh That's just what fluy executor is wrapping around. So we want to take a closer look at what, for example, the update command is doing behind the scenes and how it's actually implemented. Uh It looks like this. All right. So some of the terminology here might look a little familiar from what we saw earlier with the automation API code, right? We have the same concept of a workspace which to recap, just captures your state and bundles your configuration with your source code, et cetera, et cetera. And then there should also be a line of code in here that looks nearly identical to something we've seen before. And if you can't find it, here's a hit this stack dot up is exactly what is automation API uh is doing. This is automation API at work here. So to juxtaposition this with that automation API code that sample skeleton code we saw earlier that last line stack dot up is just how automation api deploys your stack for you. So this gobin this Pulumi deploy executer is just a wrapper layer that has been built on top of automation API. So as a quick recap, what is Pulumi deployments actually doing? As Evan mentioned, we have that front end layer, right. I'm going to go in the opposite direction that you mentioned earlier. We have our front end layer which is how you're going to interface, you can click to deploy, you can get push, deploy or integrate directly with that rest API, we then have our API layer where our queuing is managed. And then how um actually assigns that work to our workflow layer. And then that computation layer, we spin up that secure isolated compute instance to deploy your infrastructure. And then we have the executor that is just running through these little uh binary steps. Uh It clones in salty dependencies. And then that final bit that Polloi operation is just automation API. So at its core poum deployments is just a lot of infrastructure built on top of automation API. And that's how the sausage gets made. And if you thought that was all, but wait, there's more. So if you remember this slide where I first went over what a local workspace was uh local workspace being a workspace that lives in a local machine. Um local workspace as a name kind of implies that there might also be something called a remote workspace, right. So what is a remote workspace there for? If a local workspace means that we're cloning the source code onto our local machine and that enables a automation api to execute our plume up locally. Then a remote workspace might mean that we're cloning that source code onto a remote box and then running the Pulumi up from there. But cloning your source code onto a box and running it remotely just sounds like what Pulumi deployments is doing, right? So that's actually exactly what's happening. Uh We also have this new future of remote deployments that's now supported by the automation API. But rather than running a pluming program on your local machine, you can use automation API to run it remotely and it does this using to Pulumi deployments. So we got this kind of sick circle of life here, right? Where you have Pulumi deployments, which uses automation API in order to execute your Pulumi up commands your Pulumi refreshes and then automation API uses Pulumi deployments if you just want to execute that remotely. So it's all part of the same fabric in the same family and the same library. I'll now hand it back to Evan uh to tie everything back together in a new little box. Thanks Casey. So, you know, automation API is just another building block. Uh And, and as you've seen, it's a building block that we at Pulumi use to build higher level software systems like Pulumi deployments. Uh You know, today we dived into Pulumi deployments, a complex distributed system that's built on on, on top of automation API. And we saw some of the ways that automation API can be embedded with common software practices and systems such as a managing compute, queuing concurrency control and many others. Just another piece of software that you can use to embed the Pulumi engine. And you can too or you can use Plumy deployments because we've already done a lot of the hard work and all of this is to say, accomplish more with less. That's why we built Pulumi deployments. Uh because we found that, you know, customers that adopt automation api are able to manage 10 times the infrastructure per engineer. Uh This means being able to keep up with exponential cloud growth without having to uh you know, explode the, the growth of your team uh or put your engineers and operators under significant stress trying to keep up with that. All right. Thank you all very much for joining us.

---
