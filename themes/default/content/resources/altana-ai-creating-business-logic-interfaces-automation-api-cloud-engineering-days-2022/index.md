---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Altana AI - Creating Business Logic Interfaces with Automation API | Cloud Engineering Days 2022"
title: "Altana AI - Creating Business Logic Interfaces with..."
meta_desc: |
    After automating infrastructure with Pulumi, how do you operationalize it? Dan Swartz, Altana's Principal Software Engineer, discusses how Pulumi's...
url_slug: altana-ai-creating-business-logic-interfaces-automation-api-cloud-engineering-days-2022
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Altana AI - Creating Business Logic Interfaces with Automation API | Cloud Engineering Days 2022"
  description: |
    After automating infrastructure with Pulumi, how do you operationalize it? Dan Swartz, Altana's Principal Software Engineer, discusses how Pulumi's Automation API can be integrated into a self-service application to codify your business logic and provide a richer operational experience for your organization. ► Discover the power of using Automation API https://www.pulumi.com/automation/  ✅ Get Started with Pulumi: https://pulumip.us/Get-Started ✅ Create a Pulumi account. It's free: https://pulumip.us/Sign-Up-OpenSource  00:00 Introduction 00:28 Intro to Business Logic Interfaces (BLIs) 02:41 Who am I? 03:10 Who is Altana? 04:19 What is a Business Logic Interface (BLI)? 06:04 Why BLI? 08:45 Making things not suck... 10:55 How's it looks? 13:11 What can you do with it? How could it look? 14:57 Demo time! 19:15 Closing Thanks
  sortable_date: 2022-12-27T15:30:01Z
  youtube_url: https://www.youtube.com/embed/9N4RU9Jli0Q
transcript: |
    Hello, welcome to creating Business Logic Interfaces with Plume's Automation. API I'd like to start by thanking Pulumi for the honor of having invited me to speak today. Also a big thank you to Altana A I for supporting this presentation and for being a pretty awesome employer as well. And thank you for tuning in. I'm excited to show everybody what I put together for today. Today. I'm gonna be talking about business logic interfaces or BLIS as I like to call them because it's this awesome software pattern out there that not enough people know about yet can make development and operations more efficient together and it's just plain fun to work with. So here's the idea we're codifying our business logic better and better these days and having an infra infrastructure as code platform like Pulumi that's accessible from native language constructs is a big part of that. But Pulumi actually took it a step further when they released the automation API because it also made infrastructure operations themselves more accessible to the common developer because there's a lot more to infrastructure as code than just the infrastructure code, you got to install the platform, which means package dependencies and run times. There's secrets management, configuring each snowflake of a client deployment and oftentimes a whole bunch of other things to do right before or right after the actual operations themselves. And so there's a lot of business logic in there that isn't really always being codified into a proper application. As a result, we get these huge pipeline config with bloated shell scripts and read me files full of code snippets. And as a result, the interfaces to build test and ship releases can get well, pretty ugly. The business logic interface. On the other hand is one of my all time favorite software patterns because it is the antithesis of this anti pattern. My goal today is to compel as many of you out there as possible to ditch those shell scripts for your build test and release logic. Start refactoring them into a proper software language and start building easy interfaces for managing your organization's software development life cycle. It's not just better practice, it's way more fun. But first before we get to the interesting stuff, let's take care of some formalities, shall we? My name is Dan Schwartz. I live just outside of Philadelphia and I got a master's degree in Computer Science just over 10 years ago from Westchester University of Pennsylvania. I grew up across the street from my wife and we have two amazing Children that give us the full range of human emotion. I love music and I actually trained as an audio engineer. I'm also principal software engineer on the SRE team at Altana AI. Well, A I is a pretty awesome company with kind of an incredible if not unique product offering. We've actually been in the newspaper a lot lately uh for one because we just closed a substantial round of funding. By the way, we're hiring more importantly though, we've been exposing forced labor in the global supply chain, uh uncovering hidden links and patterns in global arms trafficking. Actually a whole lot of other things, I'm not sure which I'm allowed to talk about yet, but they're always really exciting to find out about um Altana products, leverage machine learning models that train on a data lake with a massive amount of global shipping data. Uh So that allows our customers to map all of the suppliers and their value chains uh to expose sources of forced labor among other things, uh ensure compliance with international trade regulations, mitigate risks. And I think offer some advisements on certain specific logistics. Um and so much more, we're, we're really just getting started. Ok, cool. So now we can get started talking about the fun stuff. So what is a business logic interface? Well, a BL I is really just an application but it's one that provides an interface designed to help streamline business processes because people need a simple interface and from my experiences and based on what I've heard from other people in the industry people love using these little home brewed cli utilities, especially when they come with tab completion, helpful descriptions and other things to help them kind of figure it out for themselves on the fly. And it doesn't have to be a cli either. Right. If you're more comfortable with API S and web interfaces and you're more inclined to turn something like this into a managed self service portal. That's super cool. Personally though I'm just kind of a terminal nerd. And so I'm more inclined to make a cli for my bl I that said in the past few years, cli development frameworks like Cobra Cli and Python click, they've made it super fun if not easy to prototype out commands with sub commands, arguments, options. You know, all of the features that you've come to expect from the kinds of cli utilities that you're already probably using like Pulumi for example. And if you're using go lang already, you really just got to check out Cobra cli it. Uh watching that work for the first time, just like made my brain melt, I swear. But regardless of what framework or construct you go with any one of them is going to provide you with a common interface. So you can leverage all sorts of plugins like Pulumi automation API. Now maybe you're thinking, well, that's novel. But why, where's the real business value? Well, consider the fact that the whole point of DEV ops is to bring development and operations closer together and this is literally developing your operations. I mean, it goes right to the heart of the problem that Dev Ops was designed to solve. How does software get shipped? How could developers help in shipping better software and how can operators help advise development how to write better software? How do we get just a little bit closer to that place where Dev and play in a field and ride unicorns and stuff. Also, I just, I cannot overemphasize how much I feel like shell scripts are just the duct tape of software engineering. Now, application release, orchestration tools. Like, you know, your git labs, Azure, DEV ops and Circle C I, they've come a long way, right? And you can write a lot cleaner pipeline config with them now. But where's the love for the local workstation? I mean, at the end of the day, well, hopefully not the end of the day, but somebody's gonna still have to run this in a terminal at some point and you probably still got some bash or some powershell scripts cooked up out there somewhere and they're not usually pretty and maybe you're thinking, well, sure, but our shelf scripts aren't so bad. Well, I got news for you. Entropy sucks. Put it another way, they're not going to get less bad over time. At one point in my experiences, I, I actually saw a web application that was designed to cobble together a bunch of bash scripts to, you know, automate an application deployment. Things can get pretty ugly. And I mean, I'm not one to judge either. Like I used to manage terraform deployments with answerable playbooks wrapped in a nice little script. I mean, nobody's perfect. Right. But that's garbage interface. I mean, your typical web application developer or data scientist, they don't want to have to go digging around through the shell argument voodoo that you Googled to figure out they just want to do their jobs and they could probably use a nice clean utility to help them do it. So you need a unified interface to make doing your job and everybody else doing their jobs less painful. So let's discuss some of the guiding principles you'll want to follow to keep your fancy new bl I from turning into a great big P OS first and foremost, make sure it's simple and accessible using a YAML configuration file might seem like a pretty slick idea. But remember they can get big and ugly in a hurry and ain't nobody got time for YAML problems and interactive features like tab completion and help messages that are actually helpful will really improve your coworkers quality of life. Side note, if you don't know Z shell and oh my shell yet or auto jump and for that matter, yeah. Check them out. They can save you so much brain power next. Keep it organized and keeping with the first principle things need to be easy to find. So keep it modular package it up, make it portable. And if you got a problem with Repo sprawl, consider making it the first project component of a new mono repo, it's a good pattern. Also, this is a great opportunity to enforce some rules for your business logic. You don't need to support workflows that defy good practice. If you wanna make sure that deployments don't happen without a preview first, then maybe 10 seconds to cancel operations. If necessary, just code that right in, want to make sure that no stacks get uh created or configured without being tagged first again, just code it in and that's how it works now. And if you know that stack names longer than 20 some characters are gonna cause problems, just validate that input again. Don't forget the helpful error message indicating that 200 some character and long names are absurd and you know, test it. I mean, one of the nice things about developing and real programming languages is that they usually come with real test frameworks as well. Make sure that that guy gets that error message and use it deployed staging as well. It's a good way to know that it won't blow up in production. All right. So how might something like this actually look? Ok. Well, here we see a synopsis for what looks like a pretty simple cli utility we wrote ours in Python using Python click and we're able to build test and package up all of our projects, programs, component resource libraries and policies right into this utility. We're able to take care of all of those operations in our C I pipelines just as easily as we're able to do them on a developer's workstation or in production. Basically just add off and you're good to go. Now, at this point, synopsis is really just providing a thin wrapper around Pulumi automation API but even still the application methods behind this simple interface can be extended as much as you want and then deeply tested to ensure that they provide a nice consistent experience for developers, operators and pipelines alike to manage complex multi tier and multi cloud deployments. And its manifest simplicity is welcoming enough that it can empower even the least tech savvy user. But what else does it actually do? Uh OK. Now we see some more really helpful functionality. For example. Now we're able to configure and reconfigure our stacks read in stack configuration settings all at once or just one field at a time and we're able to do the same for stack outputs as well. But if you look closely, you'll see one command we threw in there that has nothing to do with Pulumi at all. See it. Yeah, we also use our utility to generate release notes and change logs. You see for too long, we've been interacting with our infrastructure in a completely different code universe than everything else that we do. But thanks to Pulumi Automation api, we can now treat our infrastructure operations as first class citizens in our business logic applications. So now maybe you're wondering. Wow. Ok. Well, what else could I do with this pattern? We could run answerable playbooks. If your infrastructure has any thick instances that need to be configured, we could just codify the logic to pull any outputs we might need from whichever corresponding Pulumi stacks and just pass them in his arguments to an answerable playbook. The answerable runner package works great for this by the way. And the AWS session manager connection plug in is uh it's just a thing of beauty to watch it operate. We could generate a cloud spending report, whether you're generating your own custom formatted sheets or using a third party to track and advise you can make your data accessible to authorized members of your organization to generate these reports for themselves. We could send slack notifications or escalate incidents and pager duty. Maybe we've gotten to the point where our application is just so massive that we need to create a web interface. Uh And so we just want to launch a docker container and open up its UR I using this. We could browse our code documentation or you know, start transitioning to a managed self service web portal. If we can figure out how to automate reprisals for breaking the pipeline, we could do that here and maybe we want to make it easier for developers to create tickets or comment on them, you know, without having to contact switch. Actually, I break the pipeline a lot. Maybe we'll just get rid of that one. That's better. Now, look, it doesn't really matter exactly what we put in here. It's the fact that we can put anything in here that we imagine is useful. Anything tedious in your organization's workflow that could be automated. This is a really good place for it. OK. Let's do a demo. OK. So here we have a terminal and VS code. Um I'm gonna build the utility real quick with something called task. Uh You can find that at task file dot dev. It's basically like a nice alternative to make uh you create a task file, define your tasks like task build, for example, then to verify that everything is installed correctly, I'll run task synopsis and we get a little output. All right. So now the utility is installed and we are ready to deploy infrastructure. So I'm gonna run alt and then I'm just gonna hit the tab button and just kind of to demonstrate, we have tab completion, we can see what's available to us. So now we're gonna run alt configure, let's create an AWS account tab again, to see the options that we have. Let's just call this BL I demo. We're gonna say it's a development environment and we'll say yes to accept all of the defaults. Ok? So great. Uh It's all configured, it's ready to rock and roll. So let's preview it. Actually, I hate typing out arguments like this just again and again. So I'm gonna open up my dot NRC file. And for those of you who've never seen a dot N file, this is end direnv at work. Uh It'll just run whatever script we have in this directory whenever we see the into it and Python click will pick up on the variables that we put in the environment here. OK? So now we're ready to preview and we don't have to type in all the extra arguments to the command. All right. Now see how that first line of output says that it's using an existing repo for config and it's doing a fast forward pull. All right, let's come back to that. All right, the previews complete the policies are applied and we're good. OK? So let's deploy something, right. All right. This is gonna create us an aws organizations account in our sandbox ou. And then it's gonna put a cloud trail in there with a couple of buckets and some other things to get us started. OK? So while the account is creating, let's get back to the configure as we scaled out across dozens and dozens of stacks across Aws and Azure with different feature toggles and configurations. We found that the only way that we can really maintain our sanity. Is using a OPS configuration. And so we just codified that into our utility. Uh and it failed, of course, because this is a demo and that's what happens during demos. Now, this isn't a really big deal. This is just because the AWS account was just created and the S3 service isn't always immediately available. So let's just wait a hot sec and retry and then everything will be fine. Ok? So S3 is ready by now. So we're just gonna rerun the same command and Pulumi will just pick right up where it left off with the buckets and then it'll create the cloud trail. Ok? Now it's there. We're done. We have a new aws account that we can deploy our product into and it only took us about three or four commands after we had the utility installed and our pipelines are getting a lot cleaner too. Just an all configure here and all deploy there. And Azure DEV ops lets us test any version of our utility against multiple different branches of our configure from the pipeline run form. Ok. Let's destroy this before anyone finds out. Now, just as easily as we created this with an alt deploy commands, we can run alt destroy and it'll tear down the infrastructure for us and that's about it. I hope this has been informative, if not somewhat entertaining. And I also hope I've convinced some of you out there that making a simple business logic interface to wrap around. The Pulumi automation api is a much better alternative than shebang your head against the wall anymore. Thanks for watching.

---
