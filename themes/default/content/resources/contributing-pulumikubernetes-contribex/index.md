---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Contributing to pulumi-kubernetes | ContribEx"
title: "Contributing to pulumi-kubernetes | ContribEx"
meta_desc: |
    In this stream, Levi and Vivek will walk us through the pulumi-kubernetes codebase and show us how to make, build, and test our first contribution.
url_slug: contributing-pulumikubernetes-contribex
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Contributing to pulumi-kubernetes | ContribEx"
  description: |
    In this stream, Levi and Vivek will walk us through the pulumi-kubernetes codebase and show us how to make, build, and test our first contribution.  The Kubernetes resource provider for Pulumi lets you create, deploy, and manage Kubernetes API resources and workloads in a running cluster. Learn more at https://github.com/pulumi/pulumi-kubernetes
  sortable_date: 2022-06-02T06:01:35Z
  youtube_url: https://www.youtube.com/embed/4ompE18X5ek
transcript: |
    All right. Hello and welcome to Pulumi TV. My name is David Flanagan. Although hopefully, you know, me from across the internet. As today, we're gonna be taking a look at the contributor experience, which means we're gonna show you how to get involved with the Pulumi projects. And today we're taking a look at Pulumi Ktis. Now I'm joined by two wonderful colleagues of mine, Levi and Vivek. Hey, guys, how's it going? Good. How are you? Yeah, I did it. I was, I did this like every stream I've done for two years. I said, hey, hey, how are you? And I throw it at more than one person and then you got to see who, who, who answers first. Why don't we start with you, Levi? Can you tell us a little bit about you and then we, we'll move around? Sure. Uh So I'm, I'm Levi, I've been at Pulumi, I guess, a little over 3.5 years now and I've been uh the primary maintainer of the Cumber NTI provider for most of that time. Thank you very much. Yeah. And uh I'll go real quick. Uh So my name is Vivek. Uh I work with Levi on a bunch of our native providers of which uh uh communities is one. I've been helping out um with the communities provider uh for the last roughly year. So I've been at the company for about two. Yeah, and uh happy to be here. All right. Well, thank you both for joining me. I think the best way for today's session is just to get my screen share to right away. And then we could talk about the, the layout of the provider and try and get people a little bit of insight on how they can get involved. I know that it's one of those repositories that can feel a little bit intimidating to new people. I mean, we want to kind of break those walls down today and show people how they can get started with this. So, yeah, here we have, uh, the, I guess the, the goodest places design to start. Uh We also, where's my activity bar? No big deal. I'll look at that this month. Ah, there we go. And we have the fail system here. So, where, where do you want to start then? Um, do you want to go over the directory structure of this project? Is there a convenient place to start that most people find maybe a little bit confusing upfront? Um I was actually wondering maybe, um, Levi if you wanted to, sorry. Um Just talk for very briefly. Go over the history of the, uh, committee for, because that I think will also have some implications in terms of how, uh, it's structured and how it may look different from other providers that, that, that we support. So, if you wanna just walk through that, since you're a little closer to that history, that'd be great. Yeah, that makes sense. So, our Cober natives provider is one of the, the oldest providers that, that Pulumi has done. Uh, it was our first what we're calling native providers. Uh This, this was around prior to Pulumi schema and the registry and the, the multi language everything. So this was originally all written in typescript. So, uh this one looks a little bit different from other providers just because that, that predated everything else. And it's, it's been uh brought up to like use the schema and the code gen and be, be more similar to our other providers. But it's definitely the, the most complicated one and you'll, you'll see a number of things that are, uh, kind of, uh from that legacy there just because it, it did predate a lot of these other tools. So, um for the most part, the directory structure should look similar to what you would see in the, in the, the other native providers like you see here SDK folder in your provider folder and then the, the make file. So that, that all is, is fairly similar there. But uh uh some of some of the things we're doing with it are a little more sophisticated than our other providers. The goal is eventually to bring this more in line with, with the way we're doing everywhere and, but this is a great way to kind of go through how it is now and figure out how to, how to get it to an easier place to contribute. Yeah, there's, there's definitely some commonality that I see here that maybe we could just touch on really briefly. But, you know, most of the pluming providers, uh I think it's fair to say they have like a little bit of go code that kind of does all the, the gluey stuff and then that lives inside of the provider folder and then there's an SDK folder which then has the SDKS for all of the different languages that are supported by Ploy. I think that's almost ubiquitous. Is that, is that a fair assumption? That is right. And, and for all of our native providers, the, the SDK folder, everything that lives in there is code generated. The provider is the, the actual implementation for uh like all the client stuff and how it's actually talking to the cloud and talking back to the Pulumi engine. And then there's, there's also a bunch of code that, that handles mapping all the resources into the Pulumi schema so that we can run our code generation on that. Yeah. All right. So, yeah, exactly. Um You go No, sorry. Uh, I guess like one of the, one of the common misconceptions that people have it, like, you know, they try to, like, they find something wrong with the docs or, or rather like with, with one of our, uh, SDKS and they try to fix it by making a change directly into the SDK directory somewhere. And, uh, unfortunately that's often like one of the first things that we can't quite take on directly because uh the, all of those things are automatically generated. In fact, most of the files that you'll see will have a preamble thing that this was automatically generated. OK. So I just, I wanna make sure I understood that correctly. I say the SDK is generated. Yeah. Right. If you make a change there, next time the, the build is run, it will override any changes that you've made to that file. So if you, if you want to make it fixed, you have to actually make it in the, the part that's generating the code. Yeah, I could see why that would be a little bit challenging to someone that's not aware of that coming to the repository. You know, what appears to be a really trivial fix and they can find it in the sdks and go I fixed it, but really, it's not done in a way that's going to be uh actually fixing the problem for future users. All right. So when people come to this project, then they should spend, if they want to make a change or improvement, they spend all their time and say that the provider folder. Is that correct? Ok. So is this where the code happens? I guess we got the commands here and we've got the, the package. So there's quite a lot going on there. Maybe we could give kind of a quick overview of what's going on and say the provider. Sure. So, so looking in the package folder, you'll you'll see the provider directory, that one is going to be common to all of our native providers. And that has the provider dot go file there. And if you open that up, that has the implementation for all of the GR PC methods that we use to talk to the engine. So you'll have this file on every single one of the providers. So this is setting up like all of the credentials reading in like the configuration for the provider, uh setting up the connection to the Kubernetes cluster. And then you've got uh like the the cred methods, create read updates, deletes and then a number of other methods as well. Does the predictability? I don't know if that's the right word of the Cober api make it a lot easier to code the SDK because everything is kind of to find upfront regardless of resource. Is that a, a fair assumption, it is fairly straightforward in KTIS because it, it does use that, that standard cred model. Some, some of the providers are a little more challenging to, to map to that. But all of our native providers use that same model. So in, in some cases, the trick is figuring out how you map the, the upstream API to this model. Got it. Ok. Cool. So they get this provider, I mean, I'm assuming from my superficial 4.5 seconds of looking at this file that most people come into this project that probably don't need to end up in here or is that incorrect? That's right. If, if you were writing your own native provider, you would be working in a file like this. But for most contributors to the, the Cober nineties provider specifically, this wouldn't be something you'd have to worry about. All right. Excellent. So they got the provider, they got the provider to, I guess a lot of this other stuff is how it speaks to the, the CP I look the con I'm assuming from this. And right. Yeah. So most of what this in in this folder is, is for talking to the API. And then we've also got implementation for some of our overlays which include helm and YAML support and customize. I, I think all of those are features that are somewhat unique to the, the KTIS provider where uh it, it's support for common tools that, that people already use for managing Cober Netti and it's, it's built on top of the on top of the core provider? Ok, cool. So could we try and understand how the code on this provider works? Uh So that people have an idea that, you know, when they're coming along, I'm assuming that regenerating the sdks would be a very common thing to have to do as part of their debug and test look like. What does that look like? Yeah. So if you go up to the, the package directory, there's, there's a folder called Jen and that is where all of our code generation code lives. So something that's, that's kind of unique to the, the provider. We, we've got those overlays that I just mentioned and those are specific to each STK. So we've got those template folders, you see, you see one for each one of the languages. Uh There's the go templates dot net, templates, no Jas and Python templates. So if you needed to make a fix to the overlay specifically, uh that's a little bit different workflow there. Well, could we take a step back for a moment? And what, what do we mean by overlay and the context of this provider? I think such a good point. Maybe if I can just like kind of walk through the actual, like the overall flow. So there's actually um in the provider, there's like the C MD directory. Um you'll see that actually has the um has two binaries. So if you go to provider C MD, you'll see actually, there should be um the CRD to Pulumi as well. We will ignore that for now. So we have Pulumi Genti and Pulumi resource ktis. Uh Pulumi Genti is the binary that you that that's focused on the schema generation. So uh in the grand scheme of things, when it comes to Pulumi sort of provider ecosystem, uh there is a this, there we create this like schema which is basically adjacent schema specification of what um you know, the the resources are, what the uh you know, the the relevant properties are any parameters necessary for like um language SDK generation and things like that, like a lot of that stuff is encoded into this like Jason, like schema, Jason. In fact, you'll see that in the Pulumi resource Ktis uh directory, you'll see a schema Json file there, which is the current latest schema for this particular uh provider. So that's um the thing that like the code generation um essentially um there, there's a few different steps in this pipeline. So first thing is to generate a schema Jason and then using that schema Jason, you can essentially create the corresponding uh language sdks, right? Um So a lot of what's going on in initially is like Pulumi Kineti runs and it generates essentially a schema Jason which is then consumed again uh by Jen to create uh the sdks that you see in the SDK directory. Um And, and, and uh the, the Pulumi community is obviously really only has like a simple uh main go. Um It does most of its stuff in the Pulumi like the, the um the PC GP KG GEN uh uh package, which is what uh Levi was pointing to earlier. If you wanted to trace that sort of code base, you'd probably want to start from, may not go and uh and like, you know, go through that entire sort of flow. Um But essentially uh uh we are generate like the, the end goal is to generate a scheme on Jason. Um What's going on is actually um you know, put in Pulumi Ktis, we are taking the uh API open API specification from Kineti and we are uh generating the uh corresponding um you know, resources and types and things like that into the scheme at Jason. Um In addition to what's in the default open API specification, we also have these overlays which are like additional resources that we have custom developed essentially if you want to think of it. Um So there is the helm chart, there's the, the Yale config file that is the customized. I'm forgetting something, I'm sure. But basically uh there's these uh these, these uh additional resources that we um uh have created um on an they, they're basically component resources. Um And they're uh they were actually implemented on an individual language level. Um This is a little bit of history for those people who are deeply familiar with how Pulumi works currently, like, you know, uh component resources, we support on a bunch of different languages and you can use them and consume them from within the same language. It's only recently that we've added the support for multi line components. So this is a lot of this, this support predates multi la components. Uh but essentially um um helm chart and a few other of these kind of uh resources are, are kind of implemented, hand implemented in each one of the languages. So if you look at the PKG gen uh templates folders, you'll see the corresponding um sort of um implementations for these component resources in each of these um uh uh you know, uh each of these languages. OK. I'm gonna try and repeat that back to you and tell me what I got wrong. That looks pretty. I apologize. But that, that's great. Right. That's, that's what we want these sessions to be. We, we want to be able to kind of really understand these things uh in a way that just we haven't done before. And, but people will find that useful and hopefully it can encourage more people to contribute and help to the project. So instead of the provider folder, we've got a couple of commands, we're ignoring cr data. Pulumi for now, but we have Pulumi, Ja Cotti and Pulumi Resource Cotti. Now, I've seen this naming structure across a lot of our providers. It's very common to have a plum ja and a Pulumi resource provider. So that makes sense. But the job of the Pulumi Cotti is here is purely to generate the schema dot Json. And what you said was we do that by pulling open API specification from each COTIS release uh and generating what kind of like Jason schema but had a quite a small Pulumi flavor to it in some way for as far as structure goes. Uh And it's these do. So I think we use across all of our providers to then generate all of the SDK so that I think I got a good handle on. So from here, we are generating all the SDK from that and that's fine. But we have this concept of an overlay. Now, when you first said overlay, I thought maybe we were augmenting the resources that we'd already generated, but it sounds like we're actually just adding on new convenience resources instead for the provider. So at our core and our core support, we uh support custom resources, help customize the Gammel config and I'll ignore path dot Ts because I don't know what that is. So these are ways that we are enriching the kite support beyond the open API specification. So in my head, that feels like a really good way for people to get involved in the project is to more to bring maybe more of these overlays to increase uh fair support uh with Vancouver days is that is that correct or anything I get there wrong, anything you want to fix. So, the, the thing that's tricky about overlays is they have to be implemented for each language. So it was initially just typescript and then we had typescript and Python and now that we're, we're up to, I guess, 66 different languages. It, it's difficult to actually get language parody here. So we're, we're thinking about ways that we can make that. So there's not as much manually written code like that. So uh generally, like, I, I would say that that is a useful way to contribute. But it, the, the tricky part is that uh it's six different languages you have to work across now. Yeah, I can imagine that quite tricky and one of the challenges um Yeah, so, so, you know, um we're, we're actively thinking about how we want to support this on an ongoing basis. Um Certainly, like the existing component of resources we have, we continue to support uh and manage. Um um We hit an interesting sort of decision point recently when we added the helm release resource, for example, um we actually um implemented it as a custom resource within the provider. So basically uh leveraging the SDK Cogen and all of these things make it work across all the different languages. Um But like the provider internally implements the actual helm release uh uh uh sort of aspect, we, we got away with that a little bit because, you know, helm like helm is a go um um sort of uh project and we could embed that into the provider essentially. Like we could get a go a fair way if you wanted to do things that are like somewhat language specific, then you, you know, and which are not go essentially because that provider is written and go, then you get into an interesting decision point. Um Certainly now that we have multi line components and other things, it's increasingly interesting to kind of see these things implemented as multi line components. And whether or not that needs to live within the communities, uh provider repository is like uh another question like that can, these components can live independently and in in often cases, that might be a better model um than explicitly shipping it as part of the community uh provider. I would say though for an external contributor who is interested in something like that, that's definitely an interesting conversation to have. But that that would be something to engage like the gloomy engineers with before going a long way down the road and trying to put together a pull request. I guess the best way for people to do that would just be to open an issue on the repository and start a conversation or I mean, even just the co Cotti channel and our slack. Right, precisely, it would be a great place. We also have a contribution, con contributors or something channel as well on the uh on the Slack channel. Like either either it's fine uh you know, uh issue or what, like start with the enhancement request or whatever on uh on, on um the community's uh get repository. We're happy to engage there or uh do it on Slack if you want like more interactive conversations with this. OK. Uh Here's a tough question for you both. So you maintain Pulumi Kubernetes and you know, besides Cotis releases and changes to the schema, et cetera, like where is, where is most of the maintenance or time spent with this provider? Like what, what do you feel that you're working on 90% of your time if that's it? I don't know if it's just bugs, there's the new features that like, I mean, if it's most of it's generated, like how can people get involved and what parts of that can we can point them to? Yeah, I, I would say there's probably three main categories there. So the, the first one is the overlays that we talked about. Those, those were a lot of work to, to get to a stable point. Uh At, at this point, I, I think they're overall working pretty well, but helm the, the helm chart in particular was a lot of work to try to get to a good, good state. The second category is uh we, we call it a weight logic internally the provider. You can also think of that as readiness logic. So when you have created a kubernetes resource, we we have some custom logic here to, to determine when it's ready. And the reason why that is useful in a a Pulumi update model is say if you've created a ingress or a service and possibly your cloud provider is provisioning a load balancer, you want to make sure that that's ready and you have an IP address or a A URL that you can hit with other resources that might depend on it. So typically, when you were applying Cober netti resources, if you were using coop control, for example, you would send all that over to the cluster, but you wouldn't necessarily know when it was ready. So if you've got other components uh downstream of that, that depend on that, you need some way of checking to see if it's ready. So uh that, that was, that's another big section that, that's a fairly interesting topic if, if you want to, to go into that uh more in a moment. And then uh I guess the third category briefly is just all of the examples that we've got. Um so certain cloud providers have uh kind of a central place where you can pull examples from. Uh That's true to some extent in Cober is through the, the upstream API docs. Uh So we, we would like to make it easier to, to contribute examples back. Uh But, but right now basically, those are hand generated as well and get injected into the schema. So if you've got more questions on any of those areas, I'm happy to go into more detail just to add, just to add to what Levi said. Um You know, uh another like obviously, as far as what we spend our time on is concerned, like certainly the categories that like Leva mentioned make, make a lot of sense. We obviously have new features and new, new uh new concepts that we want to add. We've done that, for example, with release and other things. Um certainly, uh you know, there's a lot of complexities around. Um you know, again, we're, we're, we're kind of uh automatically converting um given an API specification, um you know, to a, to the underlying schema and things like that. Um They're certainly often, you know, you would run into not often, but sometimes you run into um sort of um uh some sort of a mismatch in terms of like how we handling certain things. So for example, recently we'd run into issues with like config maps are immutable or not, like how do we handle them? Like, you know, those kind of behavioral kind of uh II I it sort of uh things that we, that is more sort of business logic and something that we understand as users and we need to like layer that in to the provider. Those are some of the things that we uh often step in on and like, hey, like this did not translate exactly verbatim from like the, the API specification maybe because it's lacking or like there, there additional um interpretation that needs to happen there. We, we kind of interject that and help out sort of that, that transition um in general. Um you know, that's uh often where we spend a certain amount of our time on in terms of just, just, just smoothing out the experience for our users. And logic is a great example of like that. Um um you know, uh kind of users um 90% of the time or 99% of the time it works exactly the way we want to desire. But like every now and then they run into some sort of a um an exception to the rule and we need to understand that better and like layer that on. All right. Awesome. Thank you. Uh So I think I had two things in my head there. One you mentioned that the examples left inside the schema dot Json. Is that correct? Or did I misunderstand that? Yes. Uh that gets injected as part of the, the code generation into the scheme without Jason. Um Let's see. So specifically, um when we talk about examples, it gets a little bit ambiguous, like there's obviously the examples of like a full blown program like, you know, like PLU program that does like deals with cinti uh resources and things like that, like those um at least in this repository we have in a, in a test directory, we run like uh end to end test integration tests against those um uh here and therefore the various languages and so on. Uh We also have the Pulumi Examples repository, which is obviously our central location where we track like, you know, different use cases for different uh resources. Um And that's often where we would point users to, that's like our de facto location where we would uh people ask people who are um you know, considering adopting Pulumi to go look for inspiration. Um The examples that we are talking about here are more like in our API doc. So if you were to pull up our uh and, and things like that, so if you were to pull up our SDK, either on in um uh like in uh V code or like any other ID E or if you were to go take a look at our API docs on our website and so on so forth, often you'll see some examples there about like, hey, how do I create a deployment? How do I create a config map? How do I create blah, blah, blah using the Pulumi SDK in, in the various languages? That's the part that gets injected into um the scheme I JSON as well. And then we can render that appropriately um in the various language sdks. So if, if you want to actually look at the, the code for that, that's in the package gen examples folder and there's two different kinds here. So we've got the overlays which are documentation for like Helm and Yamal and customized. And then we've got the upstream one and these are just the vanilla resources here. So these are, are markdown files that, that get rendered into the, the API docs for each language two. All right. So this, this would actually be a great place for uh external contributions because I I think this is straightforward to, to understand the, the scope and uh it it's just a a markdown file. So you, you could add examples to like for for any resource like this. So people can comes to this repository, go to upstream and save the examples directory, just add a markdown file with more co resources. And the next time that gets merged into our code base, it will end up on our register page as the API docs examples for Cotti Awesome. That's a really cool way for people to get involved actually without having to dive into all the provider, the cogen and stuff like that because you know, there are a lot of resources and, and giving our our users more access to examples, I think is a very valuable thing. Yeah, definitely encouraging that um we have a question from Marcus in the chat. Um And he's just asking like we are we generating our SDK against Vanilla upstream Cotti. And he's curious about support for like EPS which has additional AWS resources. So we have any advice there for Marcus? Yeah, this, this is the, the Vanilla Kubernetes schema. So each, each release of Kubernetes includes uh an open API spec that's a, that's another JSON file. So we've got code that parses that and translates that into the Pulumi schema. And we, we have a, a separate EAS component EK provider that manages some of those Aws resources specifically. But the Cobern provider is just Theil Cobern plus those overlays that we talked about. Yeah, I think the communities provider like just in for those people who are uh new to Pulumi and so on. So the provider is specifically meant for manipulating and managing resources in uh a cluster or um essentially. So you're creating things like deployments and um and he like, for example, he charts installing them, managing them and so on so forth. Um It's uh like setting up a Pulumi sorry, setting up a cities cluster is typically, you know, done in, in a different provider. So you have like the EKS provider that will do the EKS uh um provisioning. We have Google, uh Google native and Google um GCP provider for managing, for example, GKE Aws and, and, and, and, and so on so forth. So there's a little bit of uh distinction in terms of basically, if you think about a provider, it's like what is the backing um sort of cloud environment that it's managing. Um in the case of the KTIS provider, it is talking to um uh the API spec and we basically track the latest um release of the API spec at all times with, with the, with the provider. Yeah, that's another interesting point about the, the Cober nutty provider is, is this can be used with any cluster. It, it could be a like a cloud managed cluster like you just talked about or you could be running kind or Docker desktop or like what whatever other flavor of Cober nutty you happen to be running. So you can configure the provider to point at that and develop it locally as well. Awesome. All right. So I think we've, we've kind of covered the, the code base and a few areas where people can get involved. Now, I'm curious if we're feeling brave and I was going to say we'll go off script, but we've always been off script. So like as soon as someone comes across, right? And they found an issue on the github tracker and they're like, OK, I want to kind of take a go at this and they make some changes to their code and could we maybe walk through the process of like, how do they build a provider? Like what are they make targets that they should be familiar with? Is there just go be, is it that easy? Like what do people need to know from that perspective. So we're actually in the process of standardizing this across all of the native providers right now. So I, I think a month from now this, this will be more consistent across balu, but it, it is all driven through the, the make file. Uh So I, I believe the read me should have instructions for any prerequisites that you need to, to have installed. And then there's just a couple of make targets that you'd have to run. So we do have a contributing um file as well. Um That's probably a better starting point for, especially if you're going to look at um trying to contribute to uh the, it's very short, there's not a lot to it. Uh but basically, uh uh you know, there's some dependencies that you need. So making sure would typically uh this is a pattern that we use across plu this is uh something that you'll see in a lot of uh pluming uh uh repositories, you typically run something like making sure to make sure that you have the appropriate versions of things. Uh This is mostly really just doing um go go download like goma download type equivalent, essentially in this repository auditors that are a little bit more complex and have external dependencies. Um And then um in this repository, really just a make build and a make install uh gets you ready to kind of play around with your local version of the provider. Um So it's relatively or because barely does that make those include fetching the latest Cotti skimmer? Yeah, it does. Yeah. All right. So, so actually if you look at the Make file. Yeah. Yeah, sure, sorry. Uh Yeah, so we can actually walk through what, how we generate the SP or like what version you're tracking. So in, in the make file, you'll see basically uh a reference to uh cube version. So capital all caps Q underscore version. Um So currently it's set to track A V 1 24 0 which is like the latest and greatest um sort of major version, at least for the API specification. Um And uh essentially any time you do a make build here, it's gonna go basically go fetch that particular open API spec version of the open open API spec and go through the whole code like cogeneration process, make the provider or make the SDK all of those things um locally for you. OK? I see we even have an open API failed target which I assume is just going to pull down open API definition. OK? Cool. And another thing just because I was on the top of the contributing and I get this question all the time and people are asking like, if I'm going to build a provider, do I need all of the supported languages and run teams on my machine? I think is it fair to say the ideal answer? Would be, yes, if you want to build all the sdks, but also you really only need to run time for the SDK that you want to work with locally. Is that a fair assumption? Yeah, I think if, if, if you're just, if you're running the, the build and install target that, that assumes that you have all of them, uh, they, there are specific targets if you're wanting to, to just develop in a particular language as well. OK. And if someone were to submit a pill request, but they'd only build the typescript. Uh SDK, is that a, is that a problem? Um Is that something the C I generates and commits back or is that something that you as a maintainer would then have to then fresh, push to their request? Like if they want to submit a request, do they need them all? Is that what we encourage it? It would depend on exactly what they were touching it. C I would run all of the SDKS. So if, if it ended up being a change that needed them all uh that, that would be caught, but there, there would be certain types of changes where you wouldn't necessarily need them all. Thank you. Yeah, often one of the challenges like um it'd be maybe be worthwhile for us to, for example, make a city change to like one of the um um one of the examples, for example, or whatever um you know, and and, and because I in PD, I believe that should Trump down to all the sdks and so on and so forth as well when you make a, make the actual generation. But essentially, you know, one of the problems that often happens is like you do it and then you only check in partial some, some of the generated code, like we do check in all the code into the SDK folder as again, like consistent behavior across all our providers. There's a lot of people who both within the team and outside that like have problems with that model of operation, but there's good reasons to do it partly because of the way go works and so on, like uh especially for a go SDK. Um uh we're not gonna debate that decision here, but basically, uh you know, uh so we do check, for example, like uh like C I will break will, will, will warn if you uh if it notices, like uh basically the don't get porcelain kind of functionality where we notice that, like there's local changes that haven't been committed to the repository and things like that. So there's a few gotchas there um when it comes to um you know, dealing with generated code essentially. Um but um certainly things that we are happy to walk contributors through if they run into it and definitely things that we can improve in terms of documentation. So obviously, like any other place, like if you see, if you run into issues, like the simplest pull request would be an improvement to like the contributing guide, which uh can definitely use a lot more attention. And we would love to get more um relevant feedback from people that are not us, you know, to, uh to make that uh process a lot more documented and well, um we certainly have people within the team also focusing on that effort a little bit more as uh I believe I mentioned. Um But yeah, um hopefully that uh gives you a general sense of like how um basic contributions can work. Yeah, I think so. Uh OK, I'm going to pick a couple of these targets that I think are useful. Um Schema calls K gen, so we, we'll call that and I was just going to take our open API specification and generate our Pulumi schema, right? The schema J. OK. So we'll let that do this thing and then we have the ability to build the provider. So this is going to give us the goal by anyway, that we could put in our path. I guess this is the dash dash. Were you gonna say something early back? No. All right. OK. So, yeah, like, so I, I my head of like, OK, if I'm working on this and I want to be able to test this with like a really simple program that I have. I really just need to run. Make Kate provider, which maybe we can do. Uh And then if I just put that into my goal path, uh I should be able to run and pull me up and actually use the version of the provider that I have built, which is, and then from there we have, and I think that's the standard across a lot of our professors. So this is really valuable information to people that, that maybe haven't delved into that yet. But we always seem to have this dot net underscore SDK or SDK underscore dot net value that we can build. So I'm not going to build dot net because I do a model. I don't think it works on an M one Mac yet. Uh We can build the No GP. Uh think that would probably be the only targets I need right from there. I can use Pulumi typescript SDK, my new provider and I'm working with whoever built I have local on my machine. Yeah, there's uh one of the things that you might want to do is the install uh targets like there's Intal install targets for uh the SDKS. So for example, there should be an installed target for uh ojs for example, which will basically do a yarn link uh type thing for you. So then if you had an example that you were working with and you had for example SDK changes that you wanted to, to, to, to use, um you know, you could like yarn link locally against that uh like locally generated uh SDK and then uh use that. Uh similarly, there's, there's similar mechanisms for the different languages. They're slightly different um in, in their behavior. But essentially that's what we use. Yeah. And as I mentioned earlier, if people, like what are the ways people can contribute would be maybe with our weight logic and you know, using the link here would allow them to kind of consume that pretty quickly and test it. Yeah, that's the nice thing about the uh the nice thing about like some of the weight logic and stuff like that. A lot of that is baked into the provider. So like, uh you know, if you have the provider, uh sort of uh like sort of like built and like in your path, then you're all good, right? Uh And, and that just goes from there sometimes, like there is a little like, like this two phase problem where like you have the provider change and you might have like SDK changes as well and like, you know, you may get into, oh, like why isn't this? Um Most likely you'll run it at compile time, like you run into like, hey, like you, this new property that I was hoping for is not showing up in my example. Oh, that's because you're probably not running against the current version of the SDK or whatever, like, you know, so there's a little bit of a mental model to understand that you might have is the shape matching. What you're, uh, are you actually using the, the right SDK to match the shape that you wanted, basically? Ok. Awesome. Yeah. Good to call that out. Like there is that two phase kind of, you can be working with the provider itself and you only have to build the provider second in your path. But if you're making any overlay changes or schema changes, then that would require the SDK to be updated as well. So, yeah, good, good to call that out. All right. That's the hardest question for last then. So, uh do you ever run the test locally or do you explicitly rely on C I? And if you do run it locally, what is it, is it make test or is there something else that could be running locally? Yes, I have not actually run the test with the, the make target in a long time that, that C I, that kicks that all off because it, it's interacting with the cloud for the most part. Uh I do often run the, the examples locally like we, we've got examples for each language. So I'll, I'll run that as part of a testing, a specific stack, but it, it's not uh through the make target necessarily. So actually this is an area that we can use. Um um some contributions are on or discussions on um like one of things like we do set up for, as LEVI said, set up like a cloud managed environment. So this by default is like a GKE environment in C I. Um And that we run all our tests against. Um uh You can certainly point it to any other, any old cluster, but there are some tests, for example, that rely on, you know, res or load balancer behavior which again, like, you know, gets all wonky when you're trying to do like kind or whatever. So, um you know, there's certainly a class of like the vast majority of the tests will work fine locally. Um And frankly, like you, as long as you just have like ac config locally that works correctly, like your, um if you were to just run the make test, most of them would just work, there are certain, which will fail and that's most likely because they require some, uh you know, like a load balancer kind of support or what have you. Um uh We would like, one of the things that we were just recently talking about is like maybe putting them behind a build target or whatever so that it's a little bit more easier for users to know, like what is safe to run locally and what is not essentially. Um And, and like what to expect basically. Um So, uh some of our tests are actually smart about it, like they will determine if you're running against like the cloud or not. And like kind of automatically skip them and things like that, but that's not uniform across the board. But certainly an area we're more than happy to, to, to chat about, um, to make, make it more easy for people to, I do run some tests locally but they're, uh, it definitely improved. Like that should be improved quite a bit going forward. Ok. Uh, now someone coming along who is wanting to make their first contribution, then, like, normally we'd say, get always write a test. But with a lot of this being code, is it safe to say that maybe tests wouldn't be needed for most first time contributors to the project, often, what I've done is like, except like, you know, uh uh actually, we have a pretty good uh provider test framework. Actually, if you take a look at it, it's not like the degree of effort to prove that your thing works locally on like, say, um say this is in, you'll see it in the test directory and then uh SDK, you know, Js or whatever, if you were to pick any of these examples, they basically should look like any old um uh Pulumi program for the most bit. So this is like just the, the, you know, this is what you would do run locally often, right to, to validate that this thing works. And then there's often a um corresponding entry in um in, in a, in a go test file which is which will basically run this test. Um So if you wanted to pull up um uh what's the sorry, my screen share is not working here. No, no test in in that same no jazz folder. It should be at the bottom. Oh Yeah. Yeah. OK. Yeah, there you go. So here for example, if you were to look at our um um So yeah, this is for example, a test where it's basically saying this is a little bit more complicated. We could probably look at some a much simpler test if you go a little bit further down. Um probably just start with that. This is obviously more complex um towards the bottom. I would imagine you would see some relatively simple tests. Um um replace set is that simple? Sure. Let's let's go with that, right? So basically you're saying, hey, like run a uh run the test in like the directory thing says, hey, run the test against replace statement set step one. So that's like the first like you, you could for example, test out things like you wanna do um you know an initial deployment and then an update to it and then so so on so forth, the way we've typically done that is like have multiple directories underneath. So you'll have like replace even step one, which will actually have like your baseline, um you know, code for your uh actual uh uh plume program. And then there would be a step two, for example, that would um be a very specific change, right? And then you can assert the behavior is matching that um kind of change, right? Um Similarly, you can add extra run time validation. All of this is like optional, you don't have to do it. But like basically you can prove that, you know, uh these things are working correctly. So like going from a example that works locally uh to a full or like addition to the integration test test test suite is actually relatively straightforward, but often something that we can like walk people through um during APR uh or we could follow up with uh uh after the, after the fact. So we don't necessarily block on that. Um It's often a lot easier to just have this conversation. All right. Awesome. Well, we are coming up on, on 50 minutes. I'm not gonna throw any more difficult questions. Yes. Did we just end? Not sure if we lost David here. I think we might have lost David. Great. So we're now the, the official host of this. Um Yeah, I guess uh uh um long story short, I think really uh think there's uh a bunch of room for uh additional improvements to our, our um uh sort of contributor experience. But I think, um you know, we always welcome um the opportunity to talk to the community and like get um a valuable sort of uh shepherd changes through. We, we would love to see more contributions from the community. We'd love to also obviously make sure that we meet you halfway in terms of uh providing you the uh the, the tools and resources you need to uh to, to make this easier. So certainly keep us to that um to that bar and uh just something we, we care pretty deeply about on the team. Um And hopefully, you know, the experience gets easier and easier as we go. Yeah, I agree with all that. We just like took over as host for like five minutes. Yeah, I went to turn off my screen share and then I think my router or my wifi just, I had to switch to tether. So I'm really sorry about that. I don't know what happened, but I was just gonna say, you know, I think we've covered an awful lot and in 50 minutes here and I hope that people find this useful and we'll definitely do more sessions in the future. Uh You know, maybe we'll even work on a wee bug fix or a future at some point live and have a bit of fun there. But I just wanted to thank you for, for joining us today. It was really great to just get some of that knowledge out of your head and share that with people. And I hope that people feel less intimidated by some of these co gender posies and feel that they can come and talk to us and make contributions and get involved in the project. Awesome. No, I really appreciate this. This was great. I think we got a lot of things that we had in the back of our mind and we've discussed on the course of pr s and things like that. Um You know, uh but getting that context out in a reusable format in this way is really helpful and hopefully that just means that we will continue to make this easier and easier for users to, to start contributing to. All right. Well, I'll let you both get back to your day. Thank you again. I will speak to you both soon and everyone watching. Have a great day. Thanks all. Thank you.

---
