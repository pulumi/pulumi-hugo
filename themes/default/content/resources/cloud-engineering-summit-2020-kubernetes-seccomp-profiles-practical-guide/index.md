---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Cloud Engineering Summit 2020: Kubernetes Seccomp Profiles: A Practical Guide"
title: "Cloud Engineering Summit 2020: Kubernetes Seccomp..."
meta_desc: |
    Have you wondered what a seccomp security profile is, and how it relates to Linux Capabilities?
url_slug: cloud-engineering-summit-2020-kubernetes-seccomp-profiles-practical-guide
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Cloud Engineering Summit 2020: Kubernetes Seccomp Profiles: A Practical Guide"
  description: |
    Have you wondered what a seccomp security profile is, and how it relates to Linux Capabilities?  Folks often dismiss seccomp profiles and Capabilities as a way of hardening applications as it is too difficult to determine what syscalls are in use by a given application.  In this session we will explore the state of seccomp in Kubernetes and a couple of tools designed to make this more approachable.  Come learn about these super powers!
  sortable_date: 2020-11-11T00:29:04Z
  youtube_url: https://www.youtube.com/embed/in_P293aXV0
transcript: |
    Good afternoon and welcome to the Cloud Engineering Summit. My name is Duffy Cooley and I'm here to talk to you today about secom security profiles. I've been working in this space for about 20 years across a variety of different companies from networking to virtualization. And most recently, I've been working on Nida since about 2016. So for the last four years, um as of this recording, I am unemployed and looking and, and, and exploring what the next thing is going to be for me. You can find me most everywhere at Maui Lion. Uh And recently I've been spending a lot of time on tgak dot IO and the Polis dot IO, both are great websites for keeping track of what's happening inside the cloud native space. And if that's something that's interesting to you, I I highly recommend that you check them out. Let's get started with what is a container? I'm I'm sure you've heard lots and lots of uh descriptions or definitions of what a container is. Uh This is my personal favorite way of understanding what a container is at the end of the day. A container is just a process running on a server somewhere. And the way that we can understand the mapping of that process or the way that we can understand, the way that uh process is isolated from other processes running on that same kernel is through the use of Linux primitives called name spaces. But understand first of all that, that process is running just like any other process on the server. So there's nothing different about this process other than the mapping of of name spaces that the process is constrained to. This is a group of pro of name spaces that are associated with this particular process ID 2452754, right? This process could be an engine X running, it could be an engine X container or it could be an SSH process from somebody logging into the server. It could be any number of these things. And this, this mapping of uh primitives is going to be is going to be available against any process in the kernel, whether they are shared processes associated with the underlying node or whether they are containerized processes because you're running darker on that node. Now, when, as we look at this, one of the things I wanted to make clear is that if I were to like compare this output with the output of another running container, I would see that the mapping, right? These the actual values associated with the C group name space and the I PC name space. And the mount name space and the network name space would disagree, they would be different values. Um And that's actually how we handle that isolation. We're basically tightly coupling that process with its own view of the network through the network name space. And that's why when you ssh into a system and you type IP add or you see all these interfaces, but when you exec into a container, you only see one and it's the same node, we're using these primitives to isolate the view that that process has of the resources that are available to it, right? We can modify the view of the file system. We can modify the view of the Interros communication system. The PD name space right inside of a container PD. One is the is the very first process that runs outside of the container PD. One is probably um the user name space and UTS. There's lots of, there's lots of these primitives um that are here to like help us isolate these processes from one another as they all share the same Linux kernel. The next thing I want to talk to you about is capabilities and capabilities is kind of a a pretty interesting uh not super new capability that is our new, new primitive that is available within the Linux kernel. That allows us to be a little bit more granular, certainly not as granular, but a little bit more granular in the permissions that we can associate with the process. Now, let's break this down a little bit. So starting with kernel 2.2 the Linux kernel divides the privileges traditionally associated with super user into distinct units known as capabilities. So it's like if you think about capabilities, they have the ability to grant a chunk of permission to a user or to a process. Right before that, we had basically a kind of a binary system. You were either going to be root and you'd had access to all the things or you were not route and you would only have access to those things that were kind of a traditional pro uh permission check where like if you were associated with the group and that group had right, access to a given file and you would have the opportunity to write that right to that file, same thing with read and also to modify or delete, right? Um But what's different about this is now we can be even more specific, like maybe what we wanna do is grant the ability to manipulate network interfaces to a process. Um But give them the ability to modify anything in the file system, right? And so we could give them a capability that would allow them to modify anything in the file system, but not let them access net admin. So we, you know, it's big chunks of permissions. Now, this is already a thing that exists within the within and, and this is an example of how you might configure that inside of CODIS. If this is something that you're interested in, you can definitely go to docs dot K dot IO and take a look at the security context topic and you'll find a way to actually explore and configure this stuff. In this example, we're actually granting net admin and time to this particular process. And so the container that we've identified GCR dot IO Google samples, node, hello, 1.0 has the ability to uh administrate the network. So they could do things like inside of the container dump IP tables or turn off of a network, turn off a network interface and those sorts of things. So how does all of this work capabilities can, can grant access to stuff, right? They have the ability to grant a very large chunk of permissions to a given process or to a or a particular user. Sitcom profiles are significantly more granular. They have the ability to filter or block access to uh uh to given calls and they also have the ability to list or um or to add or deny those permissions. Uh And the other thing I wanna call out here is that set is incredibly powerful but it should be used and it will allow and a denial list model otherwise you'll miss stuff. An example of this is that currently as of the 5.8 kernel, there are 345 C calls that can be specifically allowed or denied by a set profile in the X 86 64 architecture. Um And this isn't uh like all of the things. This is just the one that's for X 68 X 86 64. And that number is up from, I think it was like 250 in like the three dot in the in a four dot X kernel, right? So we're always adding more C calls or we're all, you know, further defining more calls. Um And so you have to be really careful about the way that you define a second profile in that you don't, it's not just a deny list because if you're denying only those things that you want to restrict, then as we add Moris calls by default, they would be granted. And so we have to be allow and deny. We got to do both. If you want to see all of the calls that are available in the system, there's a great resource here and I'll show that to you in a little while. The next thing I'm gonna do is I'm gonna describe a tool that I'll be leveraging today to understand a little bit about the way that a given process is configured. Uh And this was written by Jesse Frisell who's done a ton of work, definitely one of my heroes in the space. Um She's done a lot of work on, on, on increasing the security of processes and Docker containers and all of that stuff here is an output of what, uh, kind of a bog stock configured docker uh configuration would work with. Right. And so if we were just to do Docker run of a, of a process, and we take a look at the, um, the, the output of M I contained, we'll be able to derive a couple of different things. We'll be able to see what capabilities have been granted and we'll also be able to see the C calls that have been blocked. So by default, inside of um inside of a docker, when you configure it or when you just, you know, install it and turn it on. When you do a docker run of a process by default, you get all of these system calls blocked and a lot of these make a ton of sense. I mean, if you, if we, if we read through them. So for example, like there's one in here that is uh turning swap on or swap off, right? This actually gives us the ability to manipulate the swap file system as presented to the colonel, right? Which is probably more permission than we want to grant to a containerized process. There's other permissions like the ability to manipulate NFS or the ability to um emit or delete or create a module. There's other permissions like uh pivot root the ability to basically tru into a different file system if you can find access to it. Um And we do a lot of other filtering there as well, right? Like filtering the prop tree, filtering the the um CFS tree, lots of other stuff is actually filtered by Docker by default. Yeah, inside of Cober needs, we have sort of a different output and this is sort of an interesting thing, right? So this is what happens when you do Docker run. This is what happens when you do cube kettle run, right? When you start up a container, and we can see that some of these things are the same, we can see that capabilities have been defined and that capability set is consistent. The app armor profile is set to unconfined, which means that there is no app armor running. And if we look at second profile, it says that it's a disabled. Now, there are some blocks calls that are just inherent in the way that um the container run time inside of it operates. So we still turn off things like swap on, swap off uh load. So uh some other kind of high profile calls that could probably be more permissive. But at the same time, we could see that there's a very large difference between these two values, right? So like for example, uh set time is still available within the container, but it's not set within, but it's not blocked, sorry, it's not blocked in the container, but it is blocked. In the Docker container. Why are these different? So folks like Jess and others did a bunch of research into a reasonable default comm profile and you can see the work, the result of that work at docs dot docker dot com engine security. And they go into exactly why they blocked what and how and and why they consider those things to be risks. So a lot of ton, a ton of great work there and Docker still uses this by default, but Cober needs disables that default CODIS does this mostly because of the implementation detail of multiple containers in a pod, right? When you think about um Docker, when we do a Docker run, we're gonna get one container and that process is pretty well isolated within that container. But within Cober, we have the ability to, to create multiple containers within the same pod. And that means that there's been, we had to think about the way that all of that gets manipulated a little differently. So what do we do? Like what if I actually wanted to make use of that default um uh that default security or sitcom profile that uh Docker presents to us, right? Like what if I actually wanted to make use of that and just inherently increase the security of my processes? Well, before 1 19, you could do that with these sets of annotations. So you can annotate a deployment um or any of the other primitives within that allow you to deploy pods with these sets of annotations. And this is an example of something that you could make use of today, right? So annotations, set security alpha CODIS dot IO. And at the pod level, you can describe runtime default and that will configure your underlying container run time to leverage that default set of permissions. And you can also specify this at a container level by giving the container name instead of the word pod after 1 19 though and 1 19 is out now. So after 1 19, you'll have the ability to do this with the first class thing, right? So you'll be able to actually define this within the spec rather than having to define this at an annotation level, you can define this right there within the spec at the pod level. So within the um so within the pod level, you can describe security context and there's a bunch of other stuff in security context that you can use to also further secure your your applications, you can set the sitcom profile and the type to run time default. And that will also basically follow that very same configuration path and you can do that same thing with containers, right? So spec containers, security context set comm profile type, run time default. Let's go back again for just a moment to what a capo can do when you just do a cube kettle run. And we could take a look at the output here. Um, and remember there's like 22 block calls that compass disabled capabilities are all kind of what we expected. And when we turn on runtime default, we get up 68 block calls. So it's a lot cleaner and it's a lot more in line with what we were expecting from Ducker when we just did Docker run. So this is a, you know, very clear output, right. This is what you can do if you don't turn that on. This is what you can do if you do turn that on. And that really just basically increases the security model for that given process. So why do this stuff at all? Like why is this even interesting? Um And and first, I'll say that there are like three like pretty significant um types of attack against containers that are interesting in the space today, right? The first is supply chain attacks. And I think this is a pretty important one like where did the container image come from? Where did the front of the dependencies within that container image come from? And is there some way for us to validate that, that that came from a a trusted place? Another one is exploitable application bugs, right? So if you, if I ran engine X here and I gave the ability to like uh modify the content of the file system leveraging engine X and that would be kind of a bug, right? And the other one that's interesting is like did some console leave bash behind, right? Did somebody who uh created the configuration, leave me a bunch of uh libraries that I could use once I actually land inside of that container or exploit myself into a shell. Is there some is there are there tools that I can expose or make use of right there inside that container to further exploit the rest of the system? And the last is CS calls against the shared Linux kernel. Now, as I pointed out before containerization is really just process isolation and it really does a pretty decent job of isolating the process from other processes against the Linux kernel. But it doesn't necessarily isolate that that process from the Linux kernel itself, right? These system calls uh that, that the process can make those can be uh pretty permissive on a given process level. And what these tools allow us to do is limit that output, right? Give us, give us the ability to limit or constrain those calls that a process can make, which is a good thing. So to be able to actually pull this off, we kind of need to know what S calls are gonna be used by a process, right? And so there are a couple of different ways to do this. Um One of the ways that has been around for a while is to leverage S trace. So for example, if I were going to use curl uh And I wanted to understand what system calls curl minus ss google dot com would make. This is one way that I can actually go ahead and go about that, right. So I can do s trace for and, and pull all the C calls for a given process. And here are the individuals calls that were made that were, that were called for this given process. And from there, I can actually manipulate, I can create a set comm profile. And we'll look at some examples of set comm profiles here in just a minute um in the demonstration and, and then I can test to make sure that my process is able to run and handle that thing. But there are other tools out there and there's a bunch of, there's a bunch of them. One of the big ones here that I wanna mention is Dockers Slim, which is an incredible tool for allowing you in your build process, right? In your continuous integration or in your build process to evaluate a con a container to understand what calls and generate an app Armer profile for you, generate a Secom profile for you do all of those things for you kind of um programmatically within that thing. Uh They call it Docker Slim because the other thing it will do is it is it will evaluate the underlying file system for that given container image under test, right? So you do Docker run or you do Docker slim of your container, you run your tests, your integration tests against it that evaluate that pro you know, activates all of the code and everything within that container process and then do slim is able to take what it learned about that process and remove everything that is not necessary. So if I had, for example, started with ubuntu and I had a bash in there and a bunch of other things in there that could actually be used by an attacker. If I ran Docker slim against that image, it would be to pull all of the stuff that I didn't use as part of my testing out of that image and give me one flat min image that contains only those things necessary for my process to run or operate as it did under test. So very cool stuff and definitely worth checking out and keeping your eye on. Now, demo time, what I've got is I've got a Cober news cluster stood up leveraging my kind environment and kind is Cober nu and Docker. It's a way of actually bringing up a multi node cluster locally with my kind uh with my uh docker containers on my, on my Linux system. I'm gonna be leveraging a Docker image called an NM echo or it's called echo server and it's put out by Mario Loria. Incredible dude. Um And it gives us the ability to kind of just basically echo. Some of the things that we know about within the container system and we'll be exploring those things as well. The last thing I want to tell point out is that I have uh a new operator called SECO operator. It's not mine, but it's being worked on within the community and it's hosted at SIGS dot K. It's dot IO set operator. And this operator gives us the ability to persist those set profiles that we create down to disk so that they can be leveraged when creating containers. This is actually one of the problems that we, we have when trying to make use of set comp profiles within cooper. So let's get started here. Oop. So first um couple of things. So the c the C call profiles that I was talking or the SC calls I was talking about before. This is a list of all of the system calls that are available within uh the Linux system across all the different architectures, right? And so here's the X 86 1 and minus one means that this si call doesn't exist in X 86 but it looks like it does exist in arm. And this is another one of those things that makes this whole thing rather complex, right? Is that there are C calls that go by a name or maybe go by a different number depending on the different architecture that you're operating. So if you're leveraging X 86 64 this is the column for you but if you're leveraging arm 64 it's a very different column and they might map differently, right? Like the accept this call in X 86 64 is 43 and they accept this call in arm 64 it's 202. So when you're generating that sitcom profile, it's pretty darn important that you understand what the hardware architecture you're aim, you're targeting is and that you, and, and that you evaluate that. So like I said, there are a bunch many, a great, many of different of C calls that are available. Last thing I wanna point out is that um there's been quite a bit of work recently in like, you know, making C calls first class, like I said before, the difference between 1 19 and 1 18. Um And part of that work has been to improve the documentation around it. So if you go to the tutorials, clusters, restricted containers, C calls with set, you'll find a very good tutorial for describing exactly how to go about that. And if that's something that you're interested in or if you want to play with it, this is a great way to jump into it. Uh And they're gonna take you basically through what I I'm about to do in the demonstration. All right. So let's do our get nodes. So we have a four node cluster, we're running 1 19 1, we could all get pause dash A. We see that we're running uh the set operator already, all of these things are present. Let's go into pause and I wanna, I wanna show the difference between a couple of different pods. So let's do DF one do 18 fine pod and 1.19 fine pod. So these are the differences that I was talking about before, like in the 1 18 file in the 1 18 time frame. If you wanted to secure a configuration with a specific uh set profile, you would have to, you would have to describe like where to describe where to find that set profile. And you would do that with an annotation for that particular pod leveraging this particular uh annotation title and then pointing it pointing out where it would be found. In this case. When we say local host, we're talking about a particular directory on the underlying node and that, and that directory is V Lib Cule and then whatever you have on it back here, actually bar Libs Cub Seco and then operator, right? So let's go just take a look at that real quick and make sure that that stuff is present lit sitcom. And here we can see there's a operator folder and then there's also some configuration here right now. This one is not gonna be inside of that operator folder. If I do LS, we're definitely not gonna see the uh the fine grain Jason yet. And that's because I haven't created it yet, but that we're gonna do that in our demonstration. Let's exit this note again. So again, that difference uh just to highlight it, right? Is that in 1 18, we had to do it with an annotation. In 1 19, we now have first class support and we can define it this way instead. Um And you can see the way it's mapping, right? So in the old one, in the annotation, we would say it's a local host type profile. And then we would give a path to where it could be found in the new one, we would just say type local host and then we could give a path to where it would be found. All right, great. Let's move forward. So, because this is a 1 19 cluster, I'm gonna jump into my 1 19 defined pods and I'm gonna go first, I'm gonna go back, I'm jumping into my profiles and take a look at all of these profiles. So I've got a couple of different profiles that I'm gonna describe here. The first one is gonna be this uh audit dot json profile. This is a really interesting profile because what it does is it actually uh allows us to log the C calls that are made by a process. It doesn't deny them, it just logs them. And this gives us a way of actually determining what the um what C calls a process are is making within that run time. The other one, we have is fine grain dot And this is a interesting and this is a kind of an example of a of a security comp profile that gives us the ability to understand uh like the configuration here. So we've got our architectures X 86 64 X 86 and 32 we have a list of set. Uh We have a list of C calls by name and then we have an SE MP action allow right now up here, we have default action SC MP Act. Er and that means that our default action is a deny. OK? Anything not in the allow list will be denied. So if the process within my container tries to make a uh ac I call, that is not in this list, then thats call will be denied by that sitcom profile. Let's take a look at violation Jason. And again, we can see in this case, we just put a blanket deny, everything will be denied. All right. So we've got our three different profiles here. Let's go ahead and deploy them and the way that I'm doing that, let's take a look at the demo profiles here as I've create, I've taken all three of those examples. I've populated them into the SECO operator name space as a config map. And I've given them the name demo profile and I've given them an annotation set security cooper news IO profile. True. And this means that this will uh allow for the set operator to grab these configurations and populate them on disk. So if we go back into our doer exec again, live a sitcom operator, then we can see the demo profile and then we can see our three profiles that we created, right? So what all the sitcom operators doing right now is just taking that config map that I created lever pulling out the actual Secom profiles that I've defined and populating them on disk. And that's an important step because if they're not on disk and I reference them within the container, then the container will not start because there is no profile available on the underlying node. Now remember that that doesn't keep me from making use of runtime default. I can make use of that right away immediately without making any changes, playing with this set operator stuff, any of that stuff. What this is allowing me to do is put a more fine grain and more specific set profile to work for a given process. So let's go back over to our pods here. We're gonna look at the bash runtime pod and in this configuration, right, I've set, use runtime default. I'm actually gonna go ahead and run this bash process or I'm gonna go, go ahead and run this con um Am I contained pause process and let's go ahead and start this up. So let's do qid apply dash F bash one time, just make sure this works right? So cut kettle get pods. So it does work. And if we do cute kid, I describe pod and we can see that the configuration up here at the top, uh it actually backward populated the annotation, but inside of the configuration of that pod, it's now running under that um under that in that state with the with the configuration of se set profiles happening. So if I jump in here, keep Kiddle exact, I bash and I do am I contained, then we can see those 65 prof uh 65 blocks calls, we see filtering and so we can see that this process totally worked, which is great. And if I were to do cube kettle run it bash image equals that same image, then we can see the difference, right? So with runtime default, very much more secured without runtime default, not nearly as secured. OK? Cut, it'll get pods actually cut, get. So we can see our, our two pods, right? One running bash, one running uh run pod. All right. So next thing we're gonna do is we're gonna go ahead and deploy a more specific example. So let's take a look at fine pod. Now, fine pod is gonna make use of the Maori Lion echo server and we're gonna turn on all of the, you know, the, the, the fine grained configuration and we're gonna see if we can get this thing running the way that we had it before right. So we do kettle apply dash F fine pod. If you cannot get pads, no tile logs fine. We can see that it's not operating correctly, it's not kicking up. And that is because, oh, apparently I have set the path to something incorrectly. So we can see that in this warning error. It's telling me that the configuration, the sitcom profile that I've described seco operator demo profile fine grain con dot JSON isn't where it was expected to be. So we can actually modify that. So yeah, see the path is actually set operator setup, operator demo profile. And so, all right. So let's do cube, delete Natasha, fine cut little apply dash of fine pod. You could all get pods now it's working. So it's just a passing problem. But anyway, so that's all working. And that's actually the demonstration that I had for you. This gives you the ability to actually configure uh a se a custom set profile uh and the ability to make sure that that's working. So it's a great set of tools. Uh And like that is how that works. Let's do one more. Um Let's do one more example of the violation pod here, you can apply dash F violation pod. You could all get pods and we will see that this will fail and we'll see that the output is different, right? It's not failing because the pod wasn't able to be created. It's failing because of an error. So Q could all violation pod, no logs, cute little describe pod violation pod. And we don't, we're not seeing any output, but we know uh inherently at this point, we know it's because all of the system calls have been blocked and it means that we are not able to actually start any process because any system call that would be uh made against that Linux kernel would just be denied. Right? And so the the debugging isn't super great yet. Um But it does tell us that it was terminated in error. And uh and we can understand like that, it's likely because of the configuration of that sitcom profile. So that's one of the challenges that we have with this particular model is that the debugging isn't super awesome, but it is what it is. All right, let's go back to our slides and let me give a shout out to the amazing community behind the kind project, the magnificent Mr Daniel Mangum, who actually has been doing a lot of uh uh work on, on uh spreading the word on this stuff and actually doing a lot of the work behind the scenes for the operator. The amazing log has put up a bunch of different um incredible talks on sitcom profiles and all of those things. And Sasha Gunner also just putting in the work to actually get all getting all of these things to the place where they can be supported within, within um here's my references slide. I'll leave this up for just a moment so that you can see where it is. Again, if you wanted to, if you want to see this content, the slides uh that are are available at TJ IK dot IO slash uh set and you can find it there. All right. So everything is uh all of my references are here. Make sure you take your screenshot now so that you can go check those things out. They're all incredible and thank you so much for your time. Uh Find me online at Maui Land and have a great, great rest of the event. Cheers.

---
