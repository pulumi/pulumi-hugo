---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Dutchie - Enabling Kafka Adoption with Pulumi and Confluent Cloud | Cloud Engineering Days 2022"
title: "Dutchie - Enabling Kafka Adoption with Pulumi and..."
meta_desc: |
    Event streaming technology can be transformative but often difficult to adopt. In this talk, Collin James, Engineering Leader and Software Architec...
url_slug: dutchie-enabling-kafka-adoption-pulumi-confluent-cloud-cloud-engineering-days-2022
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Dutchie - Enabling Kafka Adoption with Pulumi and Confluent Cloud | Cloud Engineering Days 2022"
  description: |
    Event streaming technology can be transformative but often difficult to adopt. In this talk, Collin James, Engineering Leader and Software Architect at Dutchie, describes how a small team has enabled Kafka adoption by creating a monorepo of Pulumi projects that manage resources on Confluent Cloud.  ► The Confluent Cloud provider for Pulumi: https://www.pulumi.com/registry/packages/confluentcloud/  ✅ Get Started with Pulumi: https://pulumip.us/Get-Started ✅ Create a Pulumi account. It's free: https://pulumip.us/Sign-Up-OpenSource  00:00 Introduction 01:05 About Dutchie and Team 02:09 Streaming is important: It helps avoid a distributed monolith 02:58 Liberate data from legacy systems 04:06 Streaming is difficult to adopt 06:03 Streaming platform goals 06:51 Why we chose Kafka and Confluent 09:26 Managing user access 11:59 Using Pulumi to manage user access 13:07 Naming conventions 13:52 Dutichie's cluster naming convention 14:34 Dutichie's topic naming convention 15:28 The Confluent Cloud Monorepo 17:10 Organizing projects and stacks 18:25 Thin abstractions to reduce boilerplate 20:24 What resources are users provisioning? 21:07 Users deploy organization and cluster resources 22:48 Retrospective: Results after 6 months 23:26 Bumps in the road 24:05 Looking ahead 25:52 Questions and Answers with Eric 29:11 Closing and thank you
  sortable_date: 2022-12-14T21:28:51Z
  youtube_url: https://www.youtube.com/embed/X1qetq7PjjY
transcript: |
    There's another leader uh in the Devops community. Um Colin uh is a software architect with Dutchy. Um I personally had the privilege of seeing some of the Duchy team present um their architecture. So I know you're in for a treat. Um Duchy provides safe and easy access to cannabis and serves both consumers and dispensaries. Uh and Light Pulumi uh was launched in the Pacific Northwest, in this case, Ben. So, uh I, I uh I know that weather is not Pacific Northwest uh weather uh because uh it's a little bit gloomier here. Uh But he's gonna talk about enabling cough adoption um with Pulumi and specifically the confluent cloud. So take it away, Colin. Thank you. Yeah. Uh Thank you everybody. My name's Colin. I'm working at Dutchy, everything he just said. Uh This is sunny ST Petersburg. This is where I call home. Um Pretty much all of Dutchy is remote at this point. Um I think there are a handful of people in Bend, but everybody I interact with day to day is all remote. So let's jump right into it. Um Yeah, a little bit about me. I'm on this core technical services. Team at Dutchy. It's uh responsible for providing a technical platform to support three separate monoliths and enable the development of new services. Oh, and I just wanna say that please hit me with questions as we're going. Um I've timed this and it might be a little tight, so get them in there. Um And I'll try to answer them as we go along. Um So anyway, we're, we're basically a platform team. We're supporting these three monoliths. Uh about a year and a half ago, Dutchy was just, it was an e-commerce platform and then they acquired two point of sales. So we've got uh a variety of monoliths. And so we're trying to create a common platform to put all of those on and develop new services in between um our users or other engineers at Duchy individually. I'm responsible for the adoption of streaming technology as part of this platform. And I have kind of done this work once before using terraform at another organization. Um probably starting around 2019 is, is when that kicked off. Um So streaming is important and one of the reasons that streaming is important is it helps us avoid building a distributed monolith. This is really just a bunch of services that are really tightly coupled. And one of the ways those services become coupled is through synchronous communication dependencies and then streaming technology is then providing our alternative, it provides fast resilient, asynchronous communication. Um And this diagram just kind of shows that really, really closely these, these two services are coupled. If service B experiences a bunch of load, then service C experiences a bunch, bunch of load. And, and the inverse, if serious service C um has a bunch of latency, then service B is gonna have a bunch of latency. And so they aren't really that independent at all. Um The other reason that streaming tech is important is it helps us liberate data from our legacy systems. So, like I said, we have three mo monoliths, those are our largest and most valuable things. And they're also tend to be difficult to understand and modify. I'm not gonna throw shade at anybody at our organization. It's all fantastic. But in my experience when a uh a project has grown to the scope that you've got, you know, dozens and dozens of engineers working on it, it becomes a difficult thing to work with. Um So streaming technology includes the concept of these connectors which are really like low level database integrations between the streaming tech in a database. And then what that allows us to do is uh basically stream all the changes that are occurring within this kind of legacy service and get them out on to Kafka and that supports data migrations and other asynchronous communication patterns with this old system. And, you know, without a lot of work, we're just kind of standing up an appliance next to this big important thing that we've had forever and, and letting it go. So, streaming is important, but streaming is also kind of difficult to adopt. Um First reason is you really never know who's going to be the first to adopt. Um It's also unfamiliar technology. So engineers aren't going to be uh aware of the opportunities and risks that exist there. And then generally, I found especially around streaming, a lot of cost and complexity concerns just fud this is gonna be expensive. This is going to be difficult and it really doesn't need to be. So my advice here is um to, to focus on creating opportunities and reducing friction. There's there's a trap here. If you associate the development of your streaming platform, if it's like attached to a product deliverable, then there's a good chance that product deliverable is going to get de prioritized or maybe changes its implementation or there are a bunch of things that could change and that doesn't really need to change the implementation of your streaming platform. So it's very much like field of dreams. If you build it, they will come focus on creating those opportunities. Um do outreach as the technology becomes available. Uh Similar to that last point. If you engage people too early, then it kind of becomes this chicken and the egg thing, we can't use it until it's ready. And I don't know what I'm going to build until you tell me how you're gonna use it So um as things become available, that's the point to start engaging with your users. And then finally take on that early integration work with legacy systems yourself. Um Again, the monolith, you end up with kind of this stratification of responsibility. People are responsible for front end, people are responsible for databases. You're probably going to come and be responsible for producing change events out of those databases. And, and that's really the easiest way to get that work moving forward. So um our goals here, I, I wanted to create a way for teams to own their own resources as fully as possible. Um Self service, reasonable guard rails, but really make it as simple and easy to lose use as possible. Um I wanted there to be basically no friction for adopters, they should be able to come in and get something going right away. Um For me, low operational overhead, I'm practically speaking, the only person that is supporting this. So I'm one person I can't do that much. So I'm looking for solutions that are require very little of me so that I can, you know, do a lot of other things. And finally, we, we want to get that data out of the existing monolith. That's what we were talking about before. Um So get into the streaming provider a little bit here. Um We went with Confluent cloud and Kafka. So Kafka is a really proven and feature for streaming technology. It might be a bit much to say it's the most mature um I but it is uh it has a really strong open source community and, and like I said, it's really proven uh confluent is the largest contributor to open source Kafka. Practically. What that means is, they've got a lot of engineers on staff that are making PR S to open source Kafka and contributing features. It also means that confluent um has uh some advanced features because they essentially get to um develop it first before they release it to open source Kafka. So we have a little bit of uh access to some things like tiered storage and, and other little advanced things um that makes it the premier fully managed Kafka solution. One of the other benefits here is I don't have any dependencies on any other teams or, or any other individuals within core technical services. So if I were to uh pursue a solution that um relied on Kubernetes or maybe ran on AWS, I'd essentially be waiting for other people to finish their work before I could begin mine. And this allowed me to move forward without really uh depending on anybody else at all. And finally, it's really, really low effort. Um I can't stress that enough confluent cloud is really the easiest way to get started with Kafka and streaming. So a little bit about their um about the structure of confluent cloud, they're, you know, they're selling an open source product, right? And so uh some resources exist within this cluster and then other things are like attached to the organization. Um And then we have like environments as a logical grouping in between the stuff that's in the cluster is really Apache Kafka like anything that's happening here is something that you could probably migrate to another Kafka provider without a whole ton of effort. Um All of the other stuff is really like the parts of confluent cloud that aren't going to migrate anywhere else. So just kind of calling that distinction here that we have some like organizational level kind of cloud level resources and then stuff that is part of the kind of managed Kafka that they're selling. So the first thing I'd like to dig into is how we manage user access. Um confluent clouds role based access control is a little bit lacking if you're used to something like AWS or other places. Um roles are predefined. So we have this organization, admin environment, admin cloud cluster, admin, each of those has access to everything, either within the organization, within the environment or within a cluster. Um There is this operator role which is good in a lot of situations because it will allow people to uh people or services or whatever to allow uh to see configuration broadly. They can read all of the the configuration details, no secrets, but they can go see the topics out there. They can see how much data, the topic's moving, they can see kind of the basic configuration of that and so forth. And then uh finally this developer read, write and manage. This is ways to kind of enable some granular access on a per topic basis. Um So the way we've decided to apply, this is essentially with a three environment set up. We have probably very familiar to some, we've got a development environment um that is a place for engineers to test out ideas quickly. There's this Q A environment which I always refer to as practice for production and then there's production. So again, you know, there's no um no other mechanisms here, we have to assign those kind of predefined roles to individual users. So each of our engineers actually gets uh three a few more, but at least these three roles. Um so this is a very kind of simple access model. Every engineer can see every configuration everywhere. You know, you can go look at your cluster and pro and dev and see everything about how it's set up. Um The engineer gets cloud cluster admin on the development cluster. And so this is kind of their sandbox, they can go in the U I create topics, do whatever they wanna do right there in the U I without, you know, codifying any of that work. And then finally they get developer read on the Q A environment. And this uh basically allows them to consume messages back out of topics and validate their outcomes in a pre product environment. And that's really the only difference between, between Q A and production is that you can go read the data in Q A and you can't read the data in production. But this is still pretty complicated. You can imagine in the U I, if we're um you know, assigning three roles to every engineer manually and then we decide, OK, we need 1/4 role that is attached to every engineer. Well, that's a lot of work or um you know, there's a lot of opportunity to get that wrong. It's just a very kind of human error prone process. So Pulumi can be used here. Uh The code you see over on the side here is pretty much literally copied out of the main con or the main Python file I have on this, this project, I used to manage user access and it just goes and loops through all the emails and you know, manages the role bindings to, to give roles to those users. Um And like I said, this is just one way to really reduce the effort required to provision to provision or adjust the level of access for individual users. So this is just a quick example of what that looks like. Um you know, with actual code, this is a role binding. This is somebody getting the cloud cluster admin role assigned. Um this kind of user colon user ID thing is used a lot throughout Kafka, you'll see that. Uh So the next thing is naming conventions, this is another way in which kind of open source Kafka is a little bit different. Um It doesn't have any built in mechanisms for tracking ownership or describing resources. It's literally all in the naming convention um just recently. So this is just last month, the beginning of last month, confluent cloud introduced this stream governance feature that enables tagging, which is kind of closer to what you'd expect with resource tagging in AWS or other cloud environments. But you know, that just came out last month um for the last five years. The rest of this is true. Naming conventions are really the only way to keep track of your Kafka resources. So I wanna go over a couple of naming conventions we've established here at Duchy and this is going to tie into understanding the way the mono Repo is laid out a little bit later. Um So first cluster naming convention, um it's really simple. Each cluster has a purpose in a region right now. We just have one general purpose cluster in each environment. So they're all named Common us East one. But this naming convention creates space for us to have clusters that have really specialized purposes and uh also to support multi region deployments, which is something that we're definitely going after. Eventually. It's just uh you know, not a, not a this month thing So the next one is the topic naming convention. Uh So real quick, the first segment in that indicates that the topic should be consumed outside of its domain. Uh This domain is just kind of an abstract concept of an ownership boundary. Uh Just a little advice here, it really shouldn't uh align to a specific team or project. You should try to avoid any names that change. It needs to be a really durable name that's gonna live with the data and kind of with the structure of the business for a long time. Um Subdomain just provides some additional structure in there and then finally, data name, the last segment reflects the actual subject matter of the topic. So this is just a a quick example, this would be a topic that anybody could consume to understand. Um you know, product views that were collected from the e-commerce portal. So that brings us into the Mono Rio itself. So the high level uh Mono Repo is just like it's just cramming a bunch of projects into one repository to reduce the overhead. So for us, that's a single github repository with a bunch of Pulumi projects in it. Um Again, I'm just trying to minimize the amount of work that I have to do to, to support all of these people. Um So project ownership is managed by this code owner's file. Anybody familiar with that is good to know that's just something that drives the approval process. Um like the pull request approval process. So that's what's going to allow uh an individual team to come in and make some edits to their Pulumi project, commit it, approve it and get it sent out the door. Um All projects are deployed through this common workflow again, just trying to minimize the amount of effort I have to do to build and maintain all of this. Um There's this little hacky thing I do with the Python path so that everybody has access to this core module. And then uh that also allows us to just share one virtual environment. I considered a couple other options there sim links or doing like um giving each project its own poetry dependencies and treating the core as a local dependency. Um That's probably like the most proper way, but I found that it was uh there, there was a lot of friction moving between one project and another. And so ultimately, I I tried it out and took it back out because it was more work on a day to day basis. Um And yeah, this just simplifies everything. So a little bit about the organization here, each project in this mono Rio aligns to a single domain. Going back to that topic, naming convention in this kind of loose concept of an ownership boundary. Well, the names have to align to the name of the project. Um And then that is uh a really easy way for me to then understand who I need to talk to because I can see what the name is. And then I understand I there's a code owner's file, I can trace that back to at least a github group and understand some people to go talk to. Um And it also tells me, you know, where in the code that resource might be defined. And then uh the other thing is each stack defines resources for a single cluster. And I think I heard the last presenter kind of comment something similarly, this this like real simple, straight up of straight up um arrangement of one stack per cluster. So what I've done here um And so what that means is users only have to create an appropriately named stack and then the workflow selects a github environment that you know, pre configures everything and that stack name just really directly mirrors the uh cluster naming convention in the environment. So another way that I've helped here um is by adding these thin abstractions to reduce boiler plate. Um So the confluent cloud provider itself is extremely verbose and like structured. Um So I've kind of built these thin abstractions, that's most of what's happening in this core module. Um These abstractions further benefit from the assumption that each stack targets a specific cluster. So I'm able to kind of automate a lot of the configuration there. Uh So my users don't have to think about it. Uh And so this is what it takes just to define an API key. I I felt like I needed to demonstrate this. So, um you know, there's a lot of nested objects that kind of, you know, this this owner is really just taking the service account, but in all its constituent parts assigned to other other. Well, now that's exactly the same and same here. So there's this kind of all this boiler plate that uh an engineer would need to understand. But when I look at this code in its entirety, the only thing that I need my user to provide me so that I can stand up an API key for them is the service account, right? And so that's really all these thin abstractions are, is taking this giant chunk of code and boiling it down to this so that my end user doesn't have to think about it as much. Um This still provides them the opportunity to break out of the abstraction. Um I've worked in some other situations where, where you know what I'm giving the engineers is essentially um the Pulumi providers directly with a little bit of convenience on top. And I've seen other situations where that kind of is completely abstracted and they're just working in YAML. But again, I want to stay out of everybody's way. So um I want them to have access to the full tool set if at any point I'm blocking them. So let's talk a little bit about the types of things these users are provisioning on Kafka or on confluent cloud. Um Again, kind of coming back to the structure here, most often author users need to authorize services to read and write to a Kafka topic. So basically everybody that uses is going to need a service account, some AC LS and API key. Um Then anybody that's going to be producing data is also going to want to provision their topic and then others still are going to want to use these managed connectors which really simplify integration with third parties and data stores. So the big challenge here is that our users need to deploy stuff at the organization level and stuff at the uh cluster level. And I considered service accounts managing them in a separate project and using stack outputs. But um again, just really leaning into simplifying this as much as possible for my end users. I wanted to allow them to define service accounts in the same project alongside their AC LS API keys topics and connectors. Um Again, just trying to make things as low friction as possible as simple as possible. Um So to do this though, the workload need runner needs to be an organization admin. So basically they need to execute code as a super admin. Obviously, that's a bit of a concern. Uh policy packs though have allowed us to do this safely. And basically what I've created is a policy pack that just restricts creation to these five resources and then further ensures that these API keys aren't created for the admin service account or for other users. Um And that, that locks things down pretty well that, that will prevent anybody from elevating their access or, you know, standing up a new Kafka cluster or uh you know, going and deleting something whatever. Um So this is just a little example of one of those policy rules. So this is policy enforcement for the, like I said, to ensure that nobody generates an API key for that admin service account. Retrospective here. Uh I've only been running this for about six months. Um In that time, the mono repo has grown to six projects with 15 stacks. Uh We've stood up connectors and liberated data out of two of the three monoliths and we've got one product feature rolling out into production. Um That product feature rolling out into production is uh I guess going back to my earlier points, it was nothing that was uh was a thought in anybody's head when this work started. But again, focus on creating opportunities and then the use cases will follow. So some bumps in the road. Um I did end up building a dynamic provider. There was a situation where I needed to run a standalone Kafka connector and um both dynamic and providers have really unique execution environments that you should watch out for. Um And then the other thing is early adoption is just kind of tough. I developed a proof of concept three weeks before the 0.1 release of the official confluent cloud ploy provider and have, you know, expectedly bumped into a few hairy bugs along that, uh, upgrade route being an early adopter. See, looking ahead some other things that I'd like to do with this project. Uh, I think that the Monte Rio is only going to grow so far. It is uh you know, it's a pragmatic choice. It's something we do to reduce friction right now. But um eventually, I think that uh shared workflows and perhaps creating a shared like a proper um poetry library for people to import is going to uh enable more autonomy for teams. They'll take on a little bit more work, a little bit more responsibility in that, but they will have more autonomy. Um I want to try enforcing that naming convention that I spoke about early earlier in the policy pack. This is something that has just occurred to me in the last couple of months that I could probably do that. So I think that's something I'm gonna try. And then finally, this last one is, is a really a much bigger subject. But um like I said, the dynamic connector, it doesn't work well outside of the main module, which means that it's kind of difficult to create a dynamic connector and then share it internally in your organization. Um Beyond that, uh topic, schema and case equal DB queries are also things that have really conventional rest api s behind them that don't have providers today. And I have a feeling that, uh, I know at least the top two and maybe the third is something that I'm going to be tackling in the next quarter. And that's it for me. Uh, I didn't see any questions throughout but, um, oh, I missed the question so I can use both. So I think that's somebody else's question. I'll ask a question. I think, I think you got, you talked at the beginning of your, um, talk with a question that a lot of us wrestle with in a lot of different ways where, uh, you know, there is an OS S version of the technology, you know, in, in and you sort of have to decide, you know, hey, there's this cloud version, you know, it's easy to use. We often get asked, you know, the, uh, you know, should I self host Pulumi or should I use the, you know, the, the service version of me? How did you sort of think about the tradeoff on, you know, you know, should I burn an engineer, you know, standing up the instance versus the cloud service? And, uh, and how do you think more generally the, that sort of tradeoff, you know, with, uh, with using OS S versus the managed version of the service? Um I think, well, I mean, it it really is gonna depend on the appetite of the organization. I think, you know, a really technology led organization might just inherently understand the value of the technology and they're gonna put a lot of engineers towards doing something like that. But um more product led orgs are probably going to be a little bit leaner on innovation like this. Um the benefit is not as well understood. And so, uh we, we basically need to find like right now solutions that don't require a lot of engineer time. And that was basically the decision here. Yeah. Yeah, cool. I think you also talked a little bit about the, the challenge overall between, you know, unifying platforms, whether it's from acquisition or uh you know, uh heritage code base to modernization. The, the uh it with were the challenge is mostly cultural or technical or a combination of both or uh you know, sort of how do you teach people to, to move to the, the new platform? And uh what, what are your parents? Yeah. Well, it's been, it's been an interesting situation. So I started as part of this core technical services team and was kind of there at the beginning of it. So, and this was shortly after the acquisition. So um we kind of came in as like a neutral third party to all of it. Um We weren't, we weren't part of duchy that acquired, we kind of came in after Dutchy acquired the other organizations. But I would say like, yeah, definitely um culture is part of it. And uh but I would say that, you know, the, the real, the real concrete problems are, are just, you know, operating multiple cloud providers, operating multiple technologies, we have Ruby and we have dot net, we have Azure and we have Aws and Heroku and you know, that's just a lot of overhead. And so really, um on one hand, one of our, our biggest things is trying to consolidate that effort. Um But also from our users, it's not the greatest experience. They, we, they still log in over here to go to a point of sale and they still log in over here to go to a uh an Ecommerce admin portal. So, um I think the really unique thing about being in the position between those three is trying to figure out which, which aspects of the business we need to unify the service first. Like, what does that look like? Yeah, that's awesome. Well, Colin, I wanna, I really wanna thank you for your time. Uh It was awesome. Getting a little bit uh behind the scenes here. I know you got a lot of challenges and, and uh all of us as providers to, to other folks uh in the organization are constantly uh swamped with requests. So thanks for, for making time for us.

---
