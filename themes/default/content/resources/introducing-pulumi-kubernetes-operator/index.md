---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Introducing the Pulumi Kubernetes Operator"
title: "Introducing the Pulumi Kubernetes Operator"
meta_desc: |
    The new Pulumi Kubernetes Operator enables Stack deployments from within a cluster using Git-based workflows. 
url_slug: introducing-pulumi-kubernetes-operator
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Introducing the Pulumi Kubernetes Operator"
  description: |
    The new Pulumi Kubernetes Operator enables Stack deployments from within a cluster using Git-based workflows.  This introduction demonstrates end-to-end delivery using: 1. Pulumi Stacks as a Custom Resource Definition 2. The Kubernetes Operator processing Stacks 3. Demos of Stacks managed by the Operator: AWS S3 buckets, and a Kubernetes Blue/Green app.  GET STARTED: https://pulumi.com/start
  sortable_date: 2020-08-12T18:16:15Z
  youtube_url: https://www.youtube.com/embed/nQZr3uquc-c
transcript: |
    Hello. Today we'd like to introduce the Pulumi Kubernetes operator. A new way to manage Pulumi stacks of infrastructure in Ktis. In this talk, we'll review a couple of key concepts. We'll explore what a Pulumi stack is and how it works. We'll introduce the Pulumi operator and how that fits into your workflow and then we'll demo how you can manage Pulumi stacks using the operator. In Kubernetes. A Pulumi program is an authored set of code that allows you to provision and manage infrastructure across any of the major cloud providers we support along with Cabernet's, this allows you to provision communities clusters, workloads in those clusters or even provision virtual networks, virtual machines, block storage and the rest of the service catalogs that the cloud providers support. You will house the program in what's known as the Pulumi project, which is essentially just a directory that it's accompanied by some extra content such as a meta data file to describe the run time that it's being used. In this case. If we're authoring our infrastructure in Python, it'll describe the runtime to be Python. Additionally, we'll also have package dependencies that must be installed before we can actually invoke our programs. We can take these programs and describe any infrastructure that we still choose to. This program can be instantiated in what's known as a Pulumi stack. A Pulumi stack is a way to take the same existing infrastructure code and template it or configure it based on different settings or different environments. A common pattern that folks use is to mirror their Pulumi project stacks to the target environments that those stacks are being deployed into. So you may have environments like dev staging and prod and similarly, you'll have stacks that are dev staging and prod holding configuration settings for each of those environments. This allows you to cut down on the number of duplicated code and just temporize the pieces that matter most to you. A Pulumi stack can really be described as a way to house any infrastructure that you so choose to that is supported on any of the cloud providers communities or both. This includes virtual machines within a virtual network, attaching block storage to those virtual machines, creating object storage for files, provisioning managed communities clusters such as Eksgke and A KS and you can mix and match use. However, you see fit the Pulumi co operator is a way to take a Pulumi stack and run that for you until success. What that means is we can take a stack and model it in COTIS as an API resource known as a custom resource. This is a way to extend the API resources in COTIS for custom API S that don't exist. So what we've done is we've modeled the stack to be a project that gets housed in a GIT repository that holds the Pulumi programs to describe your infrastructure upon the creation of this API resource known as the stack in kubernetes. The stack controller or the operator really is going to observe, analyze and act in a continuous reconciliation loop to make sure that these stacks are being deployed successfully. The way this works is that we will check out this Pulumi program from a git repository at a given commit. Shaw. Once we check out that code, the stack controller will run through the necessary steps in Pulumi to create the program and run it to completion in what's known as a Pulumi update. When the Pulumi update is successful, this stack will reflect any metadata information about how to work with it in the Pulumi console. And in the chance that the stack does not successfully deploy it will error inform you and the stack controller by definition will continue to try to retry to deploy the stack. Let's see how we can take an existing Pulumi program and model it as a stack custom resource in Kubernetes and have it be managed and updated by the kubernetes operator. We'll start off by using a canonical example of the typescript programming language in Pulumi to provision AWS S3 buckets on Amazon. We'll start off by importing the AWS SDK using node and M PM. Then in a for loop, we're going to create 2 S3 buckets that are publicly readable and we'll take the names of those buckets, push them into an array and export that array for other users or Pulumi programs to refer to. We'll then take this program and store it in a version control system such as GIT and upload it to a repository. Say on github, we need this to be git friendly because the way the operator works is that it'll check out a given program at a given commit. Shaw and it'll run a Pulumi update on that commits shaw until that update is successful. So in this case, in the context of cabernets and desired state, the Pulumi Cotis operator is driving towards a desired state of a successful update for a given program at the given commit and it will retry to update the program until we have success. Once that is up and running, we're going to store this on github. And we're going to create a new Pulumi program to describe how we deployed the operator and the stack using the stack custom resource. So in the first step, if you don't have a Pulumi operator, we're going to deploy it using a component resource that we've created that allows you to aggregate and manage all of the resources the operator needs holistically such as a service account for identity, a role for permissions a binding of the role to the service account. And then lastly, the deployment that describes how we actually want to roll this out here. We can see that we'll use the service account roll and binding in a new deployment for the operator that will leverage the service accounts with the given container and additional settings. Once the operator is deployed, we can create a S3 bucket by describing this program and its settings in what's known as a stack custom resource. This custom resource allows us to encapsulate the settings to pull down a given project repo at a given URL. That is GIT based, we'll take a commit and do a check out of that GIT repository and then we'll deploy it in an update using this given stack name. We can pass along settings such as access tokens and other configuration settings and we can even say, create the stack if it doesn't exist. And when we delete the stack custom resource, if we still choose to, we can also tear down all of the resources in that stack along with the stack itself. Let's see how we can deploy this to manage our S3 bucket program. So we'll start off by initializing a new as three stack. And we're going to then check out the settings that we're going to be giving it such as the axis token and blooming service to use. So we can store and manage state the stack settings such as where is the program located? In this case, here's the URL, here's the giving commit. We're going to check out and run a plume update on and the stack name that we want to use additionally, we can provide credentials such as what my aws access and secret access keys should be to work with aws. We run this configuration and do a Pulumi up to deploy the operator and the stack custom resource. once the operator is up, great, it's deployed. Now, let's inspect the operator pod. Let's do a tail on that pod. And here we'll see that the stack custom resource is starting to be processed and run through its update loop. If we don't want to look at the logs on the operator, we can see the stack itself as a resource. He would get a full output of the object as it's being updated by the operator as information is made available. We'll get information of how we can work with the stack and see its information. Great, an update's been deployed. And here we can see that we have the Perma link to go visit its update along with its outputs of the bucket names that we want to deploy. Let's see what this looks like in the console. Here's the update. A couple of buckets have been created. You can see a diff we can expect the resources. Here are the two buckets. We can inspect this on aws and see that we have the first bucket and the second bucket. We can also see on the stack, the actual commit that was deployed. In this case, an adjustment of a couple of buckets being deployed and our stack is fully up. Let's see how we can run a kubernetes blue green application that is modeled as a stack, custom resource and it's managed and updated using the Pulumi cnet's operator. We'll start off our deployment by deploying version one or the blue version of our application by targeting a particular current image tag that will be deployed. Once the application is up, we'll create a service that will front that deployment using a public load balancer on the V one deployment apps using the selector based on its labels. In this case that the application is blue at some point later. When we have an update that we want to deploy or V two green in this matter, we'll create a secondary deployment that will be on standby until we're ready to make the cut over in this V two or the green version. We're gonna target the new image tag compared to the current image tag. And once that's up and running and we're ready, we'll make the switch from V one to V two by updating the services labels from selecting V one to selecting V two. We'll take this program source and we'll store it in a GIT based version control system and upload it to a repository such as say on github, we need it to be a GIT based repository because the operator checks out the code at a given commit and will walk through running a Pulumi update on that commit. Since we're walking through a series of commits here, we can pass these changes to the operator. But let's see what that looks like before we do. So here is a visual of the commit history starting with the bottom initial commit and moving on up to the most recent changes. So in this commit, we have deployed V one of our deployments that is active and a service load balancer that's serving traffic on this commit. We'll stand up V two of the deployment or the green version that is in standby or passive mode. And when we're ready, we'll make the switch of the service selectors to go from V one to V two to cut over the traffic and not drop any packets in the process. We'll walk through these commit changes using the Pulumi grenades operator and the stack custom resource. So we'll create a new Pulumi program to manage this stack and describe it here as a custom resource that says we're going to be deploying this particular project repo at this given URL we're gonna deploy and check out this commit. And we can even do functions such as say, initialize the stack if it doesn't exist on creation or even destroy all of the stacks, infrastructure resources when the stack, custom resource gets deleted in the cluster, we can model all the settings that the stack custom resource needs such as this Pulumi api access token to work with the Pulumi service to manage and store state the settings for the stack itself such as its name repository and commit. And then we can take the actual token and model it as a secret that we pass in for the stack to use. Let's run through this deployment in a couple of steps. We'll start off by initializing this program and let's see what its configuration should be. We're going to pass in my access token. We're gonna say use this given stack name located at this repository on this commit B 19 759. So if you look here, we're going to just jump ahead to this step for the sake of time and deploy the live active version of V one with a servers load bouncer along with V two, which is just sitting on standby shortly after we'll make the switch to go from V one service to the V two service. Let's set this config let's do it. Pull me up. This will go off and deploy the stack custom resource in the cluster and with the operator already running, it will process the stack and deploy a pluming update on it until completion. Let's inspect the community's operator by looking at its logs. So I'll follow the community operator and see all of the live output as it makes itself available. If this is too noisy, we can also see the information on the stack, custom resource itself. We can do a get stack and watch all these changes happen as they deploy shortly. We'll get some more information from the new updates as these updates are made available. Let's jump into what our console looks like if we want to see another live view. So here's our V two of our deployment that's being stood up as we speak, we can inspect all of the changes that are happening. In this case, we're standing up both versions of the deployment where the service is initially targeting V ONE as updates are made available, you will get information such as the Perma link of the update that was made the state or the desired state here, which is the commit that we're checking out and running a plume update on and any outputs that the stack may have exported such as the URL end point of the service. Let's go ahead and take this URL and do a curl on it to see if our V one is actually functional. We'll do overall true, do curl on the end point and we get the output that we're running the current tag of our V one blue deployment. Great. If we want to see what this looks like as we saw earlier, we can jump into the console and see all the information as such as what resources were created. Its names, this information, any timeline of activity that may have occurred. Great. When we're ready to make the switch over, we're going to update the commit to switch from V one to V two. And the operator will deploy that for us using the community's operator. So we will do a Pulumi config to show the current settings. We're gonna update this commit to the switch over, commit F four BF. And we'll run a second plumy update on that program notice on the right. So we are actively pulling our endpoint for its version in a bit. We should see the cut over from V one to V two happen seamlessly. We can do the stack yet again to see any changes. So this is the previous stack. But shortly as the updates are made available to the system in, it'll be updating the stack as well. So as we see the cut over of traffic from the blue version to the green version has happened and we haven't dropped any packets in the process. Our blue green deployment is functioning as expected on the left. You'll see that as the blue green deployment was rolled out and it was successful. We can see information such as the deployments in the console. And we can see that we made the switch from V one to V two, we can get a richer diff of what that looks like. And we can even inspect this commit to see what changes actually took place. We went from V one labels to V two labels. Great. As you can see, we deployed a blue green deployment seamlessly through community operators and modeling our program as a stack custom resource. We've seen how we can model Pulumi programs in Cotis in a first class approach, we can encapsulate the program stack settings using the stack custom resource in Cobert that is managed and updated by the Pulumi communities operator to seamlessly run Pulumi up on all of your programs at a given commit. This is great for continuous delivery settings as well as automation systems. If you'd like to check out the code and more examples for the operator, please check out our GB repository and for even more examples of the types of programs and infrastructure you can manage using Pulumi and the Pulumi Cober operator. Check out our Pulumi Examples repository on github for examples on infrastructure containers and more. Thanks.

---
