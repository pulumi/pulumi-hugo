---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Cloud Engineering Summit 2020: Standing Up a Serverless Platform"
title: "Cloud Engineering Summit 2020: Standing Up a Serverless..."
meta_desc: |
    Serverless platforms are supposed to make life easier for Developers and by integrating Pulumi, we can help simplify the life for Operators too.
url_slug: cloud-engineering-summit-2020-standing-up-serverless-platform
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Cloud Engineering Summit 2020: Standing Up a Serverless Platform"
  description: |
    Serverless platforms are supposed to make life easier for Developers and by integrating Pulumi, we can help simplify the life for Operators too.  In this talk, you'll learn how to use Pulumi with Google Cloud (GKE and Cloud Run) to deploy a serverless platform with dependencies easily.
  sortable_date: 2020-11-11T00:29:16Z
  youtube_url: https://www.youtube.com/embed/3cjDS1X-DFk
transcript: |
    Hi and welcome to the Cloud Engineering Summit. My name is Jason Smith, but you can call me Jay and I am actually an app modernization specialist at cloud today. We're gonna be talking about standing up a service platform and we're gonna be using Pulumi Ktis K native. A few other little tools I wanna start by talking a little bit about Kubernetes and I think everybody who works in the cloud today knows what it is. So we'll try to make this quick. Kubernetes is kind of the de facto platform for running containers. Don't believe me, look at all these people. This is an exact number might be a little dated but of the large Kubernetes ecosystem and this is actually just a really small one. CNCF actually released a new chart that is way larger than this, but for the sake of saving your eyes from a lot of color, we're gonna do the smaller one. But trust me, this is larger and of course, it makes sense that a lot of people want to use it because it abstracts away infrastructure. If we are trying to move to the cloud, it only makes sense that we try to make the infrastructure as easy as possible. We want to make sure it is easy for us to provision nodes, provision, networks, provision, all of that stuff that we need. In the old days, you had to have SSH access. Sebastian's server script after script, after script, I was in the data center world years ago and we relied heavily on pearl scripts and I'm sure I just gave a few people uh some horror flashbacks when I mentioned pearl scripts. But you know, with Kubernetes makes it so much easier. Why, what COTIS provides us with a declarative API that allows us to observe, compare and act, it allows us to see what's happening, compare what we want, what we expect to happen, act on it and reiterate and reiterate, reiterate. And of course, that API is extensible, we can write custom API types. We aren't stuck to a specific platform or specific uh set of rules or anything we are allowed to extend beyond that. If you've ever seen that ecosystem really that we talked about a lot of those people are people who have created custom resource definitions to extend the is capable of doing and offer you services that you never thought of before. It's so easy. Anybody can do it. But it was always a catch really isn't for developers, at least not out of the box. It's not the right abstraction for the end developer experience. They, it's great if you want to build a platform, it makes it so much easier to build a platform, but it's not for building apps. If you don't believe me, let's take a look at this. So anybody here who's used Kubernetes will be able to tell you that if you want to deploy an application, these are all the steps you have to take and these are just the basic steps, there are additional steps there as well. You know, exposing the internet can also include setting up to standing up ambassador engine X, all of that fun stuff. What do developers actually care about writing code? That's their job, they just want to write code, that's what they're best at. Why not let them focus on what they're best at this brings us to serverless. You might have already been thinking that when I mentioned making things easier for developers, you might be saying, well, haven't we heard of this before? Isn't this called serverless technology? And I'd say you are absolutely right now, let's talk a little bit about serverless. Why is server so popular? Well, we see two models within the server list realm as you can see here. So from a programming standpoint, when, when we're talking about our developers, they love the idea that they're able to write service based applications with service based me usually means that they can also be decoupled and they are can also run in a stateless uh stateless environment uh in a stateless state, so to speak. Uh because of that, they don't have to hard code or, or imperatively code any kind of uh set up on that. And then of course, from an operational mo model, we don't want to have to handle a lot of ops to scale up as our application becomes popular as our customer base grows. But we also want to know that everything is being taken care of. We want to tell somebody else, hey, you manage the security, you make sure nobody hacks into the servers, you make sure the servers are up. Oh and on top of that, I only want to pay for my usage. I don't want to actually have to pay for idle workers. I mean, I mean, that, that makes perfect sense, you know, and that's kind of why a lot of people move to the cloud in the back in the day. If you wanted to have side resources just in case of a spike on say Black Friday or something, you would have to have servers on standby. But what happens if it's an off period? You know, those, those things are just gathering dust, maybe you can find some use for it. So the serverless philosophy is efficient developers and efficient operators. One way to think of it is we want to give people the ability to focus on what they are good at. We don't want developers to have to be operators. We don't necessarily want operators to have to be developers. Now, granted we're seeing a lot more operators function in developers. And of course, we see a lot of developers, function operators. You know, that's kind of where the whole full stack developer de ops that whole whole idea came from. But realistically, if we can have people focus on what matters to them and what they are best at, that's how we bring the best value to our projects. So while we're talking about developers, what do they care about? Philosophy and reproducibility, they don't not care a thing about the infrastructure. At the end of the day, they just want to know that their app works. Their app scales, their app does what it's supposed to do. That's it. If there is a load balancer issue, they don't wanna, they don't really care about it, at least in terms of their persona. Now, if somebody gives them that duty, then they care about it. But now that's taken away from their other work. So I've created kind of a serverless platform. Now, usually our serverless paradigm. If you will, usually it's build, deploy and consume. But thanks to my friends at Pulumi, I've actually learned that there are four steps stage, build, deploy and consume. So staging with Pulumi. Now, I'm sure you've heard a lot of talks about Pulumi, you're joined in this conference. So you've probably heard a little bit about it, but let's just take a little time back and talk about what we have here. So infrastructure management is now in is now orchestrated by definition files, not hardware tooling. So this brings us to Infra infrastructure as code. I'm sure you've all heard every tool that exists out there. Uh whether it be terraform cloud formation. Chef Puppet, the list goes on and on and on and on and it's great because when the cloud became a thing, it made it so much easier just to deploy my application while also standing up the environment with just code rather than physically putting servers somewhere, running some startup script. That's, you know, we all used to do that back in the day. Infrastructure of code does not necessarily come without its own burden though we often see custom language types. So we, you know whether it be called uh uh the different types of DS LHHCL languages, a lot of them are tend to be bespoke. So they will be very, very unique to a specific tool set or a specific platform. And you're finding yourself having to work around that. And maybe that maybe it doesn't work as well on all platforms. So you're using one tool for 11 tool for another. You're trying to find new ways, you have to manage state files. So the state files tend to be saved in a directory or in the cloud somewhere to let you know where you're uh application, where your infrastructure, what it looks like after the last push, configuration management becomes difficult, where do we save all of our files? Where do we save all of our, our recipes, our definitions, et cetera. This all becomes very difficult. And also all of this tends to exist outside of our base code. So we have like this entire different box just to stand up our application, then we can deploy code. And, you know, for the most part, it did make things easier and we just kind of worked around it. But that doesn't necessarily have to be the case anymore because you know, with Pulumi, I find that I don't have to write cookbooks. I don't have to write J Jason uh cookbooks or definition files. I don't have to use any kind of DS L for that matter. I can use the code that I use to write my regular application to deploy an uh serverless application on KTIS. Now, you might be saying, well, Kubernetes, that's not exactly serverless, bear with me and we'll talk about it a little longer. But from a developer standpoint, I can stand up code using or I can stand up my infrastructure using nothing but code regular code in my regular coding cycle. In my regular C IC pipeline, I can actually create a definition file in typescript in Python in go less copy and paste more productivity. It's just in my normal work flow. So as a developer who writes in Python or Ruby or whatever your language of choice is, this fits right into my normal workload. This doesn't feel like additional work, so to speak because I can write it into my normal loop or my normal work flow as I mentioned earlier and it can be put into C IC pipelines as part of that building status. Uh So let's talk a little bit about CS CD pipelines. So we're gonna jump into the build portion of the server list. Many of you may have heard of Tect, you may not have. It is an open source tool governed by the CD foundation. If you're not familiar with the CD foundation, it is something of a spinoff of the CNCF foundation. What they're trying to solve is a way to make cloud native declarative. What uh C I CD pipelines? So, Tect uses kubernetes native components. What does that mean? Well, it means that everything is ex is a co kubernetes api extendable. Everything is extended from the kubernetes API, everything's a knee's object. Every step is a kubernetes container or it runs on a pod. So everything is kubernetes, it can actually live in your cluster, which a lot of people actually like because if you're running a large cluster, say on Prem and you don't want your, you, you don't want to have to ping to the outside world in order to trigger your pipeline or whatever this is perfect. We also offer catalogs or Ecton offers catalogs. So for a lot of the tooling that you'd use, that is pretty common. So like pulling from github or pushing to get lab or, or standing up a Google Kubernetes cluster or a kind cluster or whatever, that might be very common actions, we can create a catalog that has reusable tasks and pipelines that you can just download plug in the specifics of your information or of your environment and run. And then it also integrates with other products that exist out there, such as Jenkins uh integrates with K native, which we'll talk about shortly. And even more. And as more people join the CD foundation, we're starting to see more and more companies adopt Teton. And really, I think it's going to become the gold standard of cloud native pipelines. And this kind of gives you a quick overview of what a pipeline is. Uh So you, you've probably seen something like this before. So you can create a trigger in tect to that. Whenever you push something to a specific branch or with a specific tag in your git repository, it will then trigger the pipeline. Each step, each pipeline creates or each pipeline has a variety of steps. So each little box here can be seen as a step. You can actually create some additional logic to tell it based on this criteria, execute this step. So as you can see the branching here as a step completes spins up another pod for the next step and the next step until things are done. So all in the cloud, you can actually automate using code the entire C I CD pipeline. Now, if we're taking a step back with Pulumi here or Pulumi, sorry, uh what we have is the opportunity to actually create a pipeline for code that builds clusters. That's actually pretty interesting when you think about it just like you would create a pipeline to create a service that does machine learning or anything like that. Now, we're gonna jump into K native. Now, what is K native? I don't like to say it's a serverless platform or a serverless framework because it's more like the components to build a serverless framework. We don't try to define specifically what a serverless framework is as much as we want to give you the ability to fulfill that serverless paradigm that I mentioned earlier of being developer focused and not focusing so much on the infra or the deploy process of your application building. So K native is an open source project. It was open source by Google back in 2018. But uh at Google next, uh it is 100% open source. We have a variety of companies involved in maintaining it, but of course, Google is 100% committed to it as well. So you have kind of this huge mind trust in building it. It creates a set of building blocks to can create your own fast or pass. So when I mentioned earlier, we're not trying to tell you uh in an opinionated way. Well, serverless is functions or serverless is pass. What we are saying is serverless abstracts kubernetes tasks from the user. How you want to stand that up is up to you. So it, it's an abstraction on top of kubernetes, it automates a lot of the kubernetes deployment. So if you wanna, if you wanna move it up to the higher level to where it acts as a function as a service with say open pass, you can do that if you want to do it lower level and make it more like a platform as a service based on containers. You can do that as well and it runs on containers at the end of the day, I do want to emphasize it is not a Google product. It is an open source product that Google open sourced and Google contributes to. It is not a Google product. You do not have to pay a license fee in order to download it. You can go to github right now, pull it down, use it and do whatever you want and it's open source, you can contribute, you can extend it, we encourage contributing. And of course, like I said, it's not a fast uh it, it's not functions, we're not talking about functions. You can build a function as a service framework on top of K native, but it's not functions in and of itself. So what can you do from a developer perspective, directly deploy code, it's not easy but it works great. So I try to avoid telling people we make anything easy because easy is kind of, you know, objective. It depends on who you are. You know, some people think just writing on the cli is easy. Whereas other people prefer the U I. What we do is we simplify the deployment process to where developers don't have to focus as much on that tedious task. The operators love it because it puts a level of distraction between the devs and Kubernetes. You know, if you're an operator, you have a lot of stuff to do already. You don't wanna have to on top of that, do deployment work, you wanna be able to focus on what you need to and let the developers focus on what they need to and enable them to do the deployment without hassle. Now, for your platform architects, they can define what their platform looks like because it's not super opinionated. It's not saying yes, you have to use functions. It's saying hey, we are abstracting Cober netti and you can build whatever you want on top of this abstraction. Now out of the box, I would describe it more closely as a pass. But we have seen people install other tooling on top of it to make it more fast related uh kind of removing a lot of the containerization if you will. So let's talk a little bit of what that stat looks like. So Kubernetes is the platform and that will, will build out later. The primitives that we offer are serving events and well, I put, build on there and it's a funny story. So build was originally one part of the K native components, but it became such a way that we, that the developers thought, hey, this is such a great product. It shouldn't be strictly for K native, it should be for anything cloud native C I CD. So build spun out became Ecton. And since about version 0.8 it's been deprecated from the K native stack. I usually like to reference it just in case somebody's diving into old documentation again, this is a 2018 summer product. So there's a most documentation is relatively recent. Uh So you know, kind of given that context and on top of that, as you can see, you can install a bunch of different products. So Google, we actually have cloud run, which is a managed version of K native serving. But you can see there are a lot of other tools that are built on top of these K native primitives. Let's talk a little bit about the component. So K native serving, what makes this easier? Well, K native serving is what actually handles the deployments. When you deploy a new version, it automates that revision handling, it automates the traffic splitting and it automates the auto scaling. What does that mean? Well, it means it's seamless to scale up and down. It is seamless to build in uh to do the traffic between revisions if you want to do like Canary test A B whatever, uh it integrates directly with a service mesh. So out of the, I wouldn't say out of the box, but originally it supported Justice Steel, but now it's in supporting contour and glue and ambassador and a few others depending on what your needs are. And it's easy to reason about it. And again, it is extensible because it's built on top of Kubernetes, Cuber Netti is object. So if you want to use your own auto scale or if you want to use your own monitoring platform, you're absolutely allowed to do it. You're not boxed in and here's a quick look at what it might do. So you know where you see service might function here. That's what I've deployed. That's the application I've deployed in a container. The the configuration will then handle the revision. So the different version. So I push a version a day later, I push another version, it will then deploy the next one and then the route is what routes the traffic. So a quick look here is that Kubernetes does memory and CPU based scaling. So if we just talk about straight Kubernetes without K native K native, does it based on requests scale to zero cober needs can't do it. K native, your applications absolutely can scale to zero. And there is a way to set like one pod if you want to have warm uh startups instead of cold. Uh but it will scale to zero because the K native operator, the K native components, the the K native serving components. That is what's actually listening to traffic coming from the uh coming from outside world, inside world. And it is when it gets the traffic, it wakes up the the application saying, hey, we need to run this application X amount of pods and route the traffic there. So you're able to scale down to zero. If there's no traffic, the load, the load balancer much easier to set up. It's based on requests and you can do simple traffic splitting. And let's actually take a look at what Kubernetes looks like uh with K native. So anybody who's deployed a Kubernetes app has seen something like this. This is a simple Hello world app, but look at all that text. Is there any way to make this easier? And by the way, this is two files or you can just stack them in one. But with K native, I don't really need to set replicas because serving already does that for me, I don't really need to set these labels either because I don't really need all this. Like I only need these lines of the name and I need to call it a service I need to know what container I'm using, maybe set some limits. A lot of these lines aren't really necessary. So instead I can write this simple service K native service using the K native API. And as you can see that that exact file I can deploy that exact application with just these lines here. Same exact thing, cloud run for ants. I want to mention is a Google uh managed K native offering for Kubernetes. We also it is a cnet's offering. We have a fully managed version as well. Uh So we have one that's K native serving API compliant, but it's running on top of different things. So if you don't care about Kubernetes, if you just want pure serverless cloud run, fully manages for you, if you want to extend it and you want more freedom, cloud native or cloud run on ant is for you because it runs in a regular Cotti offering. Now, let's talk about eventing. What is eventing now, I would encourage you to go to serverless eventing dot com because I write a lot about it, but we'll touch upon it here a little bit. Anybody who's had to write an application that connected to code or connected uh to a Kafka bus or some kind of message queue out there knows that you have to imperatively to bind, to bind your code to. That won't, that doesn't make much sense in the world of micro services. Because the whole idea of micro services is that there are a bunch of decoupled service. We don't wanna have to declarative, bind them to anything specific or imperatively bind them. What if we could declarative, bind them? K native eventing kind of creates that abstraction between your application and whatever your messaging queue is to where instead of writing an application that connects directly to the queue, you just write an application that either handles egress or ingress can native eventing will then handle that traffic and tell it where to route what, what topic it's supposed to subscribe to how to authenticate with secure TLS mutual TLS. You can create your own pipelines, you can do view events, live streams and it connects to your existing system. So we're not saying you have to throw away everything you have today to use K native eventing. You can use whatever it is you use today. Uh We support a lot of things. Uh cof A Nats Pubs sub uh the list goes on and on. If you go to K native dot dev, you can see it all. So this kind of gives you a quick idea of what K native eventing looks like. Uh Obviously, it can change because it is an open source and kind of pre I don't wanna and it's pre I guess enterprise release if you will. So we have the two basic uh paradigms here. When it comes to delivery, we have simple delivery, something hits a source, let's say our, our topic and we just want it to go straight to the service. Like, not simple as that. You can set up a simple delivery for that. All that service has to do is be able to read a, uh, post request and it's good to go. So it doesn't have to directly connect to anything. Now, maybe you can have a more advanced topic and you want to give a little intelligence to it. You're actually able to create a channel which operates under the subscription model. So you create various subscriptions to the channel and based on the traffic that comes in or other parameters, it can route that message to a different service or a different channel as you can see. So you can do some really advanced routing too, which is great when you're scaling out and building larger apps. Why don't we jump into a demo and I'll show you how we can do this. So let's take a look at the demo. So I'm not gonna belabor this part because I'm sure you've seen plenty of Pulumi demos uh today. But I did want to point out some of the basics here. So we have some type script and what it's gonna do is it's gonna provision a cluster for us uh then, but we also have a few other features here. So we're gonna pull down K native. Uh What we have here is we have our ID OCR DS. So is do, is a requirement for K native uh or it was an original requirement, I should say. So we do support or K native does support other versions such as ambassador glue a variety of other types of service meshes, ingress controllers, et cetera. Uh But for the sake of this, we're gonna use this do since that was kind of the original. So we're gonna install that, We're gonna install some required steel components for K native. Then we're gonna go ahead and install the K native eventing and the K native serving components. Now, the beautiful thing is lately, K native team has actually created an operator. So you don't have to install the components individually in their Cr DS individually. You can just kind of install it as one thing. So we're gonna actually install that operator back in the day. You had to install it separately and honestly, sometimes I still do that. But um you know, I, I'm starting to get used to using the operator since it's new and easier to use uh some basic uh We also have some streaming. So we're gonna be installing a rims operator. If you're not familiar stri is an open source uh solution based on CNCF. It's essentially a way to run COF a easily on ACUs cluster, making it easier to do it without having to do a lot of zookeeper and whatnot provisions. Oh, so we set some TIS as well for roll binding, all that good stuff. We have this Teton thing. Now we're not gonna show the tech to today, but we do have the code. I do encourage people to go and play with it and figure out how the best way to get through that and run that. We also have a sample application. So this is gonna be the interesting part. So we have a simple application uh that pulls code from Alpha Vantage uh not code but uh you it pings the Alpha Vantage API. I really like using the Alpha bant api because one it's free and to or up to I think 500 requests a day. But also if you are a uh person building streaming software and you want to build a demo, I can't really think of a better example of streaming data than your financial data since that seems to change every second, almost every microsecond. Really? Uh So yeah, so we pull there some currency information. We're gonna just do some exchange rate of the Japanese yen to us dollar. So that's that part. We also have a producer. So this is what's actually going to act as our event source. The producer is going to send the data to the Kafka cluster. So basically our event source egresses to the pro the Kafka producer which then writes to Kafka. Now you might be asking yourself, well, you know, in this code, it doesn't actually say to connect to a specific service. What I have up here is a URL called K sync or a AAA variable called KY and K sync is essentially saying event sync. Now how does it know what the event sync is? That's a very good question. What we do here is we look at sync binding and a sync binding is an object that tells K native eventing. Hey, things coming from this subject. So this is gonna be our source. Things coming from currency source should go to a pro uh producers. So you know what I mentioned earlier, you just worry about egress ingress. That's exactly what we're doing right here. This is just sending a post request to whatever our SYNC URL is Casey. And then this just simply getting any post requests coming in simple as that. We also have some. Uh so talking about ST RMS, this is how easy it is to deploy a cluster on rims once you have the operator installed, uh this is also how we create. This is a service called a Kafka consumer. So if we have something writing to a topic, we need something to consume said topic. So this is what's gonna consume the topic. And you can see in the same idea it's um using a sync. So it's sending to an event viewer. We have an event viewer. If you actually want to see the code, we have the code right here. It simply just displays whatever comes to it through that post. Uh And also I want to point out one more thing. So we just create a topic on our cluster called Finance. Simple enough. All right. So let's see what we got here. All right. So I actually had these running a while ago, but let me go ahead and delete them so you can see it fresh. So we're gonna leave Kafka producer, I just create use because as you can see and what you'll see in the read me is that you're able to replace it with your project ID. So when pushing up the code, I just created a separate file called use and get ignored it. So in case you're curious, no, no data, we're gonna just delete these files really easily. All right, simple as that. So let's go ahead and send the producer first. Basically with the way sync binding works is the sync has to be set up before the source is set up. So essentially there has to be something catching the data before you send, you create the thing that's sending the data. So let's go ahead and do that. So our source is called currency source containers creating. So I wrote some code in to the currency source that's also going to output stuff. So that way we can see. OK. Well, this is the uh currency that's coming out. So let's do it this way. All right. And let's take a look here or I'm sorry, it's actually a producer. It's all right. If we see nothing in currency source, that means that it's working. All right. So here is our currency exchange rate. Now, ideally, what we're gonna do is we are going to set up our event viewer. Now, this is just a simple kind of proof of concept. If you will, uh, you know, if this is a real app, it might very well be something that is, you know, uh you know, uh displaying like a, a front end or something to that effect. Maybe you have a machine learning pod that is running uh data or you know, running some kind of process against the data that's coming in. There's various things that we can do here. See. Uh let me do user container. Oh, well, look at that in real time too because if we go back here to producer, we should probably see a new 1715. All right. Yeah. So it's pretty, pretty neat. So it takes, it's gonna take a second because I have a low level container. But as we can come up here into Gke and Google cloud console. So if you look through my example and uh we'll, we'll put it in the, in the notes where you can get my github and you can test around this and whatnot. We have a, a secret alpha vantage key that does API call. We're able to pull that code, we're able to run that, we're able to pretty much do everything that we need to do. And in real time, we're able to stream some uh financial application. Now, why is this important? If you actually look at what we have here, we have, we have stood up these clusters right here using nothing but code. And as you can see, this is just standard type script. This isn't a special uh type of language that we need to use to create a create a definition. This is standard code I can put into my standard pipeline. And on top of that, we have more code. And with this more code, we are able to actually write the application. All I needed to do to deploy it was create a simple Docker file. And then as you could see, all I did was using these YAML files was able to push the application as you could see very simple YAML file. All I have to do is give it a name kind of declare with the kind. And then also say where the image is hosted simple enough. Once that happens, you know, we have the eventing portion. As you can see here, I didn't as the developer. Now, this might be a little bit of a different example but uh from the consumer per per spark uh excuse me from the consumer perspective. But as an event source, there's very little actual connecting to anything here So my event viewer is just egress is just ingress the information as we can see here rather than connecting to anything specific. It is actually K native and the K native operators uh K native components that are connecting the KK native eventing. So from a developer perspective, I am able to from the ground up, build the entire application as code as true code, not a third party thing that it's hard to maintain uh some special language. It is all simple code that I use every single day. I was able to literally be a full stack developer. I built the infrastructure, I built my code, I deployed it. I didn't have to do a lot of configuration and it's all running on top of Kubernetes at the end of the day. This is as you can see here, this is a Kubernetes cluster at the end of the day. So this is all very, very just I would say the future of development of cloud native full stack development and it's all thanks to Pulumi and K native and Kubernetes. So it wasn't that easy. I was able to stage my environment, build my code, deploy it and use it all with a code layer. I didn't actually have to do much at all. From an infrastructure part portion, I was able to just use the languages I use on the daily. So that was standing up a serverless platform. I really hope you enjoy it I encourage you to tweet me. I am usually pretty responsive on Twitter. Uh So yeah, please message me. You can also check out my linkedin. Please also check out serverless eventing dot com and also check out what Google cloud has to offer and we uh we work with all the time. So I recommend giving us all the talk. Thank you and have a great day.
---
