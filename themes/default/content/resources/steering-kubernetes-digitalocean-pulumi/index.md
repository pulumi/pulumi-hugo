---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Steering Kubernetes on DigitalOcean with Pulumi"
title: "Steering Kubernetes on DigitalOcean with Pulumi"
meta_desc: |
    Learn how to get started setting up DOKS using Pulumi and TypeScript.
url_slug: steering-kubernetes-digitalocean-pulumi
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Steering Kubernetes on DigitalOcean with Pulumi"
  description: |
    Learn how to get started setting up DOKS using Pulumi and TypeScript.  This tutorial shows you how to setup Kubernetes on DigitalOcean using Infrastructure as Code with Pulumi and the methods work on all major cloud providers and your favorite programming languages including Python, TypeScript, JavaScript, Golang and C#.  GET STARTED: https://pulumi.com/start
  sortable_date: 2020-07-17T21:07:33Z
  youtube_url: https://www.youtube.com/embed/8xP7erXx4-Y
transcript: |
    Hello, everyone and welcome to today's Digital Ocean Tech Talk. My name is Mike Metre and I'm an engineer at Pulumi. In today's talk, you're gonna learn how to manage infrastructure, manage community clusters and workloads in those clusters using programming languages on Digital Ocean. Before we get started, a couple of things to know first, this talk is being recorded. So no worry if you're not watching it live, you can always refer to it after because we're going to be sharing the video link in an email and the video will also be posted at digital Oceans, youtube channel as well as Digital Oceans community Tech talks page. Also in go to webinar, there's an option to drop questions in the questions box. So if you have any questions throughout the presentation, feel free to drop them in there and we'll make sure we leave time at the end of the presentation to get to as many questions as we possibly can. No worries. If we don't get the response live, we'll make sure to get your response soon enough. So let's begin. So steering communities on Digital Ocean, what does this mean? How do we actually work with communities clusters. How do we work with infrastructure and how can we leverage programming languages to improve our workloads and manage our stacks with more efficiency. Again, my name is Mike Metro. I'm at Pulumi. You can follow us on Twitter at Pulumi Corp or you can follow me on Twitter at Mike Metro to get things started. I want to get a gauge of the room. Uh Many of you are visiting us remotely and digitally and I would like to know if possible what your experience level with communities is. So I can gauge the talk appropriately to make sure that everyone can learn something from this talk. So if you'd be so kind and partici just pull up your cell phone or pull out a browser tab and just visit the URL at the top pull EV dot com forward slash M Metro 075 and just answer the simple question. How long have you worked with communities? That'll help me gauge how I can appropriately fit the talk to. Let everyone learn something. We'll leave it in about a minute or so. So folks can, can chime in but please uh take this time to, to do this and I promise this is the only work I will make you do this today. I'll put the feedback results here live for those folks who are actually participating. Not everyone jumped at once. OK, great. We have some polls coming in. Give it a couple more seconds for folks to, to get familiar with the page again. It's pole ev dot com forward slash Mike Metro 075 and it's just one simple question. Ok. Wow. So uh the majority of you are brand new to Cabrini. So welcome, thanks for, thanks for coming out and joining us and, and learning more about how you can go with Cabret and into the ocean. Uh It seems we definitely have some folks who, who have been experienced and seasoned folks working with Cabret. So I promise you'll learn something too. So need not worry. Great. Thanks for your participation. That's all I need from you. So let's begin. What can you expect in today's talk? We're gonna review what Pulumi is and how it works. Then we're gonna show Pulumi in action by deploying a couple of droplet virtual machines on Digital Ocean using the Python programming language. Then we'll visit how you can do production Verne's architecture and how Pulumi works with that Cotis model. We'll show how you can deploy KTIS clusters, whether they be managed or self managed and you can deploy workloads into those clusters and we'll do that using the typescript language. And then we'll show another demo of how you can do immigration testing using the go language on the demos that we'll be walking through throughout this talk and then we'll leave time at the end for Q and A. So you'll learn how to manage infrastructure, you'll learn how to work with, converted these clusters with workloads and leverage programming languages to really manage the infrastructure in a better way than hopefully you've been doing it today. So what is Pulumi? Pulumi is modern infrastructure S code? What does that mean? It is a tool that allows you to provision and manage cloud native resources using your favorite programming languages. Pulumi supports languages, javascript, typescript, Python go and the dot net family. That means you can use these languages to provision all resources that you can imagine for public copy writers or on prime situations. So here's an example on the right, here's a snippet of what it would look like to create a Digital Ocean Domain using the type language and Pulumi libraries. So because I'm using programming languages, I'm able to use my usual ID E flow. I can import the SDK. In this case, the Pulumi Digital Ocean package that I'm pulling from the NPN repository. Since I'm using typescript, I can define my digital Ocean Domain, give it a name, give it an IP address and then I can optionally export properties on that domain if I wish to share that resource with other programs or other users. So immediately I have the ability to have an ID E to help me to compile against a known spec, to do checking of, of spec matching, to do linking, to do uh ID integration, to jump the documentation. And more importantly to do testing right. So this allows me to leverage programming languages for this very appropriate text. So why are programing languages so important? Well, the current state of art of tools today and infrastructure code are ones like chef and puppet and answerable and terri form orchestration templates for that matter. And these tools have served folks very, very well, but they leave a couple of gaps as you begin to grow. A bucket of those gaps is essentially some of these tools will directly modify state on a machine as opposed to modern flying state and a game system like an API when you modify state directly on a machine, that doesn't prevent anybody else from making the same changes in that machine. And so you don't really have a good understanding of what that machine should look like and how it should function. Whereas an API system, because it's a program, you can manipulate a state appropriately and you can set it to the configurations that you need. And if folks are to deviate that state, you have a state of the world as we described in our program to say this is what the state of the world should be. So if I had say one virtual machine and someone went on and created two more additionally, uh virtual machines, the next time I can refresh and recon reconcile all of these changes and make sure there's only one virtual machine because that's what I've been describing in my program because it's code, I can leverage the same package managers and sharing functionality that I have today. So if I'm using typescript, I'm using M PM. If I'm using uh Python, I'm using pit. If I'm using go, I'm using the gold modules from github or any other version control system that you use. And if I'm using dot net, I can use the dot net, the dependency packages like new. So with this code, with this code, you will allow yourself to preview these changes before they happen because Pulumi can see each property at its at its most finite states and see what's changing and whether it can change or not because it's code, you have a full audit of who changed. What when if you integrate this with your get offs pipeline, your C I CD pipelines, you can preview these changes, you can approve these changes and you can roll these changes out has in integration with secrets management as a first class resource into the program because it allows you to not only maintain the sensitivity of information like database secrets in your stack, it allows you to make sure the whole stack is protected as you see fit. But Pulumi isn't just about provisioning cloud native infrastructure like V MS and block storage and virtual networks. It's also has the ability to test your infrastructure. So you can use a language like go to test and validate through unit testing through integration testing. The stacks that you're, you're provisioning are functioning in the way that you expect them to. And most importantly, Pulumi SDKS are open source. We're a PQ two based and we have a great size and console that works with our CO I tool for both individuals and teams and for teams, we have the ability for you to enforce and optimize uh organizational policies that everyone must adhere to for your infrastructure and how they manage their infrastructure. But Pulumi isn't just about cloud native infrastructure as code. It's about Cobert as code too. What we mean here is that you can use Pulumi to not only provision the infrastructure such as V MS and virtual networks, you can also use Pulumi to provision, manage clusters like the ones that Digital Ocean offers or the raw compute if you want to build the cluster yourself. So you can use languages to manage the cluster. But you can also use the languages of typescript, javascript, Python go and dot net to provision the Kubernetes API resources that you may be familiar working with such as a C's deployment Abertis service, a big map because what we do is we take that same API just like we do with all the cloud providers and we expose it as a library SDK as noted above. And once we expose that as an SDK, you have a first class construct in the language that can guide you against a given spec that we can compile against that. We can test that we can readily build out without seeing any, any obvious changes. Because the compiler will tell us if something's wrong. If you've used tools in the past, you've noticed that when you configure things like Yaml and Jason Typos and errors aren't discovered until deployment time or much later. And they tend to be fairly, fairly nuanced. So languages allow you to bubble up that much sooner and get a better handle of it. And because you have type systems in some of these languages, you can enforce that the spec that you're working with is compatible as the provider expects it to be. So here's an example of a snippet of how you can use typescript to create a community deployment and a community service. So I'll, I'll review what the Pulumi config system is, but I can import the boom you config that allows me to parameterize the the settings of this particular program. I can create a provider which is just a wrapper around the credentials to access my cluster in this place. Confia if you've worked with CNES before, once I have these credentials, I want to separate them out into a provider because I want to have the resources be independent of the credentials that created them. So that way if I need to rotate these credentials or, or simply alter them, I can make sure that the resources are stood up with the appropriate credentials that I want them to be so I can pass that provider into, into this object to create a new name space. I can create a new pod for engine X that I can deploy into that name space. I can wrap it in deployment and say I want two copies of engine X running at all times and I want a public load balancer. I want a public load bouncer that allows me to expose these virtual machines in a public way that gives me an end point that anyone can reach. And because it's code with COTIS, I can not only deploy the cos apr resources that the API system supports. You can also deploy helm charts directly. You can deploy YAML manifest. If you still have those, you can inject site cards like envoy or, or prometheus depending on what it is you want to config. And because we are AC I tool, we have many integration points with our great C I CD partners because we are a cli tool and no one's workflow is the same, no developer, no operator to work in the same fashion. We have many integration points to support your work flows. We support various source code integration providers with companies like github and bit bucket and GIT lab. As we said earlier, you can use the languages javascript, typescript, Python go and dot net with Pulumi to author and manage your infrastructure. Your applications can remain in whatever language they're already in, you can just support them over. This is essentially just talking about the infrastructure aspects of it to work with the code base depending on the language of your choice or the platform of your choice. You can use package managers that you're already familiar working with. So if you're in the node family, you're using M PM, if you're in the Python family, you're using PP. Similarly, we have integration with other C IC partners such as Spinnaker Circle C I github and C I. We support many different environments, both public providers and private and we have the ability to integrate with communities in a very first class way on the bottom, you'll see a couple of screenshots of what a console looks like. When you work with blooming, you can get a rich preview directly in the pull request embedded. So you can approve or deny whether these changes can actually be rolled out in the middle. You see a full audit timeline of who changed what win on what commit and what branch and did that succeed or fail. And then you can have a laundry list of resources that are being provisioned in this program. So you can do a fine grain detail of the cluster and the resources that I'm creating and see all the properties in a very consumable format. How does the plume cli work? So first off you author a program such as creating a digital ocean domain in the language of your choice. Say Python, the Pulumi cli will parse that all of this is happening in your client. We don't see any of this uh on the Pulumi side of things. Once it processes your program, it'll invoke the run time that you've chosen. So if you're using Python, it will invoke Python. And once you describe those resources, it'll go off and directly make an API request to the provider of your choice. In this case, Digital Ocean. So it'll say create me a new domain in Digital Ocean and it'll make that api request directly. There is no interchange format, there's no conversion to Jason, there's no conversion to Yaml. Your program is the desired state. What you write in that program is what it will be pro provisions and that's what it will maintain as far as provision goes. So you can work safely knowing that when you create your infrastructure, what we are doing is actually building you out a graph of the different components that your infrastructure has. And it's basically creating a sequence of the order that they should be stood up. So that way they can all be created appropriately. This never leaves your client machine, but this graph gets openly stored as a state file. And this file is what says this is what my stack should look like. We do some check pointing by default in our, that's free for individuals and it has different tiers for teams and in that size, you can checkpoint that file, you can do concurrency walking. So if you're on a distributed team working on a, on a similar stack, you're not stumping over each other's changes. We, you have integration with things like identity and single sign on. And we have this ability to integrate with configuration systems and secret systems. So you can leverage those in your stacks as well. A Pulumi project is no more than a directory that has a Pulumi program, a meta data file. So the Pulumi cli knows it's the ploy program and then the dependencies that your program needs such as the Pulumi visit Ocean Library, you can take the Pulumi program and instantiate different copies of it. What that means is I can reuse the same infrastructure over and over again, but I can change parameters depending on the environment that I'm running in or depending on the branch that I'm working in. Such as if I have three different phases of development, staging and prod, I can have a different number of, of V MS that I want to say. Schedule, schedule one VM for a developer, two V MS for staging and three V MS for product, I can configure that using the same program without having to copy and paste this over and over again. So stacks give us a great way to instantiate a given program and change the parameters as we see fit in Pulumi stacks can reference other stacks. So you can imagine if there's two Pulumi programs if I am the identity team. Uh and my company and I wrote a text program on the left. And my colleague is an application developer writing his infrastructure such as his V MS in Python. My colleague can reference all the outputs that I want to make available for them such as say the idea of the DPC, they have to work in or the API token they have to use and they can mix and match the pieces that they need. But you can segment these responsibilities by the organization by the roles and by really the function of what folks should and shouldn't be doing. So this gives you a great way to break up your infrastructure and make it more compos depending on how you manage your infrastructure and how you organize your teams. But Pulumi programs are really all encompassing the provider allows you to instantiate the infrastructure and Pulumi can be scripted to write anything that you want. So you can create a Pulumi program that has V MS or object storage or block storage or you provisioning a cluster uh or a virtual network. And all that essentially will be a set of resources that we map out in order and create in order to make sure that we're meeting the infrastructure that you've programmed. The output of that is this graph that we store as a state file and that state file. Is what regulates what the view of the world should be for your stack. So if anyone fidgets with that, we can refresh and get the changes and try to enforce the state to make sure we always have the state that we expect. Let's jump into a demo of how Pulumi works in action by using droplets under the ocean. So I'm gonna switch my screen real quick. So here we have on the left a Pulumi program that's written in Python and on the right, on the right is gonna be our our ability to control this program through Poli. So the left is a Python program that describes the following. We're gonna deploy a stack that has three droplet virtual machines and these virtual machines will be put behind a low balancer that we will publicly expose. So if you've written Python, this is regular Python. I have my ID E I have the ability to have my compiler yell at me if I for example, am not following the proper casing that I expect. But when I change things like like essentially what am I doing? What am I doing here? I can delete states. And I can say if I have a typo for a variable that doesn't exist, I can have my ID E tell me, hey, this change is not gonna work. So I wanna make sure that at compile time I fix this. So that way the deployment actually functions. So languages allow me to, to catch these changes early on and to improve the workflow that I'm offering these programs in. So I'll set up account and say I'm gonna set up three virtual machines. I'm gonna reach into the config system, fool me and get the region. What does that mean? Let's switch over to the right. So I have the program and remember we create stacks or instances of this program. So the first step I'll do is do a Pulumi stack in it. I'll give it a name DEV. And because it's Python, I have a requirement dot text, I'm gonna install those requirements in my virtual environment. Great. And I'm gonna do uh some configuration settings such as give it the parameters that I want to set this particular program. An example of that is the region. So let's say I want to deploy this program of virtual droplets into the New York Center, the New York City Data Center that Digital Ocean has. Similarly, I will do. So I'm more config to set up my Ocean token. So I can provision in my account. As you see, I can set secrets on configuration values that mask this value and actually encrypt it in the states whether I use uh encryption that a site text by default and me or I given a key management system a key that I can use to lock that if I need to. So this configuration management system allows me to tap in in the program and get that value accordingly so I can use it in my program with the region pulled out from the Can fix system. I said I'm gonna create a user data script that allows me to update the packages on boots and install engine. And we're gonna throw these three copies into a for loop. So I save for uh up to three droplets. We're gonna create three virtual machines of type ubuntu with half a gig of Ram in this particular region. And with these tags, once that is provisioned, I'm going to create a load balancer that that sits on top of these V MS and round robins between each of the virtual machines while exposing a public load balancer. So let's see what this looks like in practice. So I can see that with Pulumi, I can do a preview to see what does my changes look like before I deploy them. I can see a great, I'm gonna create nine different resources. Some of these are droplets, some of these are tags and then get load balancer. I can get a bit more rich on the if I have the flag and I can see the actual details of these resources and their properties. So for example, I can see that this drop that is being stood up within a 2 20 04 image in New York City with half a giga Ram and this particular use data. Great So if that all checks out you, I can either approve this or deny it if you were in a, in a for example, and if everything looks good, I can just run to plu me up to deploy those changes. So I'll say yes, deploy the changes. This will take about a minute or so. But while we do that, let's kind of go back here and explore what it is that we're building again. So we are constructing three different virtual machines. I've been able to configure all these parameters as I see appropriately, I can set some of this to be uh configured in the configured system of gluing if I want to template this out across many different programs, and I have the ability to leverage languages to give me things like warnings. When I say, hey, this user data doesn't have been formed to upper case naming style. So if I say I'm going to write this as it should be for my winter, those errors should go away and they do. And so now our program looks completely fine and that's the beauty of using programming languages or, or per se using tools like that have Yao or Jason or or domain list of languages because at some point, the functionality is limiting as far as what you can and can't do. And we already have all of these problems solved for us. But with programming languages, because we have ID ES, we have winters we have checking and so we should be able to leverage those tools, not just for applications but for our infrastructure as well. All right, great. Our deployment on the right has finished. So let's actually go and visit this URL. Let me share my desktop uh to get a little bit more of a bigger view. And in this screen, we're going to visit the page. So sure enough, if I hit that end point, I'm getting engine X. Great. So the cool thing that that folks can see is that I deployed these changes. Now, if I want to say, make a couple more changes and say spin up one more droplet, I can do a Pulumi preview and see that. It's fun to say you want to stand up one more virtual machine. Great. So it's gonna create that along with this tag. So if I do a Pulumi refresh, remember a Pulumi refresh is fetching the states from Digital Ocean. So once I created the virtual machines, there may be metadata or time stamps or information that I don't know about before it's been deployed that gets added after the fact, a Pulumi refresh allows us to reconcile this state between what I have in my program and what exists in Digital Ocean. So when I do a pre refresh, it'll tell me, hey, there's some information here that's been updated by your programs, local state does I have or what are those details? I can see that I've never specified in a stage key and that the total resource count here I have is uh three replicas for my droplets. So I'll say yes, refresh these changes. Can I do a Pulumi preview? I can see that I have the ability to uh create that and I'm gonna do it, blew me up. Yes. And it will go off and change that. So once that gets stood up, another interesting property to note is that you can mangle this however you see fit, but you are ultimately going to dictate what gets into the state of the world by what's written in this program. So just as we change the parameters here, anything you change on Pulumi as far as the code goes is going to be reflected the next time you roll an update so soon enough, this will finish. And we have now why I expect Pulumi stack? I now see, I have very, I have four virtual machines as I expect them. Awesome. I'm gonna destroy this and move on to the rest of their demo. So with that kind of setting the stage, right, we now want to talk about communities. So communities is a very multilayered approach. As far as how you want to work with communities, there's different layers to go about it. And the way Pulumi works with communities is by offering many different library packages that allow you to encapsulate the figure and manage each of these layers at the very bottom, you bottom two rows, you essentially have the core infrastructure providers that give you the resources and infrastructure to provision things like virtual teams, virtual networks, storage and keys. Most of these providers have a managed community offering that allows you to actually deploy a community cluster, manage that cluster if you want to do it yourself. And then once you have a cluster up and running, you're left with an empty kind of vanilla communities cluster. And now the work really begins for you to turn that into something that you want to use to install the services for the cluster and applications that you may need. And then finally deploy the applications on top as denoted by the markers on the left and right. You can see the different SDK packages that Pulumi makes available across all of our languages, typescript, javascript, Python and go in dot net that allow you to work with the infrastructure side of the things as well as the application forces of committees. So with communities in particular, you can create communities api resources using the Pulumi community library and the community's library. Let's show a demo of how we can use, create clusters in text script. So we'll switch to our second screen here. And what I'm gonna do is I'm gonna kick this off. I'm gonna uh as I walk you through the example, I'm gonna, gonna deploy this, you're gonna, we're gonna deploy a cluster and we're going to just leave this running in the background. And for the sake of time, I'm gonna run this test as well. That'll get gonna suck. So on our left, we have a similar program this time, we have it in text script. Remember we were doing Python before? So now we're switching contact and we're using text script to author a Cober cluster on digital Ocean. So since I'm using typescript, I'm gonna pull my packages from M PM. These packages are Digital Ocean to configure Digital Ocean Resources. This is COTIS to deploy COTIS resources into that cluster once it's up and some facility functions that allow me to work with my cluster uh in an easier way. So I can leverage the can fix system in a couple of different ways. Here, I can say, hey, because I want to uh deploy a coin cluster with a given API token for those of you who don't know courage clusters on the ocean have the ability to provision a API token for you on your behalf. I decided I wanted to control this API token myself since I can revoke that token whenever I see fit. And because it allows me to have better control of that token if something were to change, change, so I'll pull that token from the convict system and also use it to get some defaults. So a puer is essentially a control plane that the provider is running for you and a set of nodes that deploy your workloads. And these nodes, I can say either get a configuration number that the user has specified or if not default to one copy. Similarly. How many copies of next do you want running on this cluster? If the user does not specify I can default to one, but we can already see how languages here are beneficial because I can not only do this sort of logic, I can see if I do like an A button and F six, I can see I can see the whole type of this actual value of this variable. And I can make sure that at deployment in time, these specs are interoperable because the types match similarly if I want to, I can jump into defining a cluster in the ocean by saying here use the region that the user has specified. We're gonna deploy 1.17 of cnet and we're gonna create a node pool that's attached to this cluster. We're using a droplet that has two BC P US and two gigs of ram with the count that we specified of one node. Once that cluster comes up, we can actually pull information out of that cluster such in its name and the Q and fig that comes created with it. So we can access the cluster. But because I have languages, I can do things if I can jumping into the documentation. So I can see that if I don't know what I'm building here. I can see that the arguments to create a cluster in Digital Ocean are encompassed in this type called cluster arts that takes a name, a note pool region tags. And I have all this documentation to refer to, to not only know how I can work with this in my ID E but I can have types that validate that the variable variables are holding the values that they should be having. So I can leverage languages and I Ds far better than I can or Jason for that matter, I can go back to my code and continue to see that I'm going to provision the cluster. And then once the clusters comes up, what we're gonna do is we're gonna create our own cube config file using the API token. So again, because Digital Ocean has this API token by default that can provision with clusters. I wanted to take the extra measure of making sure that I provided my own token and then I can have the cu config file that uses that token to access the cluster. I'll pass that into what's known as a community provider. Again, this provider is this notion of it's the ability to, to decouple your resource from the credentials that instantiated them. So if you need to swap those credentials out or if you rather do it with another user, you have that leverage. So with that provider, which is essentially just a wrapper around the Q config that we created above. Again, we can reference objects here. So that's the other benefit of using languages. We're not referencing strings that are hard coded in like JSON or YAML or, or domain specific languages. We have symbolic objects that we can reference because it is a programming language so we can reference these objects, we can access properties of those objects and we can manipulate it as we see it fit because it's just code with the cluster finally deployed. What we're gonna do next is create a deployment in which is just a speck of a set of given pods. And these pods are going to essentially spin up an engine X application with the number of replicas that we've given it. It's gonna select one of subset of labels that we've provided. And once the deployment is up and running, we're going to attach a community service and this community service is going to expose that internet deployment to the public world using a publicly typed load balancer. We'll say that on this load balancer, we're also going to target the same labels that we're using to target in the deployment. So we know we're selecting a particular set of workloads. And with that, we can say open up port 80. So that way when you provision the infrastructure and provision the load balancer, you can forward port 80 onto the engine S app itself because these are resources I can now reach in and get values that I may want. Such as I can reach into the service that in for the tension X app, I can retrieve it status, reach to a slow balancer and pull out the IP that gives me the ability to have ingress into the flow balancer. So I can take that public IP and I can do things like create a vanity URL where I can interpolate some string with the prefix that I need with the IP. And I can create that and expose it for folks who want to consume that in either other toy programs or other users who want to actually reference this or access those end points uh if they want. So we'll give this a couple of more seconds because this should be finishing up soon enough. But the one thing that I want to to call out here is you have the ability to describe infrastructure in a more robust way as your infrastructure scales, as your complexity scales, this becomes unwieldy if you don't have programming languages because ultimately everyone's workload is different, everyone's requirements and standards are different to run these applications in production. So ultimately, you need something like a complete uh complete programming language to encapsulate the expressiveness that you want to, to encode as this finishes wrapping up on the right. I'm gonna switch context just for a split second and show you uh what it looks like once we are actually up. So on the right, it'll be done just shortly. I can show you that if I check out what this is actually doing for me, I can see that in this uh provider. If I do only staff, I can see that my stack is still being provisioned. It started six minutes ago, I can see resources. I can view this on my console. So in the mi console, I can view what resources are being stood up. So here I have a full view of the console of who owns what, as far as the metadata for this project, what activity has been taking place? In this case, I can see that a deployment hasn't stood up and I can see that the information there is is still refreshing because we're rolling out the update. The timeline says here's the given commit on the given branch. And as they start to become more fleshed out, I can see these provider resources become more flourished uh in the stack once the deployment actually occurs. So this will keep going. And while that's going, I'm gonna switch back to the slides and talk to how you can test your infrastructure in polling testing is is a key fact that that many people don't really think about in provisioning and managing infrastructure. Most folks pretty much stop at how do I get things up uh readily and how do I actually work with it? But it's about policies. It's about making sure that you can test this infrastructure that you can readily work with it. And one of the cool things that blooming offers you is the ability to, to do just that. So I'm going to show you what it looks like to do something a little bit more advanced before I show you a test and Pulumi. So we have a great tutorial that our friends at Digital Ocean put together that is uh located right here in this tutorial that allows you to take the recommended steps to secure your Digital Ocean uh cluster by opening up your cluster to other users by creating client certificates. Once you create client certificates for like a group of users, like say developers, you are allowing yourself to uh use credentials to rectify and validate that you can actually authenticate into the cluster. But as you can see the documentation, we have to do some, some manual work around creating the certificates uh invoking those certificates, passing those certificates to communities to approve and give us a client cert for the request that we've issued it. And once that's up, we can actually set up then the access authorization aspects in communities because accessing the cluster is, is the authentication piece. The next step is the authorization piece. What can the developer users actually do in these clusters? And that is defining different settings through our back role based access control on the properties that they can use in cities what they can't use and how they can use it. So, what we've done is we've taken this tutorial and we've codified into a reputable program that you all can use. Uh, with, uh, by the end of this talk, I'll share the link but you have the ability to take this full tutorial and never really have to worry about it again because we've, we've been able to codify that in, in a program using Pulumi. So what that means is here, I have changed now, this update to say I'm gonna also create a new uh client certificate request with a given key. I just generate this using open SSL. And I'm gonna create a client search in Cotti that will be approved uh by by the cluster for me to use my developers. I can jump into that code and see that what it's actually doing is reading a couple of files forming this certificate, this client certificate request, issuing that certificate request to Cober Netti. And once it's done, it's been retrieved back and improved, read it to a local file so I can consume it. That gives me the access credentials for the clients. I'm going to similarly wrap that in a provider so I can go off and use that provider and now deploy something as this developer group using the client certificates. This allows me to create a name space as a developer. See because I can create a namespace, sorry as an admin and then the developer can actually create the uh resources after we've given them roles and access control into that name space. So if I go to that, I can see that this person particular role is only going to be allowed to use the following resources. Config maps pods, secrets deployments and they can only do the following verbs, get list, watch, create patch update, et cetera. And so that allows you to gate what they can do, how they can do it and how much freedom they have to, to work within the cluster. This gives us more security, but it gives limited privilege. And similarly, it's not just about reducing the scope at which uh users can operate, it's also about enforcing things like a quota making sure that they have boundaries to how many compute resources they can use, how many compute resources their containers can actually take up and you can even enforce things like limits and ranges that allow you to actually enforce these limits on a hard way. So that way they don't get scheduled if you know, you don't want uh applications that are, that are heavy in consumption of resources. Once that is up, we'll deploy an application as a developer that allows us to truly manage this in a, in a programming first product optic kind of way. So here you see, I have this new class that I called a demo app in this demo app. What I actually have is a class that I essentially is an extension of what we call a component resource. This is a collection of resources that are managed together when you want to co locate the responsibility of these applications. So what's a good example of this? I want to create an application that I have locally, which is a node app. This note app looks like the following. It is a simple server in javascript that says listen on 4 80 expose uh the root path to this index AC ML which is just simply a hello world file. And once that's running, make sure that that container can actually serve that response in that I can then use the latest feature. For example, I did the ocean release which is a container registry to provision a registry and a single line of code. That's the power of program languages. I can create resources like this very, very articulately and I can even encompass them like I'm doing here in the demo application to really minimize the amount of work I need to think about if these things aren't supposed to be managed together. So I just like I have a package for me to manage the ocean and I have a package to manage docker containers. So I can do a Docker image and do the docker file since I have a Docker file here for this app that simply just says, hey, give me a node run time set up some of the directories, copy the application that I just talked about for the whole world over into that container, run N PM, install it to install the dependencies and then actually run the, the Note app and serve it in that I can take that doctor file from Pulumi, build it in my program and automatically push it up to the registry that we just created up here. So in 10 lines of code, I created registry and I built my image and deployed it into that container registry. Similarly, if I'm working with computers, I can create configuration maps secrets. Uh I can even pull in uh all sorts of configurations such as being able to describe the pod and wrap that pod in deployment using less code. As you see here, I'm using this new abstraction that Pulumi offers calls X and this is essentially a subset of the code you need to write to actually work with communities in that you can see that if you want the full community effect, we don't create new nouns, we don't create new verbs, we expose the full community's api for you and allow you to, to truly define this as you see fit. But where we think it makes sense, we want to reduce the boilerplate, you need to author and to create and to manage all of these. So what happens is that you can create all these resources for you um by still being able to tap into the full API spec so I can create a persistent volume thing just as I expected the secret. If you're looking at this and you've worked with before, if you have seen anything with before, a lot of this should look familiar. Right. We're just doing it in the language of our choice. So we'll start up a deployment that deployment can be as, as verbose as we need it to be. But see how, how, how terse it is, as far as how much information the require process is set up. It's so much simpler if we could just reduce that voter plate and only use the parts that we need. And here we've done it in a couple of uh stanzas here, we've essentially replicated the same setup that we're identifying here using the full API spec that allows you to not only manage your infrastructure and your clusters, but it allows you to start calculating and managing these clusters as uh artifacts that really are managed on their own. We're wrapping up on time. So I wanted to show you what it looks like to test on Pulumi using the Go testing framework. Here, we have a great slide that shows you that the examples that we just opened up. For example, running a droplet in Python, running clusters with developer authentication using client search and some hardened security rules. We can test that using the Pulumi Go integration framework to validate that these stacks are coming up as we expect them to. So here is a go test if you worked with go test before it should be fairly straightforward. This is a go test file. I will use the same framework I I'm used to working with here. I set up a couple of options that I've imported from the Pulumi integration uh module. It'll say, hey, create this load balancer with a given set of configuration settings. And on after it's been stood up, make sure that the uh body that we extract from that endpoint matches NX as we saw earlier. It says a welcome to NX. So we can parse that, that file and assert that our stacks are coming up as we see. Uh we expect them to and our applications are functional as we expect them to. So that's the droplets in Python, we can do the exact same thing to test clusters in uh including using the same framework. And in this case, we're using the ability to test this stack that has community cluster with lockdown, developer users with lockdown uh role uh uh properties. As far as what resources they can use a quota, a limit to, to enforce really secure standards, harding standards. Because once you start working with communities, it's not just about getting your apps into these clusters, it's about sharing these apps, whether it be with other team members with other users uh or with other applications that you yourself are offering. So you want to make sure that these boundaries are are set and you can test this uh similarly by deploying and putting it to the stack program that we have here uh that we just went over and verifying that these end points are actually returning the whole world that we were referring to in our previous Note app. We are coming up on time. So I wanna open it up uh for questions and I believe our friend Samantha should be joining us any seconds. Thank you so much, Mike. Great job. And thank you everyone for asking some questions so far. If you have more questions, please type them in the questions box and we'll answer as many of them as we can buy. So uh one person wrote Mike, no question but some praise. Awesome work on making the naming and API match the CNET spec while also adding some nice short hands. Cool stuff. Thanks a lot. All right. Oh, I'll drive, I'll, I'll dive straight into it. Does Pulumi handle cr ds uh custom resource definitions yet they're rapidly growing part of puberty and are not well supported by many systems. Great question. So for those who are familiar cds or custom resource definitions are custom API types and com communities. So com has an API type like deployments service, config maps secrets, those are known API types, custom resource definitions are custom types that I want to encapsulate. Say like if I want to manage SQL by myself, I want to cough up operator. If I want the cert manager, these are all applications that have their own custom types. Yes. Pulumi supports custom resource definitions. So right now, we actually have some great work that we're working through to harden these CRD types because as you may be aware, if you work with C rds, metal cds are both the same that all of the A PS are managed the same. So we want you can definitely author and create Cr Ds and the instantiation of those custom resources in Pulumi. But we're gonna add more structure to harden the spec since all these custom resource definitions have custom specs, we're gonna be able to bubble up that spec into a first class type in the language of your choice. So that work is ongoing. But yes, we support Cr Ds. Great question. Great. Does Pulumi support or plan to support Java? Great question. We've definitely had questions for, for that. We, we have uh we have some ideas on that front. Uh Nothing that I can necessarily talk about at this moment, but we have gotten that question as well as other languages that that folks support. So thanks for that question. We, we, we hope we can address that soon enough. What's your recommendation to avoid rebuilding darker images between different stacks, which would happen with the N A native approach that creates VPC registry and cluster in one stack. Yeah, great question. So the the ultimate uh baseline for that is going to be, do you want to build it in Pulumi? Do you want this to be built centrally somewhere else? Especially if it's being shared across stacks. And the decision really kind of depends on, on how your architecture flows. For the example that I showed here, it makes sense since I'm essentially operating on a single stack, I'm a single user and it's probably not going to be shared. But as far as cashing goes, that's gonna be leveraged on the local machine. Since all that is doing is essentially calling out the dock or CL I and doing that locally. If you're looking to use this a cross stacks and building it may be an issue, then it's maybe something you should think about centralizing either uh in a central stack that does the building for say children's stacks or something more like in your CITD system that is more centralized but touches all of the programs that you may want to work with. Cool. Can you create your own references for services that you do not offer like zero tier, for example? Yes. So we actually support dozens upon dozens of providers uh and you can visit. So if you have a couple of helpful links to get you started on, on Kubernetes, on, on Pulumi and all the code that I listed is in this third bullet in the repo So please check that out. But yes, we have the notion to uh essentially take a provider uh that may exist. So you can think of Pulumi as this an API of many APIS. So as long as there's a crud api interface, the work to expose it in Pulumi as a library is pretty minimal. And we can usually work with you to make that happen. So you can either do that yourself to make it a more first class resource or we have this notion of dynamic providers, which are essentially kind of this cross between not a fully embedded and fully embedded provider and not quite something that's being scripted. It's somewhere in the middle where you can dynamically out run time, say create a uh a credit interface depending on the provider of your choice. And in this case, if you have an API like the the zero tier, you're mentioning, you can call out to the API and issue the commands that you see fit. So there's a couple of ways to go about it. Absolutely. What's the support for running Pulumi in an unmanaged fashion like towards the lines of get ups from something like AC I CD system? Yeah, great question. So a lot of the cli commands that you saw me use like Pulumi uh preview Pulumi refresh Pulumi update. That is really the domain that you're gonna be living in when working with Pulumi. Similarly, your C I CD systems will do the same. We actually have a docker container and, and the specialized docker integration containers for things like github and, and uh we're looking at circle C I as well that allow us to drive uh the Pulumi cli from your C I CD. So you can uh preview these changes. See those changes get posted through a webhook in the pull request. So you can say, yep, thumbs up, thumbs down, these changes will look good. And even on when you say you press that merge button, it'll actually do a Pulumi update. But the commands you're living in are essential that bloomy preview gloomy refracture. If things are changing and you want to make sure you, you have a good understanding of the current state is and then Pulumi update to actually invoke those changes. Can you discuss using Pulumi to perform infrastructure testing specifically using language testing libraries to check infra and compliance? Yeah. So we actually have a great blog post. I don't have it linked here, but I can definitely add this after the fact. Um I will let me actually show you this guys. This is probably more helpful. If you take a scan of that R code, it'll go to this presentation slide back and give you all the access to the information that we have here. I will make sure to add something in there about uh language test. But yes, we have a great blog post that covers how you can use things like moca to do unit testing and mocking to some degree. There, there is some nuances since you're working with infrastructure and there's only so much you can really truly know in anticipation, especially if you're working with like a copy writer, right? Mocks and unit testing get you most of the way. But yes, for the most part, your usual development tools that you use for testing are applicable and I'll, I'll drop a link into the helpful links on a blog post that covers the various use cases that you can do uh to leverage the the tool set that you currently have. What are the best ways to embrace Kubernetes without having to change everything? That is a great question. So uh is a very tall order of complexity if you want to look at it that way, but it's a very, a great solution and the same sort of solve problems that we've all faced or been plagued with for many years. And that is reliability, robustness and just the ability to programmatically orchestrate what our workloads should and should be doing. So I would say I always start small. Um The need for is something that you and your team and your organization, we're going to have to make. There's no one that's going to suggest if communities is the right thing that you should be using. But at the very least start up with a single container, take an application that you have, you're looking to say port to the cognitive world, bring to communities and isolate them into a container. That's step one. Get familiar with that process, get familiar with the process of running that container on a single docker post. The second, you want to run multiple copies. The second you want to make sure that these things are tolerant that they're highly available. You need to involve multiple docker hosts or multiple hosts that matter to run these containers that something like cos really starts to fit the bill depending on how much you want to take on. Because Cober is allowed to do script and manage all portions of your application. Whether that be the application, the ingress, north and south traffic east and west for service matches configuration management secrets, right? The list goes on so you can configure as much as you want. I say start very small single containers, single host, get that container running, then get it as a deployment in a community cluster and just that object and do nothing else. Get familiar with using that. And once you sit, you get to that point, the needs that you yourself are identified are only a matter of researching how you can do new communities because at this point, most use cases are solvable in communities for both stateless and state full workloads. There are caveats and there's always going to be pros and cons to approaches. But that is the best way I would recommend uh folks start off because you should not jump into the deep end of the pool. Start small. What options do we have in saving the ploy state other than the ploy web console? Yes, so great question. So this state file, you can store it locally in on your local file system. If you like by default, we do it in the south because it's easier for folks to get up and running. Right. A lot of the pain points we heard is this is great. I want to use an infrastructure and an infrastructure code tool, but I really work on a team. So to be able to show the state across multiple people, these people are distributed all over the world. So we made it easier to make sure that that state can be stored on the SS. So that way if you have an organization or a team on our, on our side, they can work with that stack independently and we can serialize those updates to make sure changes aren't being stomped by another. However, like I said earlier, you can manage that state file independent of the flu, using a local file system or using a block storage such as if you have object storage on digital Ocean or any other provider for that matter, we support that as well. But then the onus is on you to make sure that state is managed appropriately, it's locked and that you are sharing it with your team. If that's not something you want to take on, but you store or, or wanting to manage the state yourself, we do have the ability to host our Pulumi size in uh your infrastructure uh in the pilot on prem, we can ship you an artifact whether that be a, a container or VM and you can run this independently. You can work with us uh in our and our folks to get you uh into a state where you're not having to reinvent how you manage the state management aspects of this if you don't want to use a default size. All right, folks, we've got time for one more question. So type them in the chat box before we run away. Uh What are problems people don't think about when people first started, start working with Huber and ties. Yeah, it's a great question. Uh I would say the things that folks don't really think about is that it's, it's more of a learning curve than anything. Uh The concepts aren't necessarily new or novel, right? There's only so many ways you can set up 12 factor apps. There's only so much you can uh configure ingress, both North, South, East and West. Those concepts are pretty, are pretty applicable. The, the biggest things that hang people up is just the sheer like complexity of how big the surface area is on the resources, but you don't need to use all 100 something resources you really only need to live with, with really like the top five and that will get you 80% of the way in. So I would say focus on the typical the deployment service, the food map of secret and an English object that right there should be, should be no more than, you know, the first couple of experiments that you run and really helps you kind of get familiar with that. Don't try to, don't try to, you know, tighten up the, the hatchet on security too much at the beginning. It's definitely important. There's plenty of con trucks to help you out with that to make it easier. There's great documentation and resources all over the web now that help you provision, you know, secure ready busters and we can certainly help with that, but really, you should minimize the amount of focus on because there's a lot of noise there. It's a big bustling growing project and there's, it aims to do a lot, but that doesn't mean you have to use all of it. So pick the, pick the resources that mean the most to you, stick to those and just get comfortable in that wheelhouse and I guarantee you'll be successful. Wonderful. Thank you, Mike for sharing and thank you to everyone for tuning in. So Mike, any parting thoughts or words of wisdom for our audience, I would say uh first off, thank you all for joining us. I I know, it's a lot these days for folks to take time out of their busy days to join us for, for an hour. So I'm thankful and I'm grateful for everyone who joined us to learn about Digital Ocean, about communities and how Pulumi can help in and around that. I I encourage you, please reach out for help. Uh We have uh a community channel in our community that is the best way to interact with the team with, with thousands of community members that use Pulumi with thousands of our customers that are using Pulumi. You can get started by visiting Pulumi dot com. And if you like this content, we have more content on our youtube page on Pulumi TV. And you can also visit the digital Oceans youtube channel as well where they'll be linking this video uh with the tutorials that, that we've covered. All right, thank you, Mike. And thank you everyone. Uh You're gonna get a survey when you close this webinar. Please tell us how we did and what more you'd like to hear about next time. Thanks for joining us and see you again soon. Thanks, folks. Have a great day.

---
