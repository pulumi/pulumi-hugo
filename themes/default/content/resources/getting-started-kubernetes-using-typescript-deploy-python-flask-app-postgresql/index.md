---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Getting started with Kubernetes: Using TypeScript to deploy a Python Flask app + PostgreSQL"
title: "Getting started with Kubernetes: Using TypeScript to..."
meta_desc: |
    Learn how to build and deploy a Python Flask App with TypeScript on Kubernetes.
url_slug: getting-started-kubernetes-using-typescript-deploy-python-flask-app-postgresql
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Getting started with Kubernetes: Using TypeScript to deploy a Python Flask app + PostgreSQL"
  description: |
    Learn how to build and deploy a Python Flask App with TypeScript on Kubernetes.  In this episode ● Deploy a Kubernetes Cluster ● Deploy PostgreSQL on AWS RDS ● Deploy Python Flask App ● Follow along with code: https://github.com/pulumi/pulumitv    Pulumi is free, open-source, and supports many clouds, including AWS, Azure, GCP, and Kubernetes.  Get Started: https://www.pulumi.com/start
  sortable_date: 2020-05-07T17:47:16Z
  youtube_url: https://www.youtube.com/embed/4xDMOofr8No
transcript: |
    Hello and welcome to Pulumi TV. My name is Mike Metro. Today. We're gonna show how to get started with by deploying a Python Flask app in a post grass database. Let's begin in this episode, we'll show how to deploy a cabernet cluster on Amazon's elastic cabernet service EKS. Then we'll show how to deploy a post database on Amazon's managed database service R DS. And then lastly, we'll deploy a Python Flask cap onto the Cobert age cluster that will be able to talk and communicate with the post database to do right? When we hit its API that we'll expose to the public internet. As always, you can follow along with this video and this code by visiting the Pulumi TV Repo in our Pulumi github org. Let's begin for starters. I'm going to create a new VPC that will allow me to create public and private subnets across all of the A Zs in the region that I'm working within. This is us West two for me. Once the VPC comes up, we can actually define and create the cluster for use on EPS by giving it some properties such as the VPC to run in public and private submits of that VPC. We're going to say, don't deploy a dashboard, we're going to add some tags based on some business logic we want to track. And then more importantly, we're going to disable public IP S on our nodes. So when we set this, what we're actually saying is that the nodes should be housed in the private subnets that we're specifying here. But we're also going to provide some public subnets. So that way we can create some resources on AWS such as load balancers that require being in public subnets. The cluster will then be instantiated and will be able to extract its cup and fig. And once the cluster is up, we can actually start to see how we can create a script database as well on R DS. We'll specify the private subnets for it to use. These are the same ones that we're specifying to the cluster because we need the R DS cluster to only be accessible to the nodes in our cluster that is allowed by uh allowed and enforced by the security group to be using the same one as the nodes do in the cluster. We'll give it replicas two because we want an extra reader to be added to our R DS cluster. If we want multiple, multiple writers and multiple readers, we'll give it an instance class to consume the instance type that we need some tags. And then more importantly, once the cluster comes up. We can actually retrieve the information we need for the database such as its host port, user name, password and database name from the database. So we can expose that to other applications or other consumers of the output of this Pulumi stack, which brings me to a great next point. We have two different stacks here that we're going to be consuming. We're gonna stand up an infrastructure stack that will create our cluster, our R DS database and export the information for that R DS database running post. Then we'll jump into a new stack, the application stack which we'll review in just a second that we consume the Cuban Fig database connection and names space that's created from the former stack by leveraging in Pulumi what's known as a stack reference. We'll jump into that in just a second. Let's see what the infrastructure looks like when we try to run it. So I've taken the liberty of actually running this update because it can be a little bit time consuming. But we can show you that if you try to run another update, what's gonna happen is because there was no changes to our database or our clusters definition nothing is gonna change. So as the preview shows this essentially will be a no up once the update completes we'll verify it was in fact, I know of great. I can see the stacks output by saying Pulumi stack output. And I can see that I've been given a Q config and a database connection object that houses all the properties I need to communicate with the database. Of note, you can see the database connection actually maps the password with a secret cipher text. So you can actually view it uh by default, but we can actually extract that from other sects and not worry but get the full information we need to communicate with the database. Let's leverage the Qin fig output to communicate with Q control and see what nodes are in our cluster. OK, great. Now let's use Q control to see what pods are currently running in our cluster. OK, great. So with the infrastructure officially up with the cluster running and the R DS database provisioned, let's jump into our app stack that will reference our infrastructure stack for the cupid fig and database connection string. As we've seen, we define these properties in the apps, Stax config and now let's consume it in our index ts we'll create a new provider with the infrastructure stocks, Cuban fig and namespace to use. And then we'll create a new instance of what we've called our demo app. In this case, it's a Python Flask app that knows how to communicate with Post Grass and do rights to the database through an API that it exposes. This app is publicly available and available for use on the Docker hub at this user and repo name. And if we jump into what this demo apps definition looks like. We can see it too is another extension of the Pulumi component resource class which allows us to manage resources together that should be managed in the same life cycle. So I can see that I can start to take the database connection information from the infrastructure stack and create a Cotti secret with that information so that this set of credentials runs in a temporary file system on Cober netti when it's mounted onto a pod instead of living locally on disk, this secret will actually be used by the pod through its environment variables that we're essentially defining here. We can take the database connection secret do and apply on it since it's a polling output much like a future or a promise, grab its data such as its host port, user name, password and database and start to set up what these various environment variables uh need to be based on our applications, usage of it. So you can see, I can also specify a SQL alchemy ur I that is required by our flash gap. I'll then actually pass that environment into what we are creating here and known as the pod builder, which is the root of our app. So we have its environment, we can use the image name we've specified here. We'll give it some resources and have it run on a port 5000 per its definition. We'll put that pod into a deployment, give it two replicas. And then we will create a service on the deployment to expose it to the internet by creating a publicly typed load bouncer that will front the flask app. This knows how to target the pod by using the target for H CD P. We've defined Q let's actually run this application. So I'm going to create a new stack called DEV in my application stack. I'll set a config to be the user project and stack name of our infrastructure stack, which we can go back to our infrastructure stack and pull from by running Pulumi stack LS and see that it matches this string here. So we'll set that and we'll do a pluming up. Do I want to run this update? Yes. So this is going to go off and create the secret for our database that we are pulling the information from the database connection object and our infrastructure stack. This secret will then be mounted onto a deployment object of the Python Flask app and then it will be exposed through a public load balancer using a service. Let's run this update. So this update can take approximately 30 seconds or so. And then once it's up and running, it'll take about a minute or two for the public load balancer to be provisioned and ready. Great the update completed because it's gonna take another minute or two for the load bouncer to actually be accessible. Let's see a couple of uh neat things that we have in these stacks. So if I do a plume stack output on the stack, I'll see that this tax output has a instance URL that we've created by taking the load balancers uh hosting and then prefixing it with HCTP. This allows us to share this address for the application with users or with other Pulumi programs. Let's actually jump into the database by going up here here. We've logged in with P sequel to jump into the R DS database that we've provisioned in the infrastructure step before we can see what tables that currently exist and see that we have two tables, a basic one that comes included with most R DS instances and postscript instances and the account table, which is a reflection of the account object model that we have in our Python Flask cap. If I do a select all from account, I have nothing currently. So let's see if our application is up and running. We're going to leverage the stack output in Kerl by passing it in as an argument to curl. Let's see if the cluster. Well, let's see if the application is fully up there. It is our api responsive with Hello world. Great. One more time. Great. So on the root path of this application, we expose a basic response that just returns in JSON. Hello world, there's also an accounts path that allows us to do a post request to write to the database by creating a new account name. So I'm gonna do a poster request to the same flask api that we have provisioned on cnet's. And I'm going to say pass in the new account name, Mike and we're going to use the instance URL just like we did with before we'll give it the accounts path. And let's see what that returns. Great. The mic account was successfully created in the database. Let's verify that in R DS. If I do select, start from account one more time, there's a mic entry into the account database or sorry, the account table. Great. So in this episode, we covered a couple of different things. We covered multiple stacks such as the infrastructure stack for our cluster on EPS and our R DS database for Postgres. In our application stack, we are able to consume the output of our infrastructure stack to get the information we need such as the cup and fig the name space and the database connection information to form a database connection string after it's been placed in a community secret that gets set into our environment variables and ultimately mounted into our pod that our deployment manages and our service publicly exposes to the internet. That's all the time I have to for today. I hope you've learned a great deal. Thank you and have a great day.

---
