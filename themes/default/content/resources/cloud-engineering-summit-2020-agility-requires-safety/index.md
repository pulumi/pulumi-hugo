---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Cloud Engineering Summit 2020: Agility Requires Safety"
title: "Cloud Engineering Summit 2020: Agility Requires Safety"
meta_desc: |
    To go faster in a car, you need not only a powerful engine, but also safety mechanisms like brakes, air bags, and seat belts. This is a talk about ...
url_slug: cloud-engineering-summit-2020-agility-requires-safety
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Cloud Engineering Summit 2020: Agility Requires Safety"
  description: |
    To go faster in a car, you need not only a powerful engine, but also safety mechanisms like brakes, air bags, and seat belts. This is a talk about the safety mechanisms that allow you to build software faster.  The talk is based on the book "Hello, Startup", which you can find here: http://www.hello-startup.net/
  sortable_date: 2020-11-11T00:29:54Z
  youtube_url: https://www.youtube.com/embed/HWroZaREOQg
transcript: |
    Hi, everyone. This talk is called agility requires Safety. Where this comes from is during my career, I've had the opportunity to talk with an awful lot of tech companies and I often hear this very weird sentence. That sounds something along the lines of we don't have time for best practices or sometimes you hear we don't have time to do it. Right. And so you ask about monitoring and alerting and you get basically laughed out of the room. Right. Uh Don't bother asking about documentation. That's not even an option on the table. Uh Maybe you thought they might be using devs practice now they're just tossing things over the wall and hoping for the best. Um, and there's no tests, there are no tests of any meaningful kind. They just kind of throw everything into production. And so the result is the experience of building software at so many tech companies is something that looks a little bit like that. Right. You're trying to build something simple, you're trying to do some basic operation and things are breaking, things are falling apart, everything's coupled, everything's on fire and it's just, it's an awful painful experience. So one of the realizations I've had in my career is, I think software, people think that if we just throw away all these best practices and we just kind of slam down and go as fast as we can, we're somehow going to get things done faster and in general, and especially in the long term, uh, I don't think that's true. I don't think you can go faster by being reckless. Right. I shudder to think of what would happen if a construction team that's building a skyscraper decided we don't have time for best practices. We don't have time to get this right. We'll just get it done as quick as we can. Right? Um I showed her to think of what people would do if they're on the highway and they start thinking like this, right? You're sitting in traffic, you're bored and you're like, I want to get to work faster. You know what I'm gonna do? Forget these best practices, forget speed limits and laws. I'm just gonna slam down on my gas pedal and go as fast as I can. The result is pretty predictable, right? And honestly, this is what software engineering often looks like and often feels like uh the key insight that I want to share and capture in this talk is that the reality for most people is what limits your speed in a car isn't the power of the engine. Modern cars have really powerful engines and most of us aren't using even half of what those engines can do. What limits our ability to go fast is we would die if we went too quickly. Right. It's actually our safety mechanisms that limit our speed. So it's things like brakes, fast. Cars need really powerful brakes. You also need things like seat belts and bumpers and airbags and autopilot. And the more of these we have the faster we'll be able to go, we're not limited by the engine. And I would say in software, the same is also true. We're not limited by typing speed. You can definitely type out way more code than you can actually ship because if you tried to ship all of it, it would just break everything right. That's the limit safety is the actual speed limit for most of us. So the question I'm asking in this talk is what are the seat belts, the brakes uh and, and other mechanisms of software. What are the safety mechanisms that we should be using? And specifically what are the safety mechanisms we can put in place that will allow us to go faster. Putting the the safety mechanism in place has a cost, it'll take some time. But we want these mechanisms that pay off massively and let us go much faster as a result. Uh I'm Yevgeny Brickman. Uh often go by the nickname Gem. I'm the co-founder of a company called rut work where we provide des as a service and we help a lot of companies with infrastructure and safety mechanisms. Uh Also the author of a couple of books, uh Terraform Up and running, which is all about infrastructure code. You'll hear about that later in the talk. And he startup, which is about a lot of startup topics, but has a whole chapter dedicated to software delivery where I talk about a lot of uh about a lot of the same ideas. So here's the outline for the talk. Uh I'm gonna go through four safety mechanisms. I'm gonna use an analogy for each one. And then as we get into it, you'll see what the software equivalent is of each one of these. So let's get rolling. We're gonna start with brakes as we talked about uh good brakes are essential on cars. In fact, the faster the engine, the bigger the engine, the better the brakes need to be and they prevent you from running into things. You really don't want to run into the equivalent in the software world to brakes is continuous integration and automated testing. So that's what we're going to focus on here. And I want to pause and spend a little bit of time in continuous integration because I think a lot of people don't deeply understand what continuous integration really is. A lot of people just think, oh, it's Jenkins, right? Or get lab and there's a little more to it than that. So let's look at an analogy and get a good sense of what continuous integration really is. Imagine you were assigned to build out the International Space station, right, this giant spacecraft and you decided the way you're going to do it is you're gonna split it up into a bunch of pieces and you're gonna assign each piece to one country, that country is going to look at the plan and they're gonna go away and for years, maybe decades, they're gonna work on that thing completely in isolation. They're not really going to talk to each other, check nothing. They're just gonna work in isolation. And when everybody's done, you're gonna launch things into outer space and put them all together. How's that gonna work out? Probably not very well. Right. Uh One of the teams is gonna go, oh, wait a minute. I thought that the Russians were going to be the ones that are gonna do the bathrooms, didn't they do it? No. Uh Someone's gonna say, wait a minute, I thought the French team was responsible for all the wiring and of course, most of the teams are gonna be like, well, it's OK, everyone's using metric, right? There's not like one country out there that just happens to not be using the metric system, right? Um Here's the issue when teams are working for a long time in isolation, they start to create these false incorrect assumptions and figuring out what assumptions you got wrong at the very end. When you're trying to launch is way too late. That's a very expensive way to learn that lesson. So this idea what, what I just showed you here, that's essentially late integration. And a lot of teams build software this way they use feature branches, right? Each team has its own branch and they're all working completely in isolation sometimes for months at a time, building whatever it is not really integrating with each other, not putting their work together until the very end. At the very end, maybe once every three months or six months, they try to do some kind of massive release and to do that, they have to merge all their work together. And the result is a gigantic merge conflict. And I don't mean just a merge conflict that is, you know, oh a little text got changed here and here. And how do we put it together? I mean, these teams are have giant fundamental conflicts in what they're putting together. Maybe the team in this blue branch at the top, they were working using a library that the team in the green branch just deleted. And so now you have 10,000 lines of code written around a library that doesn't even exist anymore. Um These assumptions can cause these fundamental issues that can take weeks or months to resolve and they're very hard to resolve and you might not even realize it until you put the code in prod that you've had these crazy uh incorrect assumptions. So the alternative to building things that way is what's known as continuous integration. And the core of continuous integration is this sentence right here. The goal is not about C I servers or any of that, it's about regularly merging your work together very, very regularly, ideally every single day, but the key is don't go for months without merging together very regularly, you put all your work together. And so all of those incorrect assumptions get flushed out immediately. Now there's a bunch of ways to do continuous integration. And the most popular is what's called trunk based development. And the idea here is that the way you merge work together is you basically force everybody to work on a single branch, typically called trunk or master or main. So everybody on your team, all the developers are all merging their work on a very regular basis, perhaps daily to this one branch. Now, when I tell people about this and explain what Trump based development is, I usually get one of two reactions. One is people who have done it and they're like, Yep, makes sense, love it. And then the other is from folks who have never done it and they simply do not believe it's possible. It sounds ridiculous. And so I start getting all sorts of questions about it. Uh One of those questions is OK, there's no way this can scale. Sure you can do Trump based development with a team of three, but I have dozens, hundreds thousands of developers on my team. There's no way it can scale to that. The reality is Trump based development might be the only thing that scales most. Uh or I would say many of the major software companies in the world uh use trunk based development, linkedin, Facebook, Google, Amazon. They all have thousands and thousands, maybe even hundreds of thousands of developers committing to the same repot to the same branch. They all do Trump based development. So it definitely scales Google's numbers in particular are just astonishing. These are numbers they published back in 2015. So I'm sure the numbers have grown since but their source, they have a single repo with 2 billion lines of code and 45,000 commits per day all on around trunk based development. So yeah, it scales. You don't need to worry about that. Then the next question I get is OK, fine, fine. Maybe it scales. But wouldn't you just have merge conflicts all the time, right? If, if the merge conflict was the big thing, well, if we're all just merging together, then I'd be dealing with conflicts every day. The reality is that's actually not what happens when you're doing. Feature branches, merge conflicts are pretty likely because maybe you have two teams and for three months they're working across the code base. And so the odds that those two teams touch the same files in perhaps incompatible ways. They're pretty high over a three month period. But with continuous integration, if you're merging code into Master every day and you're pulling the latest for master every day, the odds that you happen to modify two files at the same time are a lot lower. And even more importantly, if you did modify those files at the same time. Well, it's only a day of work to merge. It's something you just did yesterday, right? So it's actually really easy to fix these merge conflicts. They don't result in, you know, these cascading thousands of lines of code that, that need to be cleaned up. And the thing to remember here is merch conflicts are part of the process. There's no way to avoid them, right? You're gonna be touching the same code. Uh So the whole point of continuous integration is you're solving these early and often and that's a really big deal. In fact, this is a common practice. This is another big part of a safety mechanism is committing early and often small commits uh have huge advantages, right? They're easier to merge, they're easier to test, they're easier to revert. Uh They're much easier to code review as well, right? We've all seen the code review that looks like this, right? You put up a pull request and it's 10 lines of code, you have 10 comments on it. You put up a pull request with 500 or 5000 lines of code that looks fun chipping, right? That's how code reviews work. So small commits are really, really valuable and continuous integration encourages and makes heavy use of small commits. OK? So then the next question is OK, fine. It maybe it's scales, maybe the merge conflicts aren't a big deal, especially if the commits are small, but wouldn't the code on trunk always be broken? And so now this is where those automated tests come in. This is the other key, incredibly important part of this particular safety mechanism. So the idea is you configure a self testing built. In other words, after every single commit, the build runs a set of tests, right? They compile the code, they do run LIN tools, they run automated tests, uh do a whole bunch of checks to make sure the code is actually working the way you expect. So this is where those C I servers like Jenkins finally come into the picture. And the key point here is that if the build fails, if some test fails, then more or less you kick the code out of trunk, right? You might revert it automatically immediately or maybe you give the developer a little bit of window time to try to fix it if it's something minor. But at the end of the day, broken code does not stay in trunk for more than a matter of, you know, minutes and usually it's kicked out right away. That's a really, really big deal. Now, of course, getting benefits from this does depend on having a good suite of automated tests and this is where a lot of the investment into this particular safety mechanism comes in is creating this C I system that's gonna run your tests and building a solid suite of automated tests. So an important question to ask is what should you test? Um Now there are some testing purists who will tell you everything. You have to have 100% code coverage. You have to do everything through TDD, et cetera, et cetera. Um I don't really believe that. And from most of the companies I've worked with, that's not really what happens in the real world. The reality is you choose what to test by considering it as a trade-off and it's a tradeoff between a few key things and those are the likelihood of bugs, the cost of those bugs and the cost of testing. So likelihood of bugs, uh certain type of code are more likely to have bugs than others, right? Really complicated algorithmic solutions. You're probably gonna mess them up than some really basic uh straightforward for loop that does something simple. Um But even more importantly, the likelihood of bugs goes up significantly as the team size grows and as the code base itself grows. So we'll come back to that point a little later in the talk. But just remember that as the code base grows, you're gonna need more and more tests. And this is pretty similar to a car that has a bigger engine, uh, needing bigger brakes to stop you on time. Second factor is the cost of bugs and here, the thing to remember is that there are some parts of your code where bugs, they're just not that big of a deal. Sure. Some user might get annoyed. It's a little bit irritating. It's not the end of the world. And then there are other parts of your code where you just cannot have bugs, right in your payment systems. For example, uh you don't want to be charging users two times or zero times um in security, right? Authentication, authorization, you do not want to get those things wrong. That's a very costly error. That might be a company ending event. So there you're gonna invest way more time in testing because the cost of bugs is really high. And then the third factor is how much does it cost to do the testing? Um For some types of tests like unit tests, the cost is really low, right? Most modern programming language have unit testing frameworks readily available or even built in. It's easy to write them, they tend to run really fast. So the cost is really low and you should almost always write some amount of unit test. But integration testing can be more expensive and U I and end to end testing can be very, very expensive. And sometimes the cost of the test is higher than the cost of the bug. Like it would have taken you five minutes to fix it, it takes you uh and you know, no users would have really complained whereas it would have taken you five hours to write the test. In those cases, it actually might make sense to skip the test or to reduce the test to just a small number of high value ones. So those are the key tradeoffs. But if you do a good job with those tradeoffs, so you are doing continuous integration, you know, everybody's regularly merging into the same branch. And you have a, a self testing build that basically runs tests after every commit and rejects things that fail. There's something really powerful that this safe safety mechanism does, which is you go from the world of late integration where the default state of your software is that it's broken, right? The default state is you just assume whatever code you have in all these feature branches, it doesn't probably work and it doesn't work until you do weeks and weeks of effort to merge it all together. And then somehow manually prove that it works. And it's, it's kind of an awful process that actually slows teams down considerably if you do continuous integration. Now, there's this incredible shift where the default state of your code assuming you have good tests. The default state of your code is that it works and you can deploy it any time you want, you can deploy 10 times a day, 1000 times a day. And that's really the key. That's why these large companies do trunk based development is with a good self testing build. Um, and everybody merging together regularly, you can deploy every day many, many times a day and really get, uh, get software shipped very, very quickly. Ok. Let's move on to the second safety mechanism which uh the analogy for them are bulk hits. So bulkheads are a part of a ship. Uh Usually when you build a ship, you separate the ship into these areas and put these giant walls between them, which are called bulkheads. And the idea here is if you get a hole in the ship, you hit something, for example, and the water starts rushing into one part of the ship, the bulkheads prevent the water from getting into the entire ship. And so you have a good chance of surviving that collision. Um And so basically damage in one part does not cause a disaster everywhere. The equivalent in the software world is splitting up your code base so that if you make a mistake somewhere over here in the code base, it doesn't affect everything. Now, why do we need this? Well, it turns out and it's a little bit weird as a software engineer, but the more code you write the slower you go. So this is one of the things that actually slows you down. It's more code, uh, in the book code complete, there were some great, uh, there's some great research done around this and what they did is they looked at the number of bugs, uh, relative to the size of a project. Now, of course, as a project gets bigger, you expect there to be more bugs. But what they looked at was actually the bug density. So that's the number of bugs per 1000 lines of code. And what they found was that bug density went way up as project size increased. So for example, if you had a project that was less than 2000 lines of code, you'd expect there to be between zero and 25 bugs, uh, per 1000 lines of code. But by the time the project reached over half a million lines of code, now we were looking at between four and 100 bugs per 1000 lines of code, right? 100 bugs per 1000 lines of code. That's every time you write 10 lines, there's a bug and another 10 lines of code, there's another bug. So what that means is as the code base grows, the number of bugs, the density actually grows much faster. So bigger code bases are going to be much buggier, which means you're gonna go much slower if you don't do something to solve this. Now, the reason for all these books, like why, why would a bigger code base have higher code uh higher bug density. The reason is that we don't really do software development in an ID E or on a chart or in some tool, it, it's really happening in your head. That's how you code, right? You build some mental model of what's happening in the code base in your head. Then you figure out how to modify it and then eventually you put that into the ID E but the real work is happening in your head and the problem is our minds can only handle so much complexity, right? We just can't handle it. When, when we're over half a million lines of code, you just can't fit all of that into your head. You can't consider all the ways the different parts of the code base interact with each other. So you start having more and more bugs and you start going slower and slower. So uh to solve that you want to split up a code base and specifically what you want to be able to do is let's say you have a million lines of code. You want to find a way to organize things so that you can focus on one part of that code base at a time and safely ignore the rest. And I do mean safely. So obviously, you can always ignore the rest of the code base and make random changes. But then you create bugs all over the place and that makes you actually go a lot slower. What I'm looking for is a way where I can ignore the rest of the code base while looking over here and be confident that as long as this little universe that I'm looking at is OK, that everything else will be fine too. And so there's two primary mechanisms to accomplish that. And one is to move to version artifacts and the second is to move to services. So let's look at these. So version artifacts. What I'm referring to here is let's say you start with a code base where everything is in a single repo and all the different parts of your code base depend on the other parts uh directly on the source code of those other parts. So module A directly depends on the source code of module B module B directly on the source code of module C so on and so forth. The change that you make to split up your code base here is to switch these to versioned artifacts. So module A doesn't depend on the source code of module B anymore. It depends on a version artifact published by module B, basically a snapshot in time that has some frozen version of module B in it. Now the types of artifacts that you use depend on the language uh in the Java world. Those might be jar files in the ruby file, you might publish Ruby gems uh in the javascript world. Those might be N PM modules and so on and so forth. But the key is that you no longer depend directly on the source code of the other module. Now, usually when you do this, you also separate the code into different repos. But that's actually not strictly required. You could keep everything in one repo and just publish artifacts. And the artifacts are really the key difference because when module A no longer depends on the source of module B now, you can modify the two of them independently because they're essentially looking at these like frozen in time uh versions of each other. Uh And that has some really nice advantages. Um And by the way, we already do this all the time, right? This isn't some like new crazy thing that I'm suggesting you do this all the time. If you're using any open source or third party libraries, you're probably not depending on the source code of those libraries directly, you're probably pulling them in at some specific version. So you know, Google Guava uh 18 or React Js 16.5 you're looking at a specific version and that open source project is able to develop itself completely independently and go as fast as they can and not have to worry too much about you and you can develop your own project without having to worry about breaking React Js or, right. That's how we use open source and third party libraries already. You can do the same thing for your code base inside of your own company. And that has some nice advantages. One is isolation, right? The ability to work largely uh independently from the other parts of the code base and even to ignore those fairly safely. The one place where you can't ignore them is your public API. So for example, if module B over here exposes some API and module A is using it, you can't just change that willy nilly. You do have to think through backwards compatibility. And what happens if module A eventually updates to the new version of module B but still all the internals of module B you can build by yourself and you can make backwards and compatible changes as long as you provide a reasonable migration path to the new version. So isolation is good, you can go faster within your one module at a time. Decoupling is an interesting side effect. Uh If you have a large code base and you start breaking it up, you'll often find that things are really tightly coupled together. Um You know, I like to think of it as like pulling a wire out of a box of wires, right? And everything seems to come up with it as well. Um Breaking that stuff up actually is huge benefits. A lot of the bugs and issues that you're often running into are because the code is unnecessarily coupled together. And so breaking it into these artifacts forces you to split it up and often um has some really nice benefits in reducing bugs and issues and cleaning up API S. And then the third thing is another fun side effect. Your builds get faster instead of having to build this entire code base. Every time you make a change, if you're changing module B, you only need to part, uh you only need to build the code that's in module B which is a really nice advantage, but there are drawbacks. So the first one is really important, those of you that have been really paying attention to this talk, hopefully noticed that what I'm discussing here is more or less the opposite of continuous integration, right? In section one, I said continuous integration, merge everything together on a regular basis. And now here I'm saying split everything into these artifacts so that you can do 1000 commits in module B and the people in module A will never see those until much later on. And hopefully what you're realizing from this is there aren't silver bullets here, right? You have to pick the right tools for the job. In some cases, continuous integration is the best fit and source dependencies and everything working together. In other cases, these sort of version artifact dependencies are going to be a much better fit. Usually the way that breakdown works is where are you spending your time? If for example, these things are completely separate from each other, right module A is maybe a whole separate product or it's a separate library that you could actually potentially open source uh into the world. The separating that into a virgin artifact makes sense because they're going to be developed separately. You're gonna be doing most of your work within module A and a separate team will do most of its work in module B. And so yes, they have public API S and how they interact. But that's really the only interaction in those cases virgin artifacts will give you some advantages over continuous integration. But if this whole thing is one product that's deployed together and version together and tested together, and uh you do basically everything together, then separating into these version artifacts will actually be a really bad tradeoff. And you should instead stick with source dependencies and stick with continuous integration. Um Other drawbacks to version artifacts. Uh You do get a little bit of dependency held there's a lot of ways that this works out. But for example, let's say module A depends on B and also has a direct dependency on E and let's say it depends on E version one module B depends on E version two. So now when A pulls in B and E, which version of E should it get one or two depending on the language and the framework and the tooling you're using, you'll get different answers to that and different bugs as a result and you can run into all sorts of issues like uh diamond dependencies, you can run into circular dependencies and just, you know, this used to be called DLL. Hell, there are a bunch of weird things that happen when you break up into these version artifacts and whether it's worth dealing with, with them or not, depends again on the type of software you're building. Finally. Uh more or less by design, it's much harder to make global changes, right? If you needed to update every single one of these modules, maybe there's like some security thing uh that came out that's gonna take a long time. If they're all separate version artifacts and they all have interdependencies, you basically have to build like a dependency graph. You have to start at the bottom of the graph, update, the lowest layer release new versions of those, then you go up one layer update everything in that middle layer to use the newer versions, release new versions of the middle layer and so on and so forth and it just takes ages and ages. So if you have to do global changes across this, this set of modules, often version artifacts are not gonna help you, they're gonna slow you down. But if global changes are extremely rare and 99.9% of your work is local with an A module, then it'll actually make you go faster. OK? So that was one way to split up a code base. The second way is to use services or what these days, uh, have become known as micro services. I don't know why. That's the cool new word, but we'll go with services for now. So, what's the idea here? Um, the idea is normally when you start building an app, it is a monolith and I don't say that is a bad thing by the way and you'll see why in a minute. But it's a monolith. It's a single app. You deploy it essentially as one process and all the different parts of that app, talk to each other through function calls in memory function calls. Uh As you grow, you might want to break this down into microservices. And so now each part of your application lives in a separate process, usually runs on a separate server server as well. And now, instead of communicating through function calls, they communicate through message passing usually over the network. Uh So for example, these might be http calls that pass json data around. So that's the idea with services as you move to the sort of network based uh architecture. Now, there are some advantages to this one is once again, you get isolation. So you could have one team that owns this service. A, another team that owns service B and they can more or less work independently from each other within their own little uh service world. Again, the exception is the public API In fact, we'll talk about that in a second, but the public API with services is even harder to update. But other than the public API you can more or less do what you want to have your own coding practices and go at your own pace within each of these, which is a really nice advantage, especially for larger companies where you want teams to be able to run um at their own speeds. Second advantage is services are technology agnostic. Since each of these things is typically a separate process on a separate server, you can build them using completely different technologies. This one could be Java uh A could be Java B could be Python, E could be node. Um You can use the best tool for the job. Also that's useful if you're acquiring companies that may have used a different technology than you. And then the final advantage is scalability. Uh services allow you to scale each one differently. So for example, maybe service A can only be vertically scaled. So you just have to keep giving it more CPU and more memory. Whereas service B maybe that's easy to horizontally scale and you can just spin up a whole bunch of little servers and scale it that way. And by having them as separate services, you have that ability. Whereas if everything was in one monolith, you're basically stuck at the lowest common denominator, you'd have to scale everything vertically essentially. So those are some really nice, powerful advantages of services. But they also have a ton of drawbacks. Um For one thing, you have a lot of operational overhead instead of having one thing to deploy and manage the monolith, you now have end things one, you know, for each micro service and each one you have to deploy it separately, configure it separately, monitor it separately, do security patches separately and so on and so forth. Everything gets multiplied. There's a huge performance overhead services are better in some cases from a scalability perspective, but they're generally much worse from a performance perspective. Uh And the reason for that is we've switched from function calls in memory to calls over the network. And if you go look up your latency numbers, you'll see that network calls take two orders of magnitude longer than in memory and sometimes more. So we're talking something that used to take nanoseconds now takes an appreciable chunk of a second. We're talking thousands of times slower. And so if you just try to naively switch to micro services, your code gets really, really slow. And so then to fix it, you have to rewrite a lot of the code, you have to think about batching and cashing and uh then you start dealing with things like thread pools or maybe non blocking IO which is a different programming model. You have a whole new set of errors to deal with right. A function call usually just works. A network call could fail. You might have to retry it, it could be slow, you could get half a response back. There's all these new failure modes. Um I mentioned this earlier. Backwards compatibility is another big drawback. If we go look at this diagram, if service B exposes some public API that A uses, you can't just change that API, you can't just delete, for example, the API or change some parameter. Because as soon as you do that, since these are live services talking to each other, a will start getting errors. So the way you evolve API is in a service architecture is much more complicated and expensive. So for your public API, you're actually likely gonna go slower. But if most of your work is internal and the public API is pretty consistent, then you might go faster. And once again, for the same exact reason by design, it's harder to make global changes. So splitting up a code base, a lot of advantages, several different ways of doing it. A lot of drawbacks. So just make sure that you're making the right tradeoffs um versus uh with having the code base split up versus having everything together and continuous integration. All right. Third item we'll go over is autopilot, some cars these days and a lot of airplanes have autopilot uh to basically automate the things that the car is doing or that the plane is doing. And the idea here is to remove people from the equation because human beings make mistakes all the time and you don't want to be slowed down by mistakes. Also, humans aren't very fast at doing things whereas computers can do things very quickly, very accurately without mistakes. So the equivalent of autopilot in the software world uh is the automated deployment. The idea is to remove human beings from your deployment process. That's the goal. We don't want manual steps in the process that allows us to do it faster, that makes it a lot safer as well because the computer is not going to accidentally make a mistake. Uh So if you're familiar with the idea of code smells where you look at a piece of code and something just really seems off kind of like it smells. Well, there are also uh smells in the DEV ops world. So one of them I would say is if you see that the way your team deploys things is by SSH to servers or manually running a bunch of commands and uh configuring things by hand or sometimes called click ups. Um That's a smell, there's something you, you're, you're gonna have a lot of uh errors as a result and you're gonna go a lot slower as a result. Um Similarly, if you see your team members deploying things by going to a web U I maybe Aws, this is the Aws console or Azure or Google Cloud and they're clicking all day to deploy things, that's also a smell that's going to be slow and error prone. What you want the deployment process you should be aiming for is this, it is a single big fat deploy button, you click it and that's it. You as a human being, your role is completed. The rest happens automatically. In fact, if you want to get really fancy, you might even get rid of the deploy button, right? You might just deploy it automatically uh as soon as your continuous integration and automated tests have passed the build. So as little human involvement as you can get away with, that's the goal now to do that, you have to automate things and you have to automate a lot of things. You have to automate where the infrastructure itself, how that gets configured, the configuration of your apps, the actual deployment itself and so on and so forth. So there's an awful lot that needs to be automated to make this happen. This is the investment for this safety mechanism. Um So I'm gonna go over some of the tooling in the space that may be useful for automating these things. And I'm gonna go over this roughly in the order of how these tools were developed historically. And so the ones towards the end are the more modern ones that you probably should be using. So the first category were ad hoc scripts uh when people first decided, OK, I need to automate the deployment of my software. You turn to your favorite scripting language, whether that's Bash or Python or whatever else, and you just write a whole bunch of code to automate uh whatever that process is. So here's for example, a simple Bash script that you can run on a Linux server to install some software on it. Now, the advantage is these are general purpose programming languages so you can do whatever you need. The drawback is these are general purpose programming languages and you can do whatever you need. Uh If you've ever had to maintain a large code base of scripts for automation, especially bash scripts, you'll find that it's very, very painful. Uh You constantly have bugs, everybody writes the code in a different way. Most people don't take into account some of the really important concepts that are essential for managing infrastructure and deployments, state management, uh item potency. Um People miss these in these ad hoc scripts because they're general purpose tools. So you just, you have to be aware of these things. It takes a long time to learn. Um So generally speaking, these should not be your primary tools, you will use them. There's all sorts of glue code and stuff that you're still going to be doing with these general purpose tools, but these probably shouldn't be your primary uh option for managing infrastructure and deployments and configuration. Now, a lot of people realize this. So the second set of tools that we built out in the world were what were called configuration management tools. These are things like chef puppet, answerable, et cetera. And these were purpose built for configuring the software that gets installed on a server. So here, for example, is uh some answerable code. It's YAML uh for uh doing something similar to that bash script that's basically installing some software on a Linux server. Now, the advantage of these tools is they are purpose built for configuring servers, which means they have a lot of tooling built in. So your code is a lot shorter. They have a bunch of patterns that you can use. Uh so that it's not just completely random. There's certain expectations you can have about the code base and they solve some of the problems out of the box that people forget to do when they're just using general purpose tools like item potency, like don't install the thing a second time if it's already installed on a server, the drawback to these tools, they're certainly better uh than just ad hoc scripting. But the tools themselves are pretty complex. It's an extra thing to learn. Many of them require you to run extra infrastructure. So like a chef master server or a puppet master server or multiple servers, they require you to open all sorts of ports and be able to connect to things you have to think about authentication and encryption a lot more. And uh one of the biggest issues I think is most of these tools were designed to configure your production environments, but they kind of left your DEV environment, which is where developers spent a lot of time out of the equation. Very few people use these tools in DEV. So you didn't really have a good parity between what production had and what you were doing in DEV. So the next layer that people developed were machine images. And this is something that I think is extremely popular today. And I think this is what we're mostly using in the modern world. And there's different types of machine images. You could have virtual machine images and you can also have Docker images. And there's a variety of tools you can use to build these things. And so this is a bit of a mindset mindset shift instead of using a tool like chef to go and configure that server and then that server and then that server, you basically just create a machine image, you create a single image that represents everything you want already installed and configured. And then you can take that image and you can run it on all of those servers and you can also run it in the DEV environment. That's the, those are the big differences. So here's an example of a Packer template that can be used to build an Amazon machine image, a virtual machine for AWS and it installs a bunch of software on it. And now you have this like immutable, hermetically sealed little artifact. And you can now deploy it all over the place. Um So the strengths are, these tools tended to be a bit simpler to use than Chef and Puppet. Um They gave you these immutable version images. So they were a really effective way to get into immutable infrastructure, just a whole bunch of uh benefits. And you could run these images in every environment dev uh even your own laptop, you can run a doer image on really easily. Uh You can run it in the Q A environment staging and prod. So they gave you good parity across all your environments. So that's why these are very popular these days, especially Docker. Now, the drawback is there are extra layers of abstraction. Certainly running a virtual machine is you have to virtualize the whole operating system and hardware. So that has all sorts of performance implications. Um But even more to the point uh these things, these tools are very useful but they don't solve the whole problem just because you have a machine image doesn't solve everything. For example, how do I get the underlying infrastructure? Where's my server come from? Something still has to solve that. And then even once I had the server, how do I take my image and put it on the server and keep it running there? So you still need to figure out infrastructure and orchestration. So that's where the next few tools come through. Um So we have a set of tools that I call provisioning tools. These are for managing the infrastructure. So these are tools like Terraform and Pulumi. And what they let you do is spin up all of your servers configure your networking, your load balancers, your databases, all of those, the basic hardware, some of which may be virtualized in the cloud. Um These are the tools that are custom built to manage that stuff. Here's an example of some Terraform code that deploys an EC2 instance, basically a server in AWS and attaches a static IP address to it. So it's this very simple decorative language for doing these things. And so the advantage is these are purpose built for managing infrastructure doing it with ad hoc scripts is hard and not fun doing it with configuration management tools. Some of those had some first class support for this, but they did it very poorly. These tools are purpose built for managing infrastructure and they do a really nice job of it including handling a very hard problem which is to manage infrastructure, you have to maintain state, you have to remember what did you deploy before so that you can update it in the future. Drawbacks to these tools. They're new. These tools have only come out in the last few years. They're still fairly immature, they still are missing a lot of the features you want, they have a bunch of bugs um eventually they'll get better, but right now they're still pretty new. Um They also introduce their own complexity. They're new tools, they're sometimes new languages. Um So learning how to do and manage these things is not always easy. Final category of tools are orchestration tools. These are things like Kubernetes, Meso ecs and nod and these are designed specifically for managing apps. So they assume the infrastructure is already in place, maybe used terraform to spin up a Kubernetes cluster. And then these tools will take your machine images, those Docker images and B MS and they will deploy them across your hardware and they'll monitor them and they'll redeploy them if they crash and they'll do rolling deployments and a whole bunch of the other things that you need to solve to run apps in the real world. Uh So here's an example of uh code for Kubernetes, which is YAML which says OK, I want to run a Docker image uh that has engine X installed and I want to run it at a specific version. This is this immutable infrastructure idea. Uh I want it to listen on port 80 I want to have three copies of it somewhere in my cluster. So this very nice and decorative language for capturing all of that complexity. Uh So strengths, these tools are built for managing apps and they're very good at it. You're, they're going to do a much better job of it than you would with ad hoc script or configuration management tools. Um and part of the reason they're so good at it is they maintain state. Again, they remember what you deployed before, how many copies of it you want to deploy, they monitor it. They, they solve all of these very important problems with managing apps. The drawbacks, these are probably going to sound familiar. These tools are all relatively new, so missing features and bugs are to be expected. And these tools introduce a lot of their own complexity, learning, something like Kubernetes, it's like its own cloud. And so you just have to take a lot of time to really understand it. So key point with all of these tools is they allow you to define and manage all of your infrastructure as code. And that's an incredibly powerful safety mechanism because with code, you can version it, you can code, review it, you can write automated tests, you can have continuous integration, you can reuse the code, you can apply all the other safety mechanisms we're talking about to this code as well. So that will let you go much, much faster. OK. Final piece we'll talk about in this talk is what's called the safety catch. So let me explain what that is. Uh back in the 19th century, we had invented the elevator but nobody, no human being was really willing to use it. And the reason was people were deathly afraid that if the cable snapped, the elevator would plunge and you would die. And Elijah Otis invented what is called the safety elevator. And he had this amazing demonstration for it where in front of tons and tons of people. He had this giant uh open elevator shaft you can see in this picture here and he rode way, way up, was up really high and was standing in his little elevator. And then he had his assistant up here, cut the cable in front of the whole audience and the elevator dropped, but only a little bit and then immediately came to a stop and Elijah was completely fine. So how did, how did the safety elevator work? And by the way, this thing transformed the world. This is what allows skyscrapers. This is what made people confident in the elevator. So here's the an image from the patent for the safety elevator. And what we're looking at here is kind of a side view of the elevator shaft. And you can see the elevator in the middle of the shaft. And if you notice along the sides of the shaft, there are these metal teeth that stick out and in the elevator itself, there are these metal safety catches that stick out and here's the key point by default, these safety catches, their position is out, so they stick out into the elevator shaft by default. And because of that, they catch on those teeth and the elevator can't move at all. And the only way to pull those catches in and allow the elevator to move is if somebody pulls up with enough force on the cable, so only when there's an intact cable, do those catches get pulled in and can the elevator move? And if the cable snaps, they pop right back out and the elevator comes to a stop. So here's the key about this idea. So I think this is actually a really cool invention. It's very clever. Um But to me what strikes me about it is these safety catches, they make the elevator safe by default. It's not some extra safety mechanism that jumps in at the last second. It's actually safe by default. That's a really powerful concept that I think we should copy in a lot of engineering. And one of the ways you can copy it in software engineering is what are called feature toggles, feature toggles, give your code some degree of safety by default. Um One of the reasons you might want to use a feature Taco, by the way, is this question so often when I talk about trunk based development, uh which I was talking about earlier in the talk. One of the questions that comes up that I didn't answer then is let's say you were building a new feature that was huge. It would take six months a year to complete. How do you commit that to trunk all the time? Right? If it's not done, you don't want to commit it and have it shipped to users. Well, the answer to that is the feature toggle and it's actually really simple. I'm sure you've invented it yourself in the past. Um So let's say this is the code for some app you're building. And at the bottom in this html, we have the original code for our website. And then at the top, this is that new feature you're building that's going to take 6 to 12 months to complete. Well, what do you do? So you can check this in without users seeing it before it's done. Hopefully the answer is pretty easy. You put enough statement around it, right? Nothing fancy. Wrap it in an if statement have the if statement look up a feature toggle and here's the key by default, that feature toggle will return false. In other words, this feature will be off and so this if statement will evaluate to false and this new section will not be visible to any users. So with this tiny simple little if statement, now you can commit this code even before that feature is done, the code still needs to compile it should be syntactically valid. So you kind of there's some bare minimum that needs to be working, but the whole feature doesn't have to be complete. It doesn't have to be working. It doesn't have to be pretty because no user will see it. That's the key. So it's safe by default. And this does something pretty magically if you wrap all of your new features in these if statements in these feature toggles that are off by default. Well, what you've done now is you've separated the act of deploying code from the act of releasing new features. Now you can take your code and deploy it all day every day to every server around your entire fleet and none of the new features will be visible until you separately turn them on by flipping that feature toggle. And this is like a superpower to have. Um This is an incredible safety mechanism. So how do you turn feature toggles on and off? There's different ways to do it. One of the ways is to just have a config file which you probably already have for your app. And in some environments maybe dev you turn the feature on so you can code it and then in other environments like production, it's off and oh by the way, it's also off by default. So I just list this just to be explicit. So it's more clear what's going on. Um Configuration is good and that's probably a good initial step for a company to do. But the next level up from that is even more powerful, which is you create some sort of a service, maybe a data store where you're storing the data for these feature toggles. So you can ping it and say, hey, should this be on in environment X and should it be on an environment, y even more importantly, if you have a service like that, you can actually return different results for different users. So maybe for user 123, you turn the feature on. Um but for user 456, you turn it off. So now you have this really powerful ability where if you put a little web U I in front of this feature toggle service, now you can turn features on and off dynamically uh after the deployment has happened, right? So this is how you release new features is using a web U I and you can turn them on and off for specific users. So this is a screenshot of a tool called excellent um from when I was working at linkedin and this was a U I that we used to turn feature toggles on and off. And so here I can turn this feature toggle show new home page model module on for 1% of users in the US as an example. And this is incredibly powerful because now I have the ability to quickly turn things on and off whenever I want to. And the way we used it was like this, all new features were wrapped in a feature toggle off by default. So we could deploy them any time we wanted. When we thought the feature was ready for use, we might turn it on and maybe initially we just turn it on for employees of our own company. So the rest of the world doesn't see it, but our employees start testing it if things seem to be working well, now we can turn them on for public users, maybe to up 1% of users. And we look at the logs and we look at the metrics and we see is it working? Are there any issues? If not now, we ramp it up to 10% 50% and eventually 100%. If at any point we had an issue, we have this unbelievable safety mechanism where in a couple clicks, we can turn that feature off again. And I'm sure users aren't gonna be thrilled that they lost access to some feature, but nobody has to be woken up in the middle of the night. We don't have to rush and work all night to fix some severe bug. We just shut it off and we revisit again and fix it when we can later on. That's a really powerful ability to dark, launch things to ramp them up slowly and to turn them off again. One of the other things you can do with feature toggles is A B testing or more generally bucket testing where you can show different versions of your product to different users and see if one version helps your metrics or if one version performs better the way you expect it to. So you can do data driven development. So feature toggles are really, really powerful safety mechanism. Um There's some nice uh tools out there that you can use to help build those web UIs and those data stores you don't have to build them from scratch. There's split IO launch darkly and a bunch of others. So check them out. Um OK. So those are the safety mechanisms I wanted to go over. There's of course many others, but these are four of my favorites. Um brakes, bulkheads, autopilot and safety catch and just to recap, brakes were continuous integration and automated tests. These are what stop broken code from getting out into the real world and doing a lot of damage bulkheads where how you separate different parts of your code base. So you can focus on one part at a time and safely ignore the rest and you can do that by using version artifacts or you can do that by using services or both uh autopilot. This is infrastructure's code, this is the ability to automate the deployment of everything you're doing, automate your infrastructure, automate the deployment process, automate the configuration, capture all of that as code and let the computer do it instead of a human being and you'll avoid many, many errors and it'll run a lot faster and then the safety catches. These are the feature toggles. These allow you to separate deployment from release, these allow you to dark launch things to ramp them up gradually to shut them off if there's any issues. Uh a really, really powerful safety mechanism. So to recap things, speed is limited mostly by safety. I think in the safety world, in the software world, uh If you want to go faster, you do need to think through these safety mechanisms. If you feel like your team is just not shipping code fast enough, think about what happened. Why, right? What's slowing you down in a lot of cases, it's that when you go faster, everything breaks and then you're slow again. So you really need to think about these safety mechanisms and it's worth the time to put these things into place. Uh Basically don't turn into this team, right? Um Take the time, put these in place, you'll end up going faster. Uh If you want to learn more, my two books talk about these concepts quite a bit. So tear from up and running and Hello, startup. Um If you need help with any of these infrastructure and safety mechanism, things, feel free to ping us at gruntwork and that's it. Thank you very much.

---
