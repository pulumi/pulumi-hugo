---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Getting Started with Kubernetes"
title: "Getting Started with Kubernetes"
meta_desc: |
    Learn how to manage Kubernetes clusters and API resources using Pulumi. 
url_slug: getting-started-kubernetes
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Getting Started with Kubernetes"
  description: |
    Learn how to manage Kubernetes clusters and API resources using Pulumi.   Mike Metral discusses the easy way to get started on the DevOpsInsights show.  Pulumi works with your favorite programming languages and any cloud. Get started: https://pulumi.com/start
  sortable_date: 2020-04-17T15:40:27Z
  youtube_url: https://www.youtube.com/embed/mKc-3nyYft0
transcript: |
    Well, thanks again everyone for having me. Um uh My name is Mike Ron and I am an engineer at Pulumi and uh I primarily maintain uh I think it like this. I primarily maintain our, our eks uh installer uh that is uh is running on a on Amazon. And we also work with uh with our provider which allows you to not only manage clusters but also uh deploy resources into those clusters. So I wanted to kind of just get a uh a walkthrough going around. How do you get started with KTIS uh using Kum? And it's really around how do you manage your clusters and your Apr resources in production. So let's kind of go over what we'll be reviewing uh in this session. So uh I'll go through a brief overview of what Pulumi is kind of the basics and, and how to work with Pulumi. We'll cover production KTIS architecture, what it looks like to actually running in production. Uh Many of us have have worked with many uh large customers globally uh to run in production at scale. So we've been able to make a lot of these, these defaults and, and experience and knowledge uh into our tool set and then we'll jump into demos. Um I'm, I'm hoping to, to have questions throughout the whole presentation. But if for uh need be, we'll be reserving some time at the end of the, the talk in case folks have any questions, but please feel free to drop something into the chat or uh or raise your hand. So what is Pulumi uh Pulumi really is a modern infrastructure as code tool uh that allows you to use imperative languages to describe your infrastructure. Uh Many folks are used to kind of using a templating system such as say cloud formation. Uh Maybe they're using JSON YAML uh or more often than not, maybe they're using like a, like a DS L like a terraform. Uh and in essence, right, the configuration management problem uh has, has been a a burden especially as the adoption of the cloud expands and especially as your complexities around the the architecture that you're deploying uh gains more resources. So really it comes down to the fact that uh it just hasn't quite cut it uh to use the the status quo. And we often reach for, for programming languages to help us in, in these these necessities, right? Being able to, to manipulate resources as we see fit and languages actually uh allow themselves to be very, very uh beneficial to these use cases. So, Pulumi is the ability to use uh any language or your favorite language, right? We support javascript typescript, Python go dot net across many of the uh clapper writers um publicly and on premise. Well, we have many providers that we can tap into. But the idea is that you can use imperative programming language to describe and declarative uh instantiate your infrastructure. Um It's really about leveraging really languages, right? And what languages are, are meant to, to give us uh but more so to just to be more effective at managing this, this complexity uh in this code sample. And you're right, this is actually an example of using go uh on GCP to instantiate uh a firewall and a VM. And it's quite uh it's quite uh crazy that we have the ability right to, to use languages to do this. Um And it actually gives you more beneficial gains because off the bat, you're, you're, you're using what languages are, are meant to be doing, right? You can share best practices with your default package managers, you get type checking lining, you have your ID E to help you out when you have errors uh as you're offering your code. Um and more so because it's code, you can do your usual audit, reviews your pr processes, your C I CD uh deployments, all of this, this code for your infrastructure can, can be co located or managed separately uh with your apps and really it's up to you. But Pulumi is about leveraging these languages uh to your full extent uh across any of the major providers. We are open source. We are Apache two license based. Um We are free for community users for life and where, where, where our business model starts is really around teams. Uh But even then we have the free that I'll get into in a bit as to how that works and then we'll, we'll jump into some more demos of, of Pulumi and Pulumi Cabernet. So it's not only cloud native infrastructure as code, right? That you can describe it's not just V MS and it's not just virtual networks and it's not just storage, right? All of these services are great and you're gonna use them, but more so, right, Cobert has become uh the forefront in in container management. So we support as well and if you've worked with the standard is working with L with Jason, with Ds LS, with, with Helm Manifest. And more so, uh this is even more a convincing reason why as the complexity of the the API resource surface area kind of continues to grow in COTIS it becomes hard to manage this with, with just general templates. And so there is no YAML, there is no JSON, there's no Ds LS. It's your favorite language to decoratively work up to the infrastructure that you desire. Um much like COTIS has these controllers that are in a control loop that are working towards a desired state. Pulumi operates in the same model but using imperative languages to drive a declarative desired state. And so this gives us the convenience of, of a couple of things leveraging uh imperative programming languages to manipulate and, and manage our our infrastructures as we see fit. But more so allowing you to have the declarative aspects that you expect such as previewing changes, diffing these changes, having rich status updates to see what's worked, what's not worked. Bubbling up errors is something we commonly do. So you don't have to go inject into working with. If you've worked with community long enough, it's, it's a, it's a game of playing, you know, 21 questions with Q control that my pot come up. Did it not come up? Let's see what events set up. Uh Maybe there's a po security policy as that's preventing me. So a lot of this, this uh discovery, if you will of, of errors as you're working with uh sorry, with Pernetti's in development, it becomes uh very nuisance. So it's not only a, a utility right to describe cornet's clusters and deploy sources into those clusters. It's really an effective means of managing communities in a much more scalable uh way and so on the right is actually a full uh working example of what it is to actually run uh on both GKE and deploy resources into those. So this is uh an example in typescript, I import our libraries. This is my usual editor, right. Uh import the libraries in this case because this text script, I'm pulling these packages from node all of our packages. Uh for Pulumi for the language of your choice are, are deployed on the common uh package managers that you expect, right? We use N PM for node Js, we use PP for Python, we have our github repos for gold modules. Uh And so the the the pattern that you used to working with, with the language of your choice translates very well to working uh with infrastructure and re through Pulumi in this fashion. But as you can see, I have 40 lines of code like that's, that's powerful, right? In 40 lines of code I ge generated oops, I've generated a strong password based on a, on an entropy library that we have. I've created a coupon cluster with the latest uh release that G uh GKE supports. I've passed my password into there. I've generated a coupon fig based on these clusters properties in uh Pulumi. We have this notion of a provider, a provider for kubernetes in particular is just a wrapper around the cup config file. This allows you to share clusters across uh different programs and it allows you to share clusters across different teams. Uh And it makes it interchangeable because you can just pass this provider in uh as we'll see in a sec, how we can swap this out if you want to have repeatable infrastructure across different environments different clusters and so you can write the code once and leverage uh leverage the use of it in many different ways. But this is, this is pretty powerful, right? In 40 lines, I've find a name space. We even created a new abstraction which I'll, I'll get into in a bit that allows you to uh write less code to create a pod, a deployment and a publicly typed four balancer for that deployment for engine X. So in 40 lines of code, we've we've already seen how much of this can be uh gained when you compare it to something like gamble manifest or extensive uh templates. So that's, that's all great and dandy. So let's let's kind of dive into some more details, right? Like Pulumi is ultimately a modern infrastructure is called tool that is meant to work in many different environments and many different languages, many different tools and environments. So we have many integration points uh with the common tool that you would come to expect um not develop our work with the same stack. So we support various source code from github uh its integration with uh via studio. Um You can leverage the many languages that we have for infrastructure code and you can write your applications in the same language as as they would come, right? Um There's no need to, to, to rearchitect your applications. This is really around the infrastructure and we also have integration points uh with your common C I tools, your common package managers uh and uh across the major cloud vendors, corne and even on premise solutions, uh such as vsphere and stack on the bottom uh is a preview of our dashboard, which I'll, I'll show in our demos, but you can start to see right? Like you can see the actual discs of what's changing on the left. You can then see in our console log, an audit trail who changed what it'll point to the commit, it'll point to the discs that are going to be actually rolled out. And then you can even even drop down and see the resources themselves and go to the actual resources uh on on the respective writer that they're deployed into. So really, it's about deploying code from and to anywhere and Pulumi has many integration points already with these. So you don't have to start from scratch. So how does Pulumi kind of work under the hood? Right? Uh at its basic essence, you know, we'll dive into a little bit of the details in a sec. Your user client is really where you author your programs and you run your programs, right? So I'll compose my Pulumi program in the language of my choice, the Pulumi cli processes that program and then invokes the language run time depending on the language that you ran, right. And in this case, if I'm running text, it'll uh spin up a note process and instantiate the infrastructure that I have described there that in turn, uh all the API calls will happen from your client to the provider. So we, the Pulumi is the Pulumi service which will get intersect. We don't see any of your user credentials. We don't make any of the calls on your behalf. We simply build the, we simply build the, the pendency graph of what your infrastructure looks like so we can decoratively roll that out uh and build it up and all these api request uh happen from your machine. So we don't have to worry about privacy and security issues where the police service uh comes into is because we build a state file much like Terraform has one. this state file is what we uh by default upload to our our that allows you to do uh really a couple of things. When you're working on the team, it allows you to do concurrent locking and state management of that shared state file. It does checkpoint um we have integration with our own config. So system secrets, you can integrate uh many of these different components uh into your programs and make them template, right? If maybe you want to, to see each program with a different uh random password or something to that effect. But more so it's around using this with teams, right? So we have team off ssor back and more importantly, a dashboard and set of workloads that helps you facilitate this that's uh very analogous to our, to our cli. So that's kind of how Pulumi works under the hood. But if you do not want to use our SAS, uh it's free and the uh it's free for community users and it defaults to it. You can also store that state file locally, um like an S3 bucket or an Azure Blob storage or GCP blob. But then you have to manage that state file yourself. But folks have been asking for that option to, to, to manage it themselves and uh we've given them that, that feature. So we're, we're proud that we have shipped that. So let's start composing, what is a pluming project? What's the pluming program and how this all fits in? So, a pluming program is the collection of your infrastructure that's running in the languages that you've chosen. Typescript Python go dot net. You write your program just like you would any program um And to instantiate it in Pulumi through the cli, we have to create what's known as a ploy project. And all that's required to establish as a project is a simple file for metadata that allows the cli to, to understand how to run it and then the dependencies that you would need depending on the language of your choice. So I may pull in some note packages or I may pull in some packages from pip if I'm on Python and this, this whole object itself is all that's required to actually run the program through your cli because programs should be repeatable, right? If I stood up a particular stack, like let's say a cluster that has all the standards that I would want uh my cluster, I I don't want to repeat that program over and over again. Right. That's, that's kind of what the moving, that's the movement we're getting away from. We don't want to uh to generalize templates, we want to be able to leverage programs and instantiate them. That's what stacks are stacks are instances of our community programs. And these are very analogous to your G branches or, or your staging environments or your environments in general for how you roll out your, your programs today. So you can have a dev stack of the same program and staging in a product and you can tag these stacks to, to filter and search them easier through blooming. And what this allows you to, to really do is is now have a holistic set of what your uh your infrastructure should be in a given program. And you can just parameterize the variables that make sense depending on the environment or branch that they're living in stacks are also capable of referencing other stacks. So if I wrote a Pulumi program, uh let's say like my Cober cluster and TED script, and then uh I wrote another Pulumi program in Python that say stands up uh a managed database as a service I can have stacks reference other stacks. So this allows you to decompose to layer each of your infrastructure uh steps uh as you see fit. So you can imagine that if these were two teams, the less maybe with our ops team who's in charge of instantiating the clusters. And the right is the application teams who's just allowed to deploy workloads into uh the cluster that we stood up. So you can start to segment this and, and organize this uh in however way you, you see fit and whatever makes sense for you and your team structure. So really plu programs are a way of enabling infrastructure, right? You dec you describe what infrastructure, what resources you want in your program, whether that be V MS, an object bucket block storage, virtual network or C and the cli will, what it will do is ultimately create a state file that looks very much like what's on the right. This will ultimately reflect what's real in, in the writer of your choice, right? The API request will, will, if I'm saying I'm running on Amazon will leave from my client machine, it'll instantiate the cumin cluster and the VPC and then the state file is what keeps track of what the the current state of the world is. We have the ability to also fetch the current state, right? So if I deployed two V MS and someone went in uh to the dashboard uh on AWS and increased it to three VM si can do what's known as the plume refresh to fetch the state of the provider. Make sure my local state is reconciled and then I can do any updates if there are any changes from there, but the code is the desired state and that's reflected in our state file again. By default, the state file, we default it to running it on our, on our uh that's free for community users and, and teammates uh of certain sizes. But really if you wanted to manage the state file yourself, you could do it locally. But then the, the onus of you managing yourself and make sure that that folks aren't stomping over each other on changes is gonna be something that you're gonna have to uh implement. So I wanted to just do a quick poll. Um I'm about to get into some of the Cotti aspect. So if those of you who would like to participate, I opened up a poll you can visit pole ev dot com S night after all 75. Uh This will help me just get a gauge for, for how folks have been working with KTIS. Uh And it help me kind of gauge the, the level of expertise uh that I can assume. So, I'll take a minute or so uh for folks who want to participate uh to vote. Great. Thank you. OK, great. OK. OK, great. Yeah, I'll just give this a couple minute. Or a minute or two. OK. Probably pretty even split so far. 0 to 3. We're seeing some youtube chats also. OK. Some, some newcomers. Great, welcome, welcome to, to the session. OK, perfect. OK. I see. We have some shifting changes. OK. Great. Um That gives me a better, a better gate. Uh And while I have you all, I'll do one more question just to uh pull the, the audience. Um it's gonna be the same URL. But this time we're going to uh see what uh what are you using to manage your Quinary cluster. So go for it. It's the same field. Should you see another question? Oh Quite, quite a variance. OK. So we have some folks in the cloud, a lot of folks managing the themselves on Prem. Wow, surprisingly, a lot more folks on Prem than they imagined. OK. Great. Awesome. Well, that's all the, the work I'm gonna put on you guys now back to me. Um But thank you for, for participating. This helps me this help to gauge uh where folks are at. So let's jump into the pieces. This is AAA cake diagram or really a diagram of many different layers that we like to, to use with Pulumi. Um because it showcases when you run in production, these are the various layers at the at, you know, at its more at its most uh smallest instantiation what it looks like, right? You have to work with the provider at the bottom to instantiate the typical I, then you have to work with whether it's managed or self managed. Uh And then once the cost up and running, that's where all the work really begins, right? Creating the cluster services that are general to the cluster itself, application services that service particular app needs and the applications themselves on the left in the brackets, we've denoted the various Pulumi XDKS that you can use which with each of these layers, right? So if I'm running on Aws, I can use the Pulumi Aws and Aws X uh S KS to instantiate things like V MS uh virtual networks, manage services, et cetera. And I can even leverage uh our Pulumi Eks uh SDK, which is uh an installer and a manager for uh EKS control points and not only instantiates the cluster themselves but starts to help you set up uh more, more uh of the, the features you're gonna need once you're actually running in production. Um And once you're actually, so these are really about infrastructure and standing up the necessary requirements. This is really around the, the management of the control plane. But once the cluster is up and running, you now have to deploy resources into those clusters. So that's what the Pulumi cabernets and SDKS are meant to help with. They're meant to, they give you, they expose the full api uh resource of all the resources that you would expect. Like deployments services config map secrets, those all exist. We just simply take the open API spec and ex uh basically extrapolate that and export it through an SDK in the language of your choice. So you can use text to generate the same uh the same resources that you would expect such as deployment, config map secrets, uh et cetera. So it's very much analogous to working with the or Jason, but you're doing it in a language. So you can see how this gets very complicated, right? But it the, the proper approach is this should be a very layered approach that, that really defines um the structure that you have in your teams, right? If there's operational teams who are, who are strictly in charge of infrastructure, you can typically say that they'll be running the infrastructure and the clusters, then you have maybe your, your developers who are deploying somewhere uh between apps and app services. And so you can segment these by different programs, you can segment them by responsibilities, you can segment them by, by roles of, of people. But ultimately, as, as we showed with spec stack references, you can, you can piece meal this in different languages across different programs uh and construct the, the, the, the stack that makes the most sense to you. Let's jump into some demos, enough slides for, for now. OK, great. So everyone can see my terminal, correct. That's cool. All right. So I touched on some of these subjects. Uh I'm gonna cover some different topics here on, on uh how to use me with. So this is what a typical balling program looks like. I have type script. Um I have typescript and in this case, I'm instantiating a Ggke cluster. Uh I'm giving it three nodes uh giving it a user name and password and constructing a Q config and then I'm creating a name space. Uh And what you can uh see right is if I decided to, let's say, change this uh to, let's say my apps. If I use the Pulumi cli, I can say Pulumi stack. What's my current stack? I'm in? All right. When you stack, when you stack at last, I can see all the stacks that I've created. If I do a Pulumi preview because I changed uh the name of the, the name space. You should see a rich diff of what's actually taking place. So it'll see that it'll actually change the name from apps to my apps. You may notice that there's this random suffix that we append to each of the resources. The reason we do that is because by default, we allow you to uh to reuse these, these programs right across stacks. So more often than not, you don't want use a static name to, to describe uh infrastructure that can coexist across many environments. It, it makes more sense to treat it more, more randomly, right? More like cattle than, than pets Now, if you were really wanting to like particularly say no, the name of this name space needs to be a fixed string such as apps, you can simply just do that by saying uh in the in the metadata um of it to change that into my apps declarative. But the point is right that you can see rich, rich diss of what's changing precisely. And if I ran up to me up, it'll present me with the preview that we just saw and it'll ask me if I want to form this, this update. If I could see a more richer uh set of details, I can see here's the exact uh property that's changing. What is changing to what's being added and what's being removed if I run that. Yes, what's gonna happen is it's going to uh pull me up to the model where it creates a new resource before it deletes an old one and it'll update any references along the way that may point to that. So what we first will do was create the new my apps namespace. Once that's, that's working, we then confidently can delete the old app's name space and within a couple of seconds, hopefully, uh this should complete. But as you can see, we have these live updates uh uh happening uh with regards to the to how we're pulling the cluster uh using client go in the background. The ploy SDK is, is that it's a, it's a piece between client go and the Pulumi Cli engine that knows how to uh retroactively construct these graphs, build them uh appropriately uh based on dependencies. And more so than not allows you to, to reconstructive step through your infrastructure. Uh as it, as the, the, the pieces and dependencies make sense. So this will take some a couple little bit because I think I haven't uh I had an app running. That's why I'll cancel that because I actually deployed an app into it. That's why it's not deleting. Uh So I'll actually pull I can cancel this update I already completed. But if we do, we check out our nodes, let's see what her name is. Yeah. So it's still determining that old one because I, I actually have an application and the next console uh using that. So what I wanted to do was really kind of showcase, right? This is not just about deploying clusters, it's really about deploying applications as well. So I can in my application, I have a new pain here where I said, hey, I want to reference the pun fig from this cluster which I define here. And I want to wrap it in a provider for GKE A provider again, is just a wrap around cup config that I can actually give it a name space. So I can say deploy this name space uh along with this coupon file and this demo app should actively work with uh with that actual provider. This demo app is actually a new class we created here on the right. And this is just an ex uh and a new class that extends our component resource in Kalu, which is really around allowing you to customize what resources should lift together and be managed together. But I am actually building a local note app using uh a Docker context path locally so I can read my Docker file, right? If I look at the actual app itself, I'm going to the Docker follows here, right? It's just, it's just gonna pull a local hello world uh and run uh run it through node. And what that's what that's doing. It's actually building the image in this uh in this uh file, tagging it and then pushing it up to the registry in this case, uh It's uh GCP or sorry GCR I can then also describe so in like four lines of code, I've built my image and pushed it and tagged it uh to a registry. I can also similarly create uh persist persistent volume claims, config maps, secrets, uh pods, deployments and services and just a matter of, of a handful of lines of code. And this will actually create, write an actual application. So it's pretty powerful that I can use languages in this respect because as you can notice, right, I can reference particular pieces that make sense. Um So for example, if you've ever worked with communities long enough, right, you have to pass an environment variables. Uh And so you can reference these just because it's a language, let's go into more detail on like how that actually works. So here's an example of the various ways we can use gluing uh with, we can deploy emo manifest, we can use our CNET SDK to deploy resources uh in in the entire space of the API uh service area. And then we can also do the same thing but with less code and less boiler plate using our XSDK. So let's see what this looks like to deploy YAML. Here, I have a typical YAML file on the right. I have a deployment, right? I have a service, I have config map, I have a secret, I have a P BC. It's a standard file if I'm in the process of say migrating from uh a YAML or Jason oriented environment into potentially like experimenting with Pulumi, what I can do is I can actually leverage the SDK that I just pull from node and in the community SDK along with all the API S like deployments and pick up secrets. We also have the ability for you to deploy a local gammel file. So if you were running this, uh we would actually have the case where if I do a Pulumi up, it's gonna be a no up because I just ran this earlier. So it'll update this. Uh Yeah, because I changed the provider. That's right. So I wanna perform this update, I'll say no for now. Just so I don't wanna break the demo, but here is the equivalent. So this is the point in YAML, right? So if you don't want to fully uh translate all your code from YAML to typescript or Python, you can deploy a YAM manifest uh to help you transition. But if you want to actually leverage the full cotis uh surface area here, you have all of the kinds and groups in uh in that you would expect, right? So this is this is uh spaced out depending on, on where the the group and kind for the given resource lives in the API. So you can play a config map, a secret a person volume claim deployments, right? And this looks exactly just like our Yam manifest, but we're doing this in a language, right? So to compare here's what the deployment looks on the right in Yaml, right? And this is what it looks like in TED script, pretty similar, right? But now we're doing in some languages and this is great. We can we can immediately start to leverage the language to say do referencing of given objects, right? As you would expect, rather than trying to hard code uh our values, uh you can proactively uh extract pieces of information such as the IP of this load balancer. Um You can wrap it in a in an interpolation to create a string that so we can create this output, right? That'll, that'll ultimately link to the URL S that we've deployed. But this is, is really the power of not just managing clusters, it's really about managing resources. And so you have the full surface area of communities to, to leverage, just go and use the resource depending on where it's mapped in the same uh style as the API resource. We don't invent new nouns, we don't invent new resources. This is exactly what you would expect coming from the communities world. We worked very hard to make this as close to upstream as possible. Again, we take the open API spec and we just expose it in the language of your choice through a library. So we are not reinventing any of this or we actually have bots that every time the release is cut with within about 2030 minutes. These libraries get updated with the latest specs. So we can describe our infrastructure, right? Uh In this case is a typical Apple deploys engine X but as you can see, we have 100 and six lines of code. This is a great start because it's program languages, but we can do better. That's where Ktis X comes in. Kris X is a helper SDK to allow you to use less code, describe less boiler plates and still create the same semantic output type that you would expect. But using languages as the the workhorse for, for doing a lot of the heavy lifting. So you can describe the same config maps secrets, persistent volume claims. And using this new concept that we have a pod builder will actually construct the pod spec for you. And then you can reference that in a deployment and a service in 61 lines of code compared to 100 and six lines of code. So we've described the same application and uh using 40% less code uh than we did prior. So these uh communities act is really powerful because it allows you to to really just get out of your way and, and focus on on what makes sense. It's easier to maintain, it's easier to read, it's easier to manage. So this, this is a great utility for folks who are learning Cobert. We, we a lot of our users are still starting off with and it almost makes more sense sometimes that the author should experience to reflect some of this. So you can see how these, these pieces can be composed, how you can this them together and, and really what it is to, to fully kind of grasp the full surface area of working with core because it is just so vast and, and big, let's move on to another demo I have. So here's a demo I have where I stood up a cluster in Amazon Eks and I'm actually leveraging uh the ability to create an O I DC provider because I want to assign our back uh to each service account for a given pod. So I want to say I'm going to actually deploy a Cotti service on EKS. And then I'm going to deploy a fluent D cloudwatch. He chart because Pulumi can also deploy he charts using uh this cluster and the O I DC provider that we've created because EKS by default, for example, does not come with cloud uh Cloudwatch logs. Uh for your cluster, you have to bring this yourself, they recommend fluent D. And so let's see what we actually can deploy here. So in fluent D is class, right, more so before I jump into that, right, it's because I have a language I could have also my, my ID E yelling at me when I don't have the proper uh spec being mapped out or if I want to jump into the documentation, I can see all the documentation of the option library. Here's the type it's expecting, here's more information on on what this option is uh some reference material and it's pretty much like working with code, it's exactly like working with code, but for infrastructure. So this is pretty powerful stuff. If I jump into the definition of Cloudwatch, right, which it's in this next file, I have a class that's that I've extended again for my own component needs, that's creating a service account that's creating uh all the R back properties and communities like cluster roles and role bindings. And more importantly, a log group in Aws cloud watch to store all of my log in and deploying the helm chart is as easy as using the KNAS SDK. And this time deploying a helm chart to actually uh run RND. One thing to note here is that our support for for helm started uh with early V one and we never depended on Tiller. Um So Tiller being removed and V three was, was not a big uh changer for us because, well, the way we use Helm here is really about taking the templates out of the tree and trying to render those on, on each of these objects. And so that allows you to, to get up and running faster if you just want to use the helm chart that exists. But as you can see, right? When I, when I describe the resources like I've done here, I have further fine two control of how I can reference variables if I'm natively describing them in Pulumi typescript uh or any of the language for that matter, health charts are different because they're opaque, they're not as transparent, right? Uh Because they're really uh managed as a single entity. So I can, I can definitely adjust values, right? If I'm usually working with like the values uh man uh the values file to, to parameterize this, but I can also leverage transformations that allow you to retro retroactively transform uh uh something within the chart. But what happens is that the Helm charts are, are going to vary on a case by case basis on, on how easy they are to manage and how complex they can be, let alone how often they get updated. So most folks tend to actually fork a popular Helm chart, edit it themselves locally in a, in a private repo and then deploy it that way. So if deploying Helm Charts is something of interest to you, we can definitely support that as well. So we deploy the fluent D hum chart and uh of notes, we actually say, hey, in the R back values that we've defined here, you're going to actually use this servers account we've generated for you. And why are we going to use the service account? Because we bound this service account for fluent D to strictly only use the, the policies to work with cloudwatch logs that we've defined it here is where all that is done. So if any of us, uh any of you have worked with Ekseks requires that you have to have an O I DC provider and you have to create a uh an IM policy that is particular uh to using what's known as an assum role with web identity action in the secure token service that they offer. In turn, what this is doing is if you have a pod and the pod is using a service account, it's going to off against the O I DC provider to get a token saying, hey, this pod is valid. It's a real pod. I have its identity and exchange the token and your clusters O I DC provider for a token in Amazon to run with the policies it needs in this case because it's fluent. D we're going to give it the logs permissions. And if you've worked with IM policies in AWS, this is very analogous, right? I'm actually stringify uh an object in JSON to pass in the policy where it's going to be able to control uh logs in the log group that I've used. So this policy allows me to not only get least privileged uh uh access to, to AWS credentials, but I can further tweak it by giving our back uh specifications and saying that this can only be used uh with a, a particular cluster role that, that ties down these rules and it binds that cluster roll to the name space uh in which this pot is running in with the given service account. So when I run this program, if I do a Pulumi Pulumi update, because I already ran, it, changes are item potent. If there's no changes, you're gonna get a no op So, because I ran it before the uh the demo started, we should see nothing changing here. Um And ultimately, once this completes it, say, um ah I changed uh oh, funny enough, we actually just uh released. Uh So this is one of the cool things about uh using programming languages and the fluent D helm chart. I'm pulling this from upstream, fluent D on the, on the Helm charts uh repo they actually leverage an older API right extensions V one beta. And so in Pulumi Cotis, we can actually tell you, hey, this API group and kind is actually deprecated if you wanna consider moving away to a more stable build, so you can actually update it. So this because I'm using this from upstream, I don't want to change that. Um So I'm gonna cancel that, but I'll show you what the output of actually uh this is. So I can say once I've created a fluent D hum chart, what I want you to do is give me the log log group name and cloudwatch where you're storing all of the the pod logs, right? If I have all my pods, I want to see all the logs for these pods. So if I do an output, like I've done here, I can get this all generated log group name and I can go to pod watch and see what that looks like. And here are all my logs stored uh for my EPS cluster using code using list privilege and using an L I DC provider. So we can see how there's many different ways that you can leverage Pulumi to, to really work with communities, right? We've, we've gone to, to the, the idea that you can leverage many different providers to create the clusters. You can leverage uh many different packages of ours to instantiate resources. Build the do images build the resources, deploy them into the clusters segment. This by the level of security that makes sense. We've seen how you can use Pulumi to deploy YAML manifest, to deploy resources and to deploy cos resources using less code uh and more. So you can see how you can use Pulumi to deploy helm charts. And all of the production needs that you would need to do to actually run an application in community is uh the way it should be right with proper im permissions with security policies, whatever makes sense to you. And so these standards are really going to to call on, on you or, or your operational teams or your development teams to figure out what, what should a standard cluster look like? What, what should a standard uh uh virtual network look like? What should be uh supported out of the box day one, right? Something like a fluent D cloud watch to, to expose logs this should be built in. So maybe I start creating a new class where my clusters are automatically deployed with a fluent D Cloudwatch home chart just so I can allow them uh my users to actually use this. So I've gone through a lot but need not worry there is uh a set of links and I'm going to be showing this whole dock um uh with you all in the next slide. So there's plenty of getting started guides. Uh You can get more information how to work with Pulumi. Uh Here um Are we have production playbooks that are a set of uh Pulumi stacks that mirror each of these stacks and a and a divided in a segmented way that allows you to run communities in production. And we have already uh reference architectures for Amazon's EKS for GKE and for a KS that allow you to run communities in production uh with a, a reference architecture that's improving embedded through, through uh experience in the, in the real world. And more. So we have an example of Repo that has over 100 and 60 examples of all sorts of languages uh across many different providers across many different use cases that cover infrastructure, containers, service and KTIS. That's all I had prepared. So I wanted to open it up for any questions uh or any comments or any feedback if, if folks had um this uh QR code is a direct link to this uh to this slide deck. So please snap a picture if that helps. Uh And here are some more helpful links as to how you can help uh you, you and your team learn more about and working with and with that, I will take any questions. Thanks Mike. That, that was really amazing. Um Let me share the call you out so that people can join us for a question? Um Sure thing. OK. So um let me check. So you mentioned that uh on the, you uh you can take care of secret also. So is that, or can I use uh your this instead of communities about secrets or is it complimentary or? Yeah, great question. So it's kind of two fold, right? You, you, you need secrets to kind of uh for the parameters if you will, if you have different uh stacks for the programs. So these, we have our own uh essentially K MS key management system, but that back end is plug to to many different uh uh systems. So we have, we support Google's, uh we support Amazon's and I believe we also support Azures. Um As far as goes those secrets, right? That would be if you wanted to deploy a bolt or A K MS um that that's going to fall on the cluster itself. So we have AAA good story around uh enabling a config subsystem and secrets within the, the project. But then once you get to the cluster, you're gonna have to figure that out or with using something like bolts or any other other uh secret managers that exist out there. OK. Cool. And um let me see, I see a question about uh test driving development. Yes. So uh there's actually some great blog posts that I can link to. Um that uh that allows you to leverage the same unit testing, integration testing. We have some great mocking uh blog posts as well. If you just visit our our blog blog dot dot com, we actually just released a couple of these, right. Um We have policy that uh we have policy packs, which is something I didn't cover. So just like you can describe infrastructure here, you can also describe policies like uh saying in the language of your choice. Uh No S3 bucket is allowed to be created that's public to the internet. Uh Don't create a unencrypted block storage device, right? Don't create a cluster that has uh public IP S attached to the nodes. So you can, you can uh use policy packs to enforce policies. But in this case, uh for example, we can even show how we can enforce resource tagging. Uh But the question about mocking and testing, right? Uh where is this blog post here? We have a couple of great blog posts on unit testing. Um If you scour it through our blog, there's even more. Uh There's we have something else in the works um around how you can test and optima optimize elastic search. But yes, you can do TDD uh in the language of your choice. Uh It is you have to have like a seed file more or less that, that helps you kind of create a baseline for how to do testing done. But then you can leverage your usual utilities like MOCA, right? If you're working uh with those utilities? Ok. Let's see. The next question. Can the script code have logic like posting, callings to an API and await its results? Yeah. So the great question, so the way that Pulumi works is um is Pulumi is really an API of many API S, right? So anything with a credit interface is is capable of, of being leveraged. Um And so what we can do is if there's a crud API, you can actually create a provider much like, you know, you said Terraform has providers, we have providers to do, we can tap into the terra terra form providers and leverage everything that has. But it's really just a bridge between, between our logic uh and just leveraging the ecosystem that exists. But we've had many uh applications uh in uh popular cloud native services that have wanted to create writers for Pulumi. And as long as there's a crowd api we can uh create a provider around that. Um And that allows you to make these external API request to something that is not say managed by Pulumi. And of course, you can await its result uh because you have the language uh to actually leverage the a sync and await properties. Yeah, that makes sense. And there's another question about secrets. Um How do you manage a secret for your clients if you have to create new keys, connection, string, et cetera. Yeah, great question. So, uh here I hadn't got into it because I didn't know if we don't have time but. Oh, perfect. So, uh here is, well, let me just have a simpler example. Here's a, uh here's the current project I'm in, right? I have an index file which is my main, I have a stack name. Uh That's, it's really at this file. I can see all the, the stacks that exist. Here. I can see. Pulumi can I can see the config settings that I set just the region, right that I want to run in. So to get into this uh uh the secrets around uh around this, I would say I can do Pulumi config help. And here I can actually set a secret, right? Such as set a secret, let's say. So we make this a little bit smaller set. OK? You can hide the bar at the bottom if you want to. Yeah. Yeah. Yeah. It's, it's not going away anyway, there's a, there's a link that says hide in the sharing. I see. Perfect. Um And when we, when we actually set a secret, right? You can actually say, how do I actually set a secret? So I can say set this secret uh food equals uh my password. Oh Sorry, I need to do this uh for the command. So you actually see. So we actually do Cypert text on this, right? So you can gate the. So what this config system really is, is a way to seed into um the the ability where if I have having a big file, no, I have a big file here. So I can say, hey, from my config pull in a given uh parameter, right? And so I can see secrets that way. If I wanted to uh put it on a per project basis, I can say I can set secrets that way. Uh But more so if I wanted to do things like connection strings for like databases, right? What I really want because I have languages. Uh Here's an example of running R DS. So here's an R DS instance. Uh So R DS is a managed post uh uh managed post case database on, on Amazon. And I can set a random password, right? A strong password, a, a typical user name, uh some uh the name for a database and actually extract that property to create the secrets with the DV host or user name password. And it can, I can pass this object along if I export it to other stacks um that want to reference it. So I don't have to actually have to concern myself with the details of what's actually taking place nor expose that in any single way. And any property that is a, that is a secret in nature, such as the password will automatically label the whole object as a secret. Much like this looks like this. So you wouldn't be able to see. For example, like if we do, let's actually let's actually do that. Let's let's see what the example looks like in here. So I haven't exported that. Let me export this. So if I export it and I do it plu me off, it'll say, hey, here's the new output. As you can see this is a preview um because we don't know what the output of this will gonna be look like, right? It's like a future. It's a promise. So we as a preview will say, hey, this may change. Um But because we exported it, we know confidently that nothing is actually in practice changing. If I run the update, what's going to happen is that it'll, it'll just expose this when I do ploy. So see even the metadata itself is confined as a secret. If I do uh gloomy stack, output that DB connection will be hidden as far as the properties that, that make it sensitive. And I can reference this by saying here's the stack, I can have another program, say reference uh my user name with this program on this stack and from this get the object DV connection so I can use that DB connection in my application. All right, let's see what other questions there are. Um How do you deal with rate limiting thunder her problem connection, time analysis of the framework? Is it our responsibility to handle the retrial logic or the P Pulumi framework has strategies. Great question. So we have plenty of retry logic uh at every step of the way. But ultimately, you are going to be gated by the provider, right? Uh If you're hitting the, the Aws, say cloudwatch api too much as, as, as can be done, say with PD, there's lots of pods that's ultimately something that A that Aws is gonna limit you on. But we have retrial logic where if I watch, if I know that something is going to not necessarily work, let's say, let me break this. For example, let me intentionally break this just so we can see uh something actually not, right. Let's say I created a, I don't know, might change the version number to something I know does not exist for two and D I'll do an update and it'll try just like re tries to run the program, it'll try doing that and it will continuously update you uh with any failed error messages or any status updates for that for that matter. So because the the the chart here is something we, we actually allowed to, I see it's not found. So I actually thought this is gonna retard, but it's because we fetch it. It actually errors and tells you, hey, we can't find this and then we're giving Rob repository. But if I did it even better example, let's say trying to think of something on the fly here. If I wanted to say ah here we go in this, in this one, this particular pod uh in this particular cluster, I require that all. Uh I have a, a pod security policy because I have a quota. It says pods must describe how much requests uh they're using, right. So if I remove that, it'll keep retrying and retrying until I add that. Right. And, and unfortunately, um because I have a quota for right on this matter, um It won't let the product actually come up, but you'll see that Pulumi will. So as I, I remember, I'm building this container and it's updating it, but it'll continuously try as Cuber's tries. So in here, because I automatically uh have the ability to, to push and, and tag images, I can automatically do that. But the spec changes on the deployment itself because we've told it to, to not have anything. So you see, I have these updates where it says, hey, I'm still waiting for this replica set to be available. I'd usually have to go to like Q control to tell me what this is when this does error out. We time out after about 10 minutes or so for most of the API resources, that's the default, it'll give you the actual output saying, hey, you couldn't create this red book set because of X reason in this case, right? If we were to um I'm gonna cancel this just for the sake of, of getting to a demo. Uh oh I actually, so I, since I canceled it, it deleted it. But in other words, it said the pod wasn't able to actually come up because I actually have uh a lack of resources and its specificity. So uh Pulumi will constantly update that, that information for you, right? With any information it may have. And once it actually time out in this case, 10 minutes, you can also make that time up custom, right? If you know an object takes 20 minutes and it's only adjusted that way. Um What are the questions? Cool things. Thanks for the answer. Yeah, great comment. Thanks for the answer. We are using grenades and Azure as we, we managed to automate some this uh using arm templates. How does school integrate with existing templates? Yeah, great question. So uh because we have no, no, no Jason uh no, no templates, right? It's really around um that leveraging something like an arm templates or a confirmation templates. That's just unfortunately not the, the path that we're going, right? We're trying to get away from ya. We're trying to get away from Jason, we're trying to get away from DS LS. Uh because we ultimately are, are firm believers that programming languages uh are just AAA firmer and more, more proven tool for, for managing uh infrastructure at this scale. Um So I, I would say that we don't, we don't have a clear support for that. Um We are working directly though with a lot of the providers to try to have first class support for these templates because we've gotten a lot of uh indication that folks may want to have more first class support, right? Because if you're leveraging something like uh like a telephone provider that maybe hasn't been updated, uh you want something a little bit more uh more uh proactive, right? As far as making sure bug fixes and and API features are, are gained. So we don't have that. Uh but we've heard that loud and clear and uh and appreciate the request. Awesome. So you mentioned uh Pulumi and Pulumi X. So X is like a higher level API correct, right? So uh if I go to the, the and if I use X and that I need and that I realized later on that I need something slightly lower level, can I use? Can I combine, combine both? Uh Absolutely. That's cool. Yeah. So here, for example, I have, so here I import the communities. Well, as you can hear the KX, I can, I can mix and match this right here. I have the deployments uh from the actual community SDK and then further along is the same example in KX, but you can mix and match this right? Um to some degree uh that said KX is still very early preview. We're, we're still trying to get the a lot of the uh the stability worked into it. But for most general cases, uh it should be pretty effective but you always have the original SDK to fall back to if K just is too limiting for you. Do you, do you expect most people to, to be using KX in the, in the long term or? So? We would hope so, right. Because this is a right, the equivalent of the, on the right using the SDK is 80 lines of code versus A X 40. Right? Ultimately, yeah, it's more concise and these create the exact same output types that you would expect. So you, you have savings uh in our, in our experiment of at least 40 to 50% of the amount of code you have to write again because the surface area of communities is so massive, you have to understand that there's there, it's very hard to find, you know, different ways to optimize it. But we like to say we are creating helpers to reduce boilerplate because we're not trying to create a new noun. We're not trying to create a new way of, of managing this communities as complicated as it is. We want to make the experience just a little bit more pleasant. Uh And we think that communities X is, is in the right direction uh to help folks not only learn communities faster but manage this and tame the scale uh with ease. OK. That's, that's really great. Um I see, I have a few minutes if you have time, do you want to show us the, the A UI a bit so that we can get an idea of what it looks like. Abso Absolutely great question. Uh So let me show you something. Let's see. Something expansive. I see that. All right, perfect. This cluster. I can go to my by just clicking on that. 00, I have a question. What is Pulumi relation with CH CD? So Pulumi uh much like you do Pulumi preview uh and Pulumi update that is essentially the, we have integrations with all the C I CD providers uh that I listed here. All the major ones you would have come to expect AC I github Jenkins uh github actions, codefresh circle C I. We have integrations with all of them, but they very much operate in the notion that you can do a preview. So when you create like say like APR, you can do a Pulumi preview, see the full uh preview, what's gonna change. You can approve that pr uh or disregard it. And if you were to say merge it, you can have it on the merge command, do a Pulumi updates. Uh And so you can do uh uh we have a lot of, we have a docker container that allows you to, to get going and we have integration points of all C I to leverage this. We are very much in the mentality. Pulumi is best managed in the get off style leveraged uh and managed by the C I CD. So, yeah, great question. Uh If I have my own C I CD and I want to add support for um Pulumi, can I do it on my own or do I need to get in contact with you? No, you can definitely do it. You can definitely do it on your own. Our, our Pulumi Pulumi uh uh our Pulumi docker container is on Docker hub so you can just pull that and and merge it into uh into the sea. I that makes sense if we don't support it yet. But yeah, it's a dark container that, that allows you to just kind of hit the ground running. So uh the console, right? So I clicked the link here and it took me to my console over here. So in my console, what I, what I have is um I haven't seen but oh yeah, we do have bit bucket support. Um That's probably not reflected on the, on the slide. Is it? No? OK. We should probably add that. Oh yes. There I know there is big bucket support. So uh Amanda, you should be good um on the console, right? This is the the various stacks that I have for this particular cluster. So I can see all of the resources that I've created. This is, this is the outputs, this is the configuration system, right? All these maps, if I do put me config these all map the same configurations that I had here. So you have an actual dashboard that has information I can see uh metadata on the version control system being used and then the outputs that I've created anything that I want to output to the user or to another stack. I would do it through uh through an output here, right? This is how I would expose data that I can share or properties that makes sense, but more so I can see an activity of right. Here's the actual commit, here's the branch I'm working on. Here's the details of this update, going to the update, I get time stamps. I see a full uh general overview of what's going to be created. You, you can get these same exact outputs uh in pr comments when you do a preview. Uh So you can see the full spec of right uh of what this looks like if you are using CR CV, I can see the full diss if I want the full actual di of what's being created. Uh I won't bore you guys with those details, but more so you can see a timeline of what's changed when it changed. Who did what, what auditing aspects? Um You can see the environment information, you can see policy packs. If I have policies that I want to enforce uh at this stack or an org level, I can, I can define them here in the language of my choice. And I can see a full resource list of what's being created in this stack. So I have everything from the name space that I'm creating the resource quota, the cluster itself, the security groups for EC2. And I can even see this in a nice little kind of dependency graph that allows you to kind of zoom in on kind of the dependency tree uh of what this all looks like, right? You have the stack then from the cluster, uh you have any dependent on that cluster, I can actually jump into say like the EKS cluster itself. I can then uh view the view the security group in in AWS by clicking a link, right? And take me directly to that resource and see that resource in in actuality. Um Same thing for say, right, like the cluster um any where, where it's supported. Um But more so than that, right? This allows you to not only visualize but manage and, and really have a, a dashboard for information uh and control flow around who did what? And you can gate all of this with our back. Um This is analogous to gating the same R back as you go with the CL I, they're one and the same. Um But it allows you to, to have a AU I for, for folks who are, are more uh information driven or more dashboard driven. Uh And we're actually considering uh trying to figure out how we can implement certain work flows for folks who may not want to necessarily drive everything through the cli um So this is a, this is a great utility. Um We, we automatically, yeah, go for it. So right now it's, it's written only but you plan on allowing people to write stuff with it. Uh write to our in the future. No, no. Uh it's not read only. No, this is definitely uh uh oh yes. Uh read only in the dashboard sense, right. Yes, exactly. Correct. And in the, the future, yeah, we are working towards, towards how to identify and workloads to help this out with this stuff. But uh in the cli, right, if I create a new project, um we have some list built into the cli uh push the pluming and do I can do Pulumi new and it'll give me a template system, right? Like I wanna do, you know Aws Python uh DEV ops name blah, blah, blah, give it a stack dev uh region. I want to do, say us S two and then you have an actual template. So that would be like doable from the dashboard, right? So equivalently, right? Something like this will be it something we're considering. Um we're still trying to figure out the, the schematics of what, what works there just because it's very, as you can imagine, it's very complex to kind of find a common ground that works for everybody. But the templating system is, is a good starting point. Um And just like this, I don't know, I can create, you know, any project that I would like um by using the template system and you can build your already created one, you can create um they, they too and you can create your own templates if you wanted to template it. That way. I see we have some questions. Yeah, but I understand we can use Docker in the pipeline if there's an error when allocating our research into groups start failing. Um This is support, roll back. Yeah. So uh because we like to drive everything through git, we say you don't roll back, you roll forward to a new commit. So on an on a change or on a fix, if something were to break, you would just uh uh you would do uh the change to sorry, I lost my desktop. Um You would choose the commits. That makes sense and then you can just roll forward and do a new update on that commit. So there's no sense of, of truly rolling back. You just roll forward. Uh Terraform has a remote backend estimate to store state, file remotely. Do you have something similar in order to avoid currency access and resource changes? Uh Yes, we do have your own remote state back end. So in the, in this diagram by default, we attach it to the S A just so you can kind of get up and running to store the state file, right that we describe here. But you can also take that state file and store it yourself locally on S3 on an Azure Blob storage or on GCP. But the benefits of doing it through the S A is that you get automatically state check point and concurrency walking. So that when you work on a distributed team, you're not stumping over changes when you want to manage it yourself, either in a local file system or in a blob object storage. Uh You're gonna have to manage that state file yourself and who has access to it. And ultimately, uh that, that updates aren't concurrently happening and, and affecting each other. So yes, you have the ability but uh you're kind of taking a, a self Avenger uh in that, in that path. OK. No more question. It seems does anyone have any more questions? Um You mentioned that for people who do not or cannot use the, the that they will have to re implement states, could you tell us a bit more about this aspect? Yeah, it's, it's not about, it's not about re augmenting state. Sorry if I, if I said that um you have the state file, you have to basically uh you have to have a while to uh manage to concurrently lock that file because what's happening is when we are actually working through our program, like let's say this one, right? We're building out like an entire graph and that graph uh, is, is kind of, uh, gonna depend. Uh, it's, it's reality in the world's gonna depend. What does that look like currently in, in your provider of your choice? And what does that, what does that look, uh, when you desire it to be in a, in a different state? So, the, the, the state file itself, you will always have, it's just a matter of where that state file lives and how that state file is managed. So if you choose to um manage that yourself locally, you then just have to have essentially a, a read lock or a right lock. Rather both on the state file itself if you did not use the A, so the state file always exists. It's just a matter of protecting the state file. OK? Um All right. I think uh we're done with the questions. Uh I don't want to steal any more of your time. Oh, no worries. Um Glad to do this. Yeah, it seem to enjoy. Great. Yeah, please please go to the links. Uh If you snap a picture again, it'll take you to the slide. So you don't have to hurry and, and write a bunch of notes. Um If this is interesting to you, you want to learn more and you can follow us on Pulumi Corp on Twitter, uh Pulumi on github. Uh My name is Mike Metro. And if you can also reach me at uh if folks have questions, uh you can also reach me at my, at Pulumi um dot com. Um, yeah, I hope everyone learns something. Um, and, oh, I haven't touched Pulumi yet and I'm considering using it for my team. How steep is the learning curve if you've already worked with, uh with infrastructure is code to begin with, say class formation or some sort of templating uh mechanism or terraform. Uh The learning curve is, is really not all that different. It's just a matter of learning the language uh that you're going to be operating within and how that kind of uh balances between the infrastructures code. But we have again, 100 and 60 plus extensive examples, easy stuff, medium and advanced um covering all sorts of topics that should help you uh start off in a much better point than trying to do it yourself. So if there's any questions, uh please open it up and we actually have uh a vibrant slack community. Uh specifically the the channel, if you're interested in, we have thousands of users uh where the entire team jumps in and helps as well as the community, helps one another out. So if you ever find yourself stuck or needing assistance, that's the best place to find support. Uh And the examples that that link are linked here um are a great place to, to start on the provider of your choice. And I encourage you to take, you know, to visit these slides so you can process this information, uh, at your own leisure and, and what makes sense to your schedule? All right. Um, ok. Well, um, do you have anything else you would like to tell us or? Yeah. Uh, so I was gonna say, uh, hi folks, folks on, on camera. Um, the, you know, the learning curves uh, to working with communities is high, right? As, as we saw with many folks that are, it seems like many folks that are starting off cabret, this is hard stuff. Um The the idea is to minimize the footprint required to get started uh to the to the the point of the question you just asked and languages we feel is a good starting point to help reduce boilerplates, to help avoid the copy pasting and to leverage the construct of languages loops, conditional distractions ID E tooling, error checking linking, right? That that's really where a lot of that is is premised on. But the the architecture playbooks, for example, that we have crosswalk for is really where the work begins. It, it's it's very, it's easy to, to say that, you know, once they stand up a coon age cluster in particular with, with like Amazon Eks or GKE, the work only starts there, right? Because you have to make these clusters multi tenant, you have to make them ephemeral. If you want to test life changes, you have to make them compatible to many different types of users. This stuff is hard and, and not everyone knows how to do this. The documentation exists, there's plenty of materials. But if, if there are already existing code, it's a greater starting point than trying to manually recreate tutorials, right? We have many examples where we've shown, you know, tens of thousands of lines of YAML uh being done in 400 lines of typescript. Um And the power is, is really quite there. So uh I would say uh feel free to, to give this a shot. It's completely free for community users for life. Again, we're open source Apache two. where we, where we have our business model is really for teams who are operating on a on or mentality, very analogous to kind of github, right? You know, you have Git is the Pulumi cli and github is our Pulumi. Um The a very much operates in that model. It's free for your general individual users for life and, and teams is, is where we, we have a, we have a, a monetary uh baseline for it. But it's really around leveraging leveraging the hard work that we've already done to, to get, get you started because this is hard, this is difficult. Uh nobody knows the full extent of all these languages, let alone every cloud and how these pieces mix and match. And then once you actually get into cos it's a whole different world. So leverage the resources that we have leverage the examples we have please feel free to, to contact us on Slack. We also do office hours, uh, twice a week. Now that we, where we open ourselves up, uh, on a Zoom uh chat for folks to, if you have questions we're having, we, we just had one, a couple of hours ago. Eu on the eu time zones. We have, uh, on Tuesdays at noon, uh, or rather 11 a.m. Ce t we have our eu office hours every Tuesday and on Fridays at noon, pacific time, we have our US office hours. Um I can, I can share a link with Patrick uh for folks who want to follow up, but it is the office hours channel, uh in, in so office hours, that's a great spot if you want more, a kind of, you know, live one on one with us. Um And, uh, that'll, that'll help, kind of help you get going. All right. Well, thanks Mike and uh thanks everyone for watching. Absolutely. And, uh, I'll see you soon and let me know if you want to do another. Absolutely. Absolutely. Thanks. All right. Cheers. Cheers. Bye. Bye bye.

---
