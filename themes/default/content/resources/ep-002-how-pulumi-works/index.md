---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Ep 002: How Pulumi Works"
title: "Ep 002: How Pulumi Works"
meta_desc: |
    Pulumi's CEO, Joe Duffy, offers a deep dive into how Pulumi works. 
url_slug: ep-002-how-pulumi-works
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Ep 002: How Pulumi Works"
  description: |
    Pulumi's CEO, Joe Duffy, offers a deep dive into how Pulumi works.   We also manage to introduce scene transitions and see Joe use a whiteboard!
  sortable_date: 2018-06-13T19:10:18Z
  youtube_url: https://www.youtube.com/embed/YMAe59BYzm4
transcript: |
    Hello. All right. So thanks for uh calling in. Uh I'm still waiting confirmation from my pals over here that this thing is actually working. I'm a Twitch newbie. So please uh cut me some slack. Um So, yeah, thanks. Thanks for uh calling in. So I'm gonna give a quick overview of uh how Pulumi works. And so, uh Luke Homan um gave a, gave a couple of demos of a few sort of getting started. And Hello, world examples to hopefully get a good idea of uh of how, you know, what Pulumi can do for you. I'll actually go through that just really quickly in case you miss those two. What I thought it would be fun today because Pulumi is actually open source or will be soon. I thought it'd be fun to actually go through how Pulumi works. It's kind of a novel approach to an existing problem of how to express, you know, cloud applications. Um And, you know, we've taken a different approach than most of the technologies out there and it's, it's not, you know, it's actually kind of a hard problem. So I thought it'd be fun to dive into how the engine works the points of extensibility and especially once we are open source, hopefully, this will give you a sort of road map to the source code. Uh So if you want to Tinker or, you know, dive into, to different aspects of, of plumbing, you'll have everything you need. Um So before getting into that, I'm just gonna quickly go through uh an overview of what Pulumi does for you and I'm gonna show you two ends of the spectrum. I think you probably saw in Luke's uh demos that, you know, we handle infrastructure, serverless containers kind of the entire spectrum. Um Because we believe, you know, really modern cloud applications are a combination of all of these things. Um I should mention uh you know, anybody who's following who, who kind of follows me on Twitter or knows me from past lives. I'm really excited about Pulumi because I think every programmer and the future programming languages really is about programming the cloud. You know, I was, I did a lot with concurrency and, you know, asynchronous programming working on a weight and C# and things like that. I think the next frontier is how people build cloud applications because we're, we're seeing a shift from, you know, thinking of infrastructure and application code is completely different things managed by different people. And I see sort of this grand unification to really have a platform for building distributed programs. Um It turns out it's a hard thing to accomplish. And I think after this talk, you'll sort of understand some of the, the, the nuances of it. Um So I'll, like I said, I'll just show you a quick, uh, you know, getting started with he with, uh Pulumi, I'll start with, I don't know how much Luke actually showed you some of these examples. But at the very low layer of the system, we have resource providers for all the different cloud vendors. So Aws Azure, Google cloud, we have Kubernetes uh support as well. At this layer, we're basically exposing every single property and every single resource for the target cloud as essentially a uh class. Uh So you can allocate objects and through the allocation of those objects, you're sort of expressing the infrastructure that you need for your application to run and it kind of blurs the boundary between infrastructure configuration and uh app code. But at the very lowest layer, we've got um super low level resources. So if you want to do like EC2 V MS, uh so this is a web server, it uses, you know, a security group and it's opening port 80. This is like very low level uh infrastructure code that is pretty common to see in cloud formation or arm templates or terraform for example. Um And in here we can uh yeah. Uh a me we've got basically uh sorry, it's not getting off to a good start. Um Let me show you a different example. Um So this example, so that was a really low level sort of piece of code. Um And if I go now at the super high level, we'll see it's closer to what Luke was showing you uh last time, which is OK. Now we're programming in terms of cloud buckets and tasks that go ahead and you know, use Docker files. And one of the coolest features that I think he probably showed is AWS LAM does uh or Azure functions or wherever you're deploying this to uh can actually just use lambda in your programming language. And so, you know, how does that work? That's, that's kind of neat. And we actually allow you to capture references to uh resources uh within your program. And so if you think of how people would normally express this code, uh I actually have a good example of a customer we worked with. Um And I should mention, please do feel free to ask questions in the chat. I will happily answer them as I go. So this is kind of where a lot of our customers are uh coming from. Um So anybody who's done sort of infrastructure programming on aws will be familiar probably with cloud formation. And so if you look at this, what it's doing cloud formation basically declares a desired goal state for your cloud applications by saying, you know, hey, here's a security role. Um And here's a code pipeline thing which they obviously, you know, C I CD system. Uh And interestingly, you end up with things like, hey, here's a, here's a Lambda and the way that the Lambda works is, you know, there are a variety of ways of doing this, but sort of the default mode is actually stick code inside of your YAML file. And so the unique thing about Pulumi is that you can just write code. And so we go back to that other example, uh if I can find it, um notice that we're just writing javascript Lambs and Pulumi run time is sort of doing everything it needs to do to sort of take that package it up and upload it to the cloud as part of deploying your application. Um And obviously doing that requires some sort of novel uh language uh techniques. So I am gonna go back and um to see if I can actually demo this one because this is kind of interesting. Um OK. So we think about the fundamental concepts that Pulumi gives you. Um So let's break them down, right? So we just wrote a program and that was the program I just saw you. So that's, you know, in a, just an ordinary javascript file. And uh we currently support javascript typescript, uh Python. And uh go uh in fact, later in this talk, I'll show you the go provider which I kind of brought online last week. And um and it's kind of an interesting case study because it, it's one language provider, but it's, it's fully sensible. So, you know, in the future, we can imagine Csar and Java support among other languages, perhaps somebody will contribute has or list for something like that. Uh Definitely Rust is something we've talked about. But the idea is that, you know, Pulumi programs can be written in essentially any language. And then, uh we'll see later, the Pulumi run time basically works in tandem with those language providers to understand the desired state of your cloud programs. And so, you know, this is a program, it allocates objects. So new cloud bucket, that's actually just something we call a resource. Um And so the web server example, we saw earlier just resources here, you know, cloud task, it's just a resource. Um And so resources are the fundamental sort of units that you're operating on inside of your, your programs. And the magic that we figured out is basically how to take those objects, you're allocating at run time and essentially map them to cloud resources uh that are actually the physical resources. Um And so when you look at cloud formation or arm or terraform or any of these, these systems, what they basically do is they take your program, they evaluate it and they figure out from that. OK. Uh What are the set of operations I need to perform to make reality match the desired state expressed by this program? And so if you think about it concretely, in terms of this one, just take the, you know, this, this simple line. Well, when we run this program, it's gonna allocate a bucket object, the bucket object will have some properties on it. This one turns out it just has a name where you can see the cloud task here has a number of things. And so Pulumi will take that and basically build an object graph that represents the the desired goal state. And then Pulumi understands what the current state is. And so it can actually diff the two of them just like cloud formation and some of these other tools and then create a plan and from the plan, it will figure out, OK, what do I need to do to actually make this um match reality? So that's, that's sort of it in a nutshell, sort of how the overall thing works um is put together. But there's obviously a lot of details that go into that. I should mention a few other just fundamental nouns that you're going to encounter uh stacks. I think Luke probably mentioned stacks are essentially isolated instances of your Pulumi program. And so often a stack maps to an environment. So you might have, you know, production, staging development testing, you might have production East Coast, production, West coast, you might have, you know, a stack per customer. If you're, you know, if you're uh si working with customers or a a product that single tenants, your product um often people will stand up lots and lots of stacks just do testing, right? So maybe in Apr you wanna stand up a new stack, that's a fresh instance of your application, run a barrage of tests against it and use that to mark a APR green uh before somebody actually merges some changes. So stacks are super flexible. I can't get into all the different ways you can use them. But um it's a, it's an important concept um in especially when you're trying to understand how Pulumi works. In this case, I already have a stack uh stood up. And so uh just for fun, I'm gonna go ahead and uh create a new one. So, so let's create a new, a new, new stack. One thing I should mention that's, that's maybe not obvious is aye the Pulumi cli and everything you're seeing here is actually working in tandem with the Pulumi a product to get the job done. So you'll notice that there are always, you know, hyperlinks for things. So here, you know, I can go look at the this thing up on the website. And this is an important, another important point in understanding how Pulumi works because unlike some other tools that you run, you have to manage state files and worry about getting them getting out of sync or whether it works in a team environment because the cli just automatically works with the Pulumi service. Um It just works in a team environment. You don't have to worry about whether your state file is out of sync or not and you could rapidly switch between these. So, you know, I can go back to, you know, the stack that I was just on. Uh oh, it's a fully qualified name, so I can go back to this. And now I can actually see, you know, the stack resources uh inside of this guy and sees, you know, plumbing config. So the config system is another key element of um of plumbing that I think uh Luke probably already alluded to. Um So I'm gonna switch back uh And I'll just configure this just so you can see in actions, you gonna basically copy that same config um notice that we're using Fargate to make all this a little bit easier. Uh So Fargate is the new ecs um infrastructure. You basically use containers as a service and not have to worry about managing your own uh uh clusters, which is great, especially for demos like this. Um So now if I run a Pulumi update, uh assuming I did everything correctly, which is a big assumption. You notice that it's doing a lot of stuff. So it's actually building the docker container and you see the docker build output here. So it, it built the docker container, it allocated all these resource objects, right? So it, you know, bucket function, service function and notice also there's a parent child relationship between these. Uh and that's an important part of the plumbing programming model. Um So that we can basically create components that internally uh compose other resources. So notably, remember I was making a big deal earlier about what resources are. Well, each one of these is a resource. So these are all resources. Um Each resource has a parent pointer. And so that's how we are able to build the tree. Uh If a resource does not explicitly have a parent, I don't know if he gets parented into this top level stack. Uh and notice all of them have names. Uh And importantly, Pulumi needs to basically be able to relate objects in your language, run time back to physical entities in the cloud and to do that, we use names. And so the name is actually very important and names generally need to be unique and this is something we'll return to when we start looking at how uh some of this works. Another part to just note is notice, it says previewing, it actually hasn't done any updates yet. It's just showing me what would happen if I actually did a deployment. And this is really nice too because this is where, you know, we are infrastructure uh as code, we are immutable infrastructure in all the same ways that existing tools that you know, and love aren't. We've just figured out how to bring general purpose programming languages into that space. Um And that's important because most language oriented approaches that have, that have come in the past, just go out and mutate infrastructure. There's no audit trail of who changed what and when uh it's ad hoc, if something fails, you know, you're failing in the middle of doing an operation, you can't, you can't typically preview what's gonna happen with Pulumi. We're actually giving you the full view of everything that's gonna happen before we do a single thing. And so that coupled with the fact that you get great ID E uh support means that you're often finding issues much sooner, much faster in the DEV inner loop rather than finding them after trying to do a deployment and it failing, you know, 10 minutes in or something like that, which is a common thing that we hear with existing technologies. So I can go ahead and do the update. Uh There's also this details which gives me a full, complete detailed di view and it's a lot of stuff. So, you know, I can go through here if I wanted to find out, you know, let's take one of these uh just arbitrarily. So here's the S3 bucket. So somewhere deep down on this, it's actually gonna create an S3 bucket. Well, here's the UN for that bucket. So I mentioned that everything is name based when we take the name that you gave us and we actually can, can meet that with some qualifying information like the module it was declared in. And the stack, this just helps to make sure that you're not worrying about names as much when you're creating um resources in your program. There's a common thing with existing technologies where you have to somehow like randomize the names or add some qualification to them and you're constantly struggling with this. And because we have this model, it's much easier to stand up lots of different stacks without running into naming collisions and, and these sorts of things, then we can see, you know, the full set of information that is going to um go into creating the a resource, but notably, we still haven't done anything and I'm actually gonna cancel a lot of this rather than waiting for it all to happen. I'm gonna take a step back at this point. So, in fact, I'm probably gonna switch to the whiteboard now just to help uh describe because I think this is easier with pictures than it is with words. So if I've done this correctly, you now see a whiteboard. Uh OK. So let's let's look at how the polluting system works at its core. So we basically got what we call the engine to get the Pulumi engine. So when you say Pulumi up, what's happening? Well, first of all, all the inputs to that are just normal programs, right? So you've got your text, you know, whether it's javascript typescript cr it kind of doesn't matter to us at this stage. Um We're basically just gonna run this program. Um And, and it basically has some metadata as well. So we've got this Pulumi file that tells us the language. Uh So in this case, it will say no Js and then of course, another input is the configuration. So you notice I config I accept as configuration, the region I'm deploying into whether I'm using far gate and a few things like that. Uh And so we've got config very different config than the normal sort of waste conha these config system and we have secrets as well. So we have encrypted secrets as well to make it easy if you have, you know, passwords or tokens or keys or things, you don't want to be in the clear. Uh We have first class way of supporting those too. So, you know, you can optionally encrypt your config also. Uh so these form essentially the inputs for ALU program. It's the program text, the and it's really to be honest, not the program text depending on whether it's dynamic or statically compiled. So when you go the input is actually a compiled binary uh and javascript, of course, it's just text. If it's typescript, it would be so javascript because you first compile your typescript into javascript and then you do it. And so we take the program plus the config plus the metadata and we hand that to the engine. Now, what is the Pulumi engine going to do. Well, it turns out the first thing it's gonna do is it's gonna say, OK, somebody just gave me a program, I'm writing this language. I need to do something with it. What am I going to do? So it does some minimal work to figure this out. But the main thing it does next is it goes ahead and loads up the appropriate language host. And so this is kind of interesting. So notice that the engine and the language shows are actually fundamentally different things. Um It's been an interesting evolution uh building uh Pulumi just a, just a fun fact, you know, we started thinking we're gonna do our own language. Um Then we realized, OK, we don't need to reinvent how people encode floating point uh numbers and frankly being able to leverage a package ecosystem is huge. I mean, I didn't even mention up here, but you've got infinite number of packages that you reuse when you build your program. So then we moved to a model where the engine was monolithic and it just knew about javascript. Uh And then we sort of had a breakthrough where we realized, no, no, actually we can tease out the language host into its own plug-in and loosely couple engine and language hosts. And by doing this, we can actually support infinite numbers of languages. And so actually getting the interface between them was actually a critical breakthrough that we had at, at one point. Um And so here's sort of what's happening. I should probably move these down. So it was a bit more. Uh so the engine talks through an interface and I should mention the engine itself is written in bill just to reiterate everything I'm talking about will be open source. Uh And so you'll be able to see how this works. And if you're part of our product beta already, you should have access um to all these repos. If you don't shoot us an email and talk to us in slack, we'll make sure you get access uh if you want to look around. Uh so the engine is written in go uh we use uh this goes statically compiled. So we needed a way to dynamically load things. And so the the interface for dynamically loaded plugins, we basically use GR PC uh and Probus, which is a great technology from Google that um allows you to basically describe an interface and have an efficient binary or HHP two interface into a component. And so we have this, you know, little Jeremy interface, it's actually surprisingly straightforward uh deceptively. So, and we'll look at it in a moment. Um But this is where you know, the language providers based or implement out of process their functionality. And so that is communication going back and forth between the engine and the language shows. Mhm We'll get into the details of how that works and, and and this sort of thing momentarily. But as that's happening, the engine is learning new things. It's learning about the resources that are getting allocated by the program and eventually what it's going to do in response to that is we have another point of extensibility for resources. So there are a few other points of extensibility. Those are the two main ones that uh if you wanted to come plug in, you could write your own language host and you know, go took, you know, a couple of weeks to bring up. So, um you know, it's, it's not like a herculean effort to bring up the new language host. So if you want to contribute, we would love to have people partying on this. Um And I'll show you that pr for go language host is a good sort of blueprint. Um So the second point of sensibility also, you know, over GR PC um interface is the resource providers. So these also there's infinite numbers of these uh the resource providers are what define essentially the resources that you can allocate and the logic required to provision them. So for the most part, this interface is actually, you know, create read update, delete operations for every resource you could possibly want to use. Um whether that data address Azure cloud, et cetera. Um So this likewise is pretty straightforward to implement and we have a few different ways of of doing that. And so setting back it's really, the, the engine is really the thing that kind of glues these things together, right? The main things that engine get you to do is, you know, previews and related to that, you know, diffing. Uh, I give you updates and destroyed, which are basically the inverse of that's just tearing everything down. Of course, it's got a notion of stacks, uh, it's got to be configured, everything, sort of that I've already covered. Well, let's walk through sort of the main flow. So we do a Pulumi update. We're gonna take the program, we're gonna feed it into the engine and just gonna inspect the data, data and figure out what to do, get first load the language host. Um And then it's gonna start chugging away on the program executing. So at this point, the language host actually has spawned the program. Um and it's actually been the same code that I showed earlier, you know, uh new S3 bucket, let's say. So this is gonna get communicated back to the engine over this R PC interface. And so what it's gonna get communicated at us is basically a gold state. Uh So we have, by virtue of having the type, we have uh basically internal type token. You pro you might have noticed this in the UR ends that I showed earlier, but it, it will look something like, you know, AWS colon S3 col N but, and so we get that, uh which is which is the type, we'll get the name, so we'll probably have like, you know, maybe photos and so we'll have photos in there. Uh And then other resources as you saw have other properties. And so it's basically a property that, that will come along with this. And so the, the host is basically saying, hey, you know, here's, here's a resource to help you during preview mode. It's kind of interesting because the language host needs to be prepared to do a form of speculative execution. Because during preview mode, even though you've expressed, you want a bucket, you actually haven't created a bucket yet. So what happens if you access one of its properties, like you know the domain name on the bucket that's gonna be allocated by A aws, you can't possibly know that in advance. And so one of the frankly most complicated pieces of implementing a new language host is essentially you've got a dag of resources, right. Um And so, you know, maybe this is the S3 bucket and maybe there are other things that depend on it, maybe the S3 bucket depends to something else. So we have this notion of dependencies between resources that needs to be preserved. And so over here on the language side, we're just allocating objects and generally speaking, and one thing you'll notice is every language does it slightly differently. The projection of the underlying resource object model differs by language so that it's in, right? So you go, you have a little bit more fun, you're in control over things. Um In Jama, everything will be much more class oriented type scripts. We're, we're leveraging union types and all these, you know, great uh rich type of features. So every language sort of projects gluing in its own idiomatic way. Um And so it will have its own thing here. It turns out in javascript, we're using basically a variant of promises under the hood to maintain the data photograph. Um And go we've got some channel fan. So, so the language sort of has its own view of the resource of graph and it may or may not actually need to reify that that entire graph. Uh And then uh once it gets back to the engine, the engine creates that graph and it has its own actual rep it maintains the whole thing and it needs to do that so that it can do parallel. And for example, uh so it needs to know the dependency is the order in which it's safe to delete things and what it'll do is so during a preview, it just evaluates and we basically simulate the data flow during an update, we actually need to perform the update. Uh And so the first time you run your program, it's gonna be all creates like you saw earlier. And so Pulumi will dependency order uh basically do topological sort kind of thing and walk the, the graph and then it will drive the resources. So we'll see it is like, oh you need the AWS resource provider, we'll load that, we'll connect to it for GR PC and then we'll feed it some create operation. So again, remember this interface is mostly just row. Uh And so the the creation is very simple and as you can imagine, destroy basically the reverse effect, right? It will walk the dag in the reverse order and destroy things. You can't, you can't delete something while something else is still depending on it. Uh So it, it, it's smart enough to do that and also split parallelism on the delete um where possible. Um And then update, update is probably the most interesting um update, you know, will actually diff states. And so it knows what the current state is. So maybe uh uh you've got some, let's say a Lambda and it's got some code in it and then you can just update the text of the lambda. Well, there might be some other resources, you know, that depend on it, so on and so forth. But we don't want to update all the resources, right? We just wanna update that one lambda, that one piece of text that you actually changed. And so the engine knows how to basically take two graphs, pair the nodes within the graph, uh understand the edges so that they can do things in a safe way and then do the minimal dip necessary to actually deploy your code. And so it'll just go patch the le the one line code to your change. It'll actually just, you know, kind of go do that. And as you can guess, probably by its name, you know, the update, uh, operation is sort of what, what that, so that was a whirlwind tour. It's probably a lot to cover in a small amount of time, I think. Uh, I did want to just show a quick road map of the source code. If you're, you know, in the private debate, you want to poke around or if you're seeing this after we're open source. Um I think any number of these areas is something I could dive deeper into, like, for example, I'd love to sometime in the future, you know, go through what that Jr PC interface looks like. Uh And how we actually create those. We've done some interesting stuff from the CNET uh space to do some type generation out of the open API specs in cnet, for example, so that we get perfectly full fide in the resources while getting great uh typing out of it. Um And then likewise implementing a new language, it would be fun to maybe dive into how to go to the language and how it works at a low level. This hopefully gives you the overall top down summary. Now, I'm just gonna jump back to the, the computer and switch my video. OK. So I think I'm back here. Um I'm basically just gonna give you a quick overview and I'm gonna spend maybe 10 minutes, let's say, because I know I'm a little bit over time here. Uh Going into sort of the structure of where some of these things live. So the main repo is Pulumi. Pulumi. That's sort of where most of the magic lives. That's sort of the, you know, anything that's not out in a point of extensibility or in a box. This is where it lives. Uh As I mentioned, it's written in go. So let's um CV S code here to open it up. And so uh the C MD directory is basically the command line. So this is where, you know, preview lives. Um So, so every command that you run with Pulumi stack and knit everything that, that lives here, what you often notice is things use engine uh and back end and those are there. So two major packages because this is go uh you could program against the engine if you wanted to build new things of it. Um It's, you know, we, we have exported members, we try to architect it cleanly so that people can plug in and build new tools on top of us. Um And then you'll see in the package directory, we've got lots of, lots of good things. I'm not gonna go too deep into this. I just giving you an overall structure. But, you know, if you want to see how um how, for example, loading the, you know, the the language provider worked, you would go in here and you know, planning this is all the magic for creating, you know, previews and doing gifts and all that. You can kind of jump off from here. There's an SDK director here and SDK contains basically all the language providers. So you see go language provider, no Js Python, because we dynamically load things. There's no need for language providers to actually live in this repo you can define them anywhere. Um We just happen to, you know, to find them here, so they're easy to find. It's conceivable later, we'll move them out into different depots. And you'll see here, you know, this is just the normal typescript um uh project, not really anything magic, but what you'll see is, you know, the resource, the fundamental type that's doing everything you need with resources is actually just a class. Uh and then it's gonna go through this run time. And basically this is where it connects up to the GR PC uh stuff that we talked about earlier, uh where basically this register resource thing, this uh this will go through and like do a bunch of GR PC things. So it'd be fun to look into, you know, how any of those things work. And again, you know, go and Python right here alongside them, there's instructions on how to build some source. If you wanna play around there, which I encourage experimentation. Um The other top level thing to note is the proto buffs that I mentioned, which are the points of extensibility are actually just right here alongside the language providers. And so if you want to see what it would take to implement a new resource provider here it is. Uh oh sorry, not this one, this one. Um Here are the methods you need to implement configure invoke, which is, that's a separate thing that I did mention. But um resource providers can have functions that you can invoke to do things like looking things up dynamically. It's kind of interesting check diff and then, you know, just create great update to lead operations. Um pretty straightforward. I'm not gonna go too much into detail here. It'd be fun one time to go through what it takes to create a new uh resource provider. I will mention we have a, a bridge that effectively takes any terraform provider and plugs it into this interface. And so you can use that. So if there's any terraform provider out there that you really like, you know, Digital Ocean is one that I hear of. Uh for example, super easy to take that thing and just glue it up and, and get it into Pulumi right away. Um Other providers like the Cumber Tti provider we wrote from scratch, but um you can go, you can kind of go either direction there so that that's the Pulumi Repo itself. Um, and then what you'll find is for every major provider. Um, you know, Aws we've got here. Uh, and so Aws, this is the package provider for Aws. It turns out you probably don't need to touch the source code usually and you're just gonna install a package. But if, if you want to, you can go look here. This one is generated from, uh, terraform, like I mentioned. So that's actually controlled through this resources dot go file. And what we're doing here is we're basically adding some nice module structure on top of the uh Terraform provider, which doesn't really have as much of that sort of user friendly metadata. Um And so all of the, you know, you see the Azure resource provider has effectively the same thing uh going on. You also same thing uh you mentioned is very different. Um That's actually got, you know, a lot more uh to it. So you've got, you know, this whole open API based Cogen and a lot of uh of fun stuff there. Um And that's, that's most of the, the main top level repos. There's also, you know, examples and a bunch of scaffolding uh stuff. The only major parts I'll mention are uh packages. So um resource providers are sort of think of those as the low level things that provision cloud resources, you can create ordinary packages that just just they're just code, right? They're not, they're not go plugins or anything like that, they're just packages, right? Um And so we have a few of those like the eight of us Infra package, this essentially just has some components that are just make it easier to program against Aws infrastructure. So for example, uh I'll, well, I'll look at the example here because it really pops when you see it. Um So if I want to provision a AW infrastructure or sorry aws network, that's in a VPC that's got properly sub netted, you know, multi availability zone networks, subnets, you know, public private subnets, I can just do this uh as a consumer of this package. And all this package is this Aws info package is code it uh type typescript and javascript code. It's, it's not, you don't need to go plug in or anything like that. And so I can go look at the implementation of this here and it's pretty complex, right? Because setting up a ARS infrastructure is complex, but that's the, the the idea of having these components is you can take that complexity and put it underneath a simple and easy to use interface. And so you notice that it, it accepts all these arts for controlling various aspects of how the network is gonna be set up. Um But internally, you know, i it's kind of fun to walk through this because it's really not doing anything. You, you couldn't build yourself, right? Um So we'll notice uh let me just find an example. So here we, here we see new EC2 VPC, right? As I mentioned earlier, this is just a Pulumi program and its turtles all the way down. So it's just creating a resource and that resource works the same way I showed you on the whiteboard. So if the definition of AWS info change and maybe this changed to false, let's say next time we ingest that package and run a Pulumi preview, we're gonna see that as a diff uh in the same way, the resource graph works uh that I showed on the whiteboard. Um And so you can build these complex abstractions out of lots of little pieces. And so that's, that's sort of the magic of some of uh what we've done. And then the cloud package is another one that sort of works the same way. It's a little bit more complicated. Uh You've probably seen, you know, God service type, which does Docker bills where you can have a container that's built out of an image. And so the Pulumi cloud package is probably our most sophisticated pure library that isn't backed by, you know, go plug in or provide. Uh And so that, that one's a lot of fun to, to spunk in uh our intention is that it's going to be multi cloud right now, we only have the AWS implementation. So if you're looking for areas to hack and play around with, you know, getting a service up and running on Azure is definitely something that's on our short term horizon and it's definitely areas of uh possible contribution for open source that we, we definitely welcome. So I think I probably tried to cover too much ground, but I hope it was fun and exciting. Uh And I think, you know, probably we should do uh regular uh deep dives, maybe, you know, every three other uh episodes or something. So we can keep double clicking into some of these areas. Definitely curious to hear what people are interested in. Um Either leaving feedback on, you know, Twitter here in the Twitch Chat in Slack, wherever you can find us, uh Love to hear from you. So I hope you have some fun. Thanks for joining. See you next time.

---
