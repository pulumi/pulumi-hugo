---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Cloud Engineering Summit 2021: Forecasting the Future: Creating a Radar for Risk"
title: "Cloud Engineering Summit 2021: Forecasting the Future:..."
meta_desc: |
    In the mid-20th century, predicting the weather was still one part science, one part intuition, and one part luck. But as computers, data collectio...
url_slug: cloud-engineering-summit-2021-forecasting-future-creating-radar-risk
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Cloud Engineering Summit 2021: Forecasting the Future: Creating a Radar for Risk"
  description: |
    In the mid-20th century, predicting the weather was still one part science, one part intuition, and one part luck. But as computers, data collection, and modeling have steadily improved, we now produce staggeringly accurate weather short-term forecasts.  In tech, we're still early in our journey to more deeply understanding and modeling our world through learning from incidents. As we improve, what if we could start forecasting incidents?  In this presentation, we'll talk about Risk Radar, Netflix's forum to collect and make sense of emergent sociotechnical risk both from experienced-incidents, and risk which can predict angry, incident-filled skies.  Talk by: J. Paul Reed
  sortable_date: 2021-10-20T23:00:19Z
  youtube_url: https://www.youtube.com/embed/J1X_VgN6mus
transcript: |
    This is forecasting the future, creating a radar for risk. Now, before we get started today, I wanted to give a shout out to Cat, Laura Maddie and Wendy. Uh Those are the folks that uh are put on the Pulumi uh Cloud Engineering Summit um and worked really hard to do. So I know a lot of folks think a virtual conference is, is maybe easier than uh putting together an in person conference. It's not, it's just a different type of work, but it's definitely the same amount of work. Um And I know a lot of us thought uh that we would be uh in person by now. Um So I'm looking forward to seeing them and you in 2022. And I just wanted to thank them for bringing us all together uh here today. All right, let's get started. So a lot of you have heard of this idea of A I ops, you know, it's a game changer. Um This idea that maybe if we can uh teach the computers enough about our work, they'll be able to detect incidents before we can and maybe even auto remediate them. It's a big promise a lot of, a lot of ops teams kind of wondering about this, you know, hey, is it just another addition to Dev Ops, you know, DEV A I OPS? And we keep adding, uh, uh, letters to that, that, uh, to Dev Ops. Um, and, and rightly so I think there's a little bit of skepticism, you know, it may seem like, uh, we're just looking at sort of a crystal ball of sorts and, uh, and, you know, in, except now it's computers that are looking at this crystal ball. Um, you know, and admit it's kind of hard to trust these things because, uh, looking back at one of those A I articles, uh, from the previous slide, you know, the, the clip art that they actually used here is a tarot card, uh, which is not particularly confidence inspiring. I don't know if I, I want, uh, you know, computer auto remediation based on a tarot reading as it were. Um, one of, uh, one of my favorite guys, Dave Hahn has a great quote about this. He, he said if you're having enough incidents to train a machine learning model, you probably have more pressing problems to look at. Um, and think about, uh, and there's, I think something to that. So for today, uh, I'm gonna talk about a I, but I'm referring to something different, the already existing intelligence that we have on our teams, um, that we use and bring to our systems every day as expertise. Um and how uh when we interact with each other and with other teams that intelligence is more than the sum of, of its parts. Um when we wrangle these systems um and operate them day to day usually pretty successfully. Um So I'm talking about that expertise. Um and that already existing intelligence within us. Um A little A A I ops that in that context. So risk Radar, what is this risk radar thing? We're gonna dig into that. Uh But before we do so, uh um uh my name is uh J Paul Reid for those that don't know. Me most important thing on here is Twitter, uh J Paul Reed on Twitter um background and build release engineering, uh did distant consulting and um I have a masters in human factors and system safety, which I mentioned because a lot of these ideas come from that field of study. Now I met Netflix on the critical operations and reliability engineering team. Get asked a lot what I do on core at Netflix. Um I once gave this answer, I navigate the organization to observe signals of systemic socio technical risk so we can activate our adaptive capacity to address that risk. And somebody came back and said, so you run around the building, gossiping with people about broken computers which uh had a reaction to. But, you know, maybe there's, maybe there's something to that. I don't know. I don't know Um So let's dig into our radar for risk, you say, what do we mean by that? Well, it's good to offer a little historical context uh before we dig into, to uh the benefits of Risk radar and, and the details of how you would build your own. So uh Risk radar uh was a repurposed meeting originally. Uh The meeting, it was originally called the IRL incident, Risks and learning meeting where we talked about incidents. Um and then risks and learnings associated with those incidents. One of the big changes that we made when we renamed and repurposed that meeting was to go from talking about specific incidents to risk themes. And so in the previous meeting, a lot of times to folks, teams, we had ask, ask teams to come present their uh incident that they had run into specific incident. Um And now we, we shifted more to uh risk themes. Incidents still play a role. We'll talk a little bit about that in a sec, but we're talking more about thematic Risk and Risk radar. Um as I mentioned, teams would come and present. Um We, we moved from a model of presenting to discussing, we found that um setting up a presentation to come to that meeting. A lot of things felt like a book report, felt like extra work. Um So we don't, we don't have teams prepare in that way anymore. Um And it's more of a discussion. Um Also uh it's less of a retrospective about, again, about specific incidents and more focused on emergent discussions, emergent paths that come about around these risk themes that we talk about. Um So, again, even though we, we bring in um some previous stuff to inform our discussion, um we really let the conversation kind of go wherever it's gonna go. Uh And it's less focused around the framing of a particular specific incident. Um Again, even though we use those talk about the details of how we do that in a sec. So the recipe, how would you put this together for your own organization? Well, you obviously have to have a schedule forum, a meeting um to, to hand it uh to handle it in or, or conduct a risk radar in. Um we solicit and collect risks beforehand. Um And so I sent out an email um a couple of times before the meeting and ask folks uh to share their risks uh before the meeting. Um So that we're not spending a ton, a ton of time doing that during the meeting, there's also a benefit that we'll talk about in a second. Um But we do all of this uh collection sort of beforehand. We also do some incident and oopsie analysis that we bring to the meeting. Oopsie, by the way, is a program that was started by Lauren Hoffs. Uh No root cause on Twitter um was one of my favorite Twitter names. Um Nora Jones was involved as well. Ryan kitchens, um, started the oopsie process. It's really near miss reporting. It's, it's things that could have gone very wrong but didn't. And then people will sort of do a retro, uh, with them and their team and write it up as a, as an oopsie. We'll take some of those analyses from actual incidents or oopsy, bring those as well. A lot of times we'll merge the risks that folks uh have raised and then look and see if, if uh we see any of those risk uh patterns in the analysis of recent incidents that we've had um published and distributed minutes. So that's actually a really important part after the meeting um that uh the meeting minutes um get put together and then we send them out um for folks to look at. Uh we'll talk about why that's important uh in a sec, but that's definitely a part of, of the recipe uh to making risk radar work. So some surprises, some surprises are risk greater, well, scheduling cadence, um surprises. Uh We were originally doing it monthly. We started this in 2019. So about a couple of years ago, uh actually, it was October of 2019. Um And we used to do it every month as the pandemic came around and we were in the thick of that, we went to every other month. Um And so we played a little bit with the scheduling and where we are now, every other month seems to be a good cadence for, for collecting these risks, discussing them and then, um, you know, disseminating them back within the organization. So you might find, uh, every month is not enough, you might find it's too much. So, that's something to play with as well. Radar echoes. What do I mean by this? Uh, well, when I would solicit risks, people were actually surprised, uh, that other people had the same concerns and risks that they had. So a lot of times when we would say, hey, I don't think anybody, you know, else is worried about this, but I'm worried about X and I would say actually I got email from four or five other people about that particular risk. Um And so we would, we would definitely dig into that one at the meeting. Um But that's one of the reasons you collect things beforehand um to reduce that uh that bias and people maybe, uh you know, having to say it in a meeting is very different than just emailing it. That was a big surprising thing, the importance of the meeting minutes. So I talked about this. So we have a lot of um folks that, that uh have a conflict with, with risk radar um or, or have a very busy schedule. Um A lot of leaders and senior leaders may not be able to make it to the risk meeting. Um A lot of their teams might. Um, but they don't. And so, um for them, the, the really useful output are the, the collated uh crisp meeting minutes which we put together and those get, you know, more broadly disseminated too. It's easier for people that weren't at the meeting leaders. Uh Or I CS to actually look at the minutes if somebody, you know, goes in and says, hey, weren't you just talking about this? Um And so it's an easy way to sort of keep the conversation going, but they have to be really high quality and, and sort of edited. So we try to make them very readable almost newsletter article, sort of. Um, styling is kind of what we're going. And finally, the risks that your A I radars detect very surprising, um when you don't constrain risks uh from an incident perspective and say, hey, we're gonna look at all the risks in this incident. You start to get risks that aren't technical in nature. Um They're about the socio parts of the system, you know how people are feeling how an on call rotation might be thin, things like that. Um It may go into other parts of the organization around. Um, you know, other, other teams that aren't, aren't engineering, maybe they're pr maybe there are other things. Um And again, it's great because then you, you can follow as part of the emergent discussion, follow the threat of risk around the organization. It's not just um you know, in the context of an incident in the single technical system failing. Um, so some of those risks, um, and where they've let us have been very surprising in a very positive way. Um, and so that's another benefit here. All right. Uh, let's talk a little bit about some of the problems and challenges of risk radar that we ran into. Um, the radar represents a sort of probable. Right. So there's a probabilistic nature uh to the risks that people are gonna come up with. We, you know, people are using their own heroes sticks and they're making a judgment call about where, how likely it is that the risk that they're bringing up is. So you have to know that this radar that we're talking about, you know, you, it, it's based on how many sensors report that same risk, right? How many different radar sites report that? Um And so there's a probable is involved. Recency bias is definitely involved. So a lot of folks will actually bring up risks that were in recent incidents or oopsie, that's ok. One of the things that we found that super interesting is those risk things ebb and flow over time. So there may be a few incidents about a particular risk. It kind of dies down, kind of gets tamped down, maybe engineers do something different. But six months later, we're talking about the same risk and we might want to revisit it because it came up again. Um And so, uh, uh, recency bias plays into that, but it's still useful there in terms of, uh, um watching risk ebb and flow over time, some risks will never come to pass. And that's something that you, you just have to accept. Uh, one of the important things is all the risks that get brought up whether or not, you know, they happen in a previous incident or end up happening in an incident uh in the near future. Uh are a second order signal of what folks are worried about in the organization. And so that's actually super useful uh to look at like where are people concerned? Um And why are they concerned? There's a lot of chunky conversations that um that can be had there. Um You might say to yourself, uh what else? This is a Netflix thing, unicorn thing. Uh I can't do this in my organization. Well, oh look, hey, hey, it's Pete. Hey, Pete. Um uh kind of in the middle of something. I'm kind of giving AAA presentation uh for uh Pulumi Cloud Engineering Summit. Uh Is this quick? Can I can help you with something? Yeah. Yeah. Yeah, I just got a couple questions about Risk Radar if you got a few minutes Risk Radar. Well, it's funny, I'm actually talking about Risk Radar right now. Uh So why don't you tell folks like who you are? And let's talk about your questions? Yeah. Hey, I'm Pete Shima. Uh I work on the reliability engineering team at Epic Games and uh um we have started doing this risk radar thing that we found out about and um and it's going pretty well, but, you know, a few things, you know, that uh a few questions I had about it, one is, you know, um you know, we're gathering all these risks and, and people have really liked talking about this and we've sort of created this forum for people to, to talk about these things, which is great, but like a lot of folks want uh action out of these things and that's, that's definitely a challenge uh um for us. Yeah. Yeah. Well, but so before I, I answer your question, we'll get to that because that's an interesting thing. I mean, this comes up with incident topics, you know, incident remediation. Like why would we do a retro if there's not any action items? So it's a juicy topic. But I'm actually really curious, how did I mean, how did you get started? Like, how did I mean, how did you introduce this meeting to the, the crew? Like, like, what was that like? Yeah. Yeah. So we have a uh uh an operational meeting that we have uh biweekly now where we talk about a lot of stuff for service ownership at Epic. So, you know, we have the definitely uh you build it, you run it type of type of culture. Um And hey, we're, we're talking about a lot of operational and service ownership items there. And we said, hey, you know, there's not really like a place for people to talk about some of this. So we talk about security risk and things like that and in other forms. But like, hey, uh uh one great conversation we had was about uh on call and problems we have with in some of our on call rotations and we had a great discussion. Yeah, on call health and, and on call configuration, right? So, so we sort of introduced this into this uh uh uh uh optional meeting that people can join and sort of learn what's going on. Um So it's a pretty big audience there and we're getting a lot of sort of feedback about, oh, well, hey, this thing doesn't seem right or this thing doesn't seem right. Yeah. Yeah. And of course, as we were talking about uh earlier, like that's, you know, the point of risk creator is to create sort of a form for that. Um So that, you know, people can kind of get some of those things off of their, off their chest or off their mind around like what's what they're worried about, right. One of the interesting things you asked, right? Was, was about action items and, and I guess, I mean, I wonder a little bit like did that come up because people were discussing these great risks and then it was kind of like, well, what now or like was that kind of the, the thinking there? Yeah. Yeah. So we've been sort of collecting these risks to sort of build our risk library, so to speak our risk catalog. And we're sort of going through this and we have a, we have quite a lot now, which is great. But, hey, what's the next step? Hey, this is actually like a serious problem. What do we do about it? Right. We, we shouldn't just leave this here and how do we sort of address that? Yeah. Yeah. Yeah, definitely. Well, so there's lots of different ways that, that we've done that at Netflix or dealt with that, right? Is it, and one of the ways is, is you can use it as uh input into, you know, product discussions, right? If you have a product team, um one of the big things too, uh you can surface, you can use some of those things to surface actually, uh where teams are, right? And so maybe there's a certain part of the product that has a lot of technical debt and that's being expressed through incidents and the risks that people see in incidents, right? But if you kind of go to someone and say, oh, I just have technical debt, right? And maybe there's a technical debt in the fro service, right? They may say, well, that's great. But if you can connect that to like there was an incident. And when we went and looked at that the, the risks that got expressed or related to the technical debt, it gives you something a bit of an anchor to do that. So I, I think, um, you can use it in a lot of different ways, but one of the things that I think is relevant and important as part of that is you do have to have somebody driving it. Right. Because otherwise to your point, I bet, um, it maybe feels like a little bit like, uh, just complaining, right? Unless you do something about it. Right. Yeah. Yeah. And I think, you know, we've, we've developed this long list of things and, and people are like, ok, we've got, we've got a list of stuff right now and we've done a couple of voting type of things, hey, what's important to people? And that's been helpful. But I think, you know, finding that right driver and hey, what, what do we really do about this one? Maybe it's not attached to even one team is something we're still figuring out. Yeah. Yeah. Well, and so, uh, the one thing too that I'll mention that's really interesting about this is that, um, not all of the risks that folks bring up or that get discussed may have an actionable outcome in the moment. So one of the things that we found and we found this, that Netflix too is, it's like it's almost trying to scale the A a and I kind of referenced this earlier scale the, the water cooler conversation, right? Engineers knowing how the system works and the sharp edges, you may not actually polish them, but you may want to know that, you know, if you use that saw in that way, the, the Buzz uh Buzzsaw service in that way it's going to bite you, right? Um And so that's useful information too, even if you don't put it in a backlog or, or, or um you know, uh uh do anything with it. Um I'm actually curious, I have a question for you uh for folks that might be interested in this whole risk radar concept, what advice do you have uh for getting them on their journey doing it at, you know, an organization that maybe, you know, this is, this is not a unicorn thing. You can do it at Netflix, you can do it at Epic, you can do it at your org. What, what advice do you have? Yeah. Yeah, a couple of things that I've found so far, you know, we've been tracking this for a few months and, and, and getting a lot of things and, and definitely finding out what is important to people um has definitely been helpful for us. We need some voting things to, to, to start gathering more of that. Um And also like having a safe space. So some of the stuff is gonna be painful for people to talk about, right? So it's got to be like AAA space where it's OK to talk about things like team health, like on call, like that sort of stuff. Uh uh uh is pretty important and if people aren't comfortable about talking some of these risks, then that's gonna make it challenging. And we've also tried to get a senior folks in this meeting too, so people can actually have a dialogue with senior people directly about how they think about some of this risk, right? So what, what is important to one person and might be a really emotional thing for, for one person might actually be a really big problem for someone else or might not as be a big of a problem for other teams. So I think finding getting that dialogue going and then, then focusing on, hey, here's actually the important stuff. Um uh people that are passionate about this stuff like they're gonna get together if you can just bring them together. So I think that's worked pretty well for us so far. Yeah, definitely. You know, we've been using the metaphor of like radar and clouds, right? And so sometimes clouds look very ominous, but there's no moisture in them, right? They're not, they're not actually that scary when you have a tool like a radar to look at them and then other, you know, things other, you know, clouds look like happy fun clouds and behind there is like major storms going on and so that creating that space can help take the, the signal of the clouds if you will, uh, and make useful, useful information about it to explore it more. Yeah. And I think people bringing up similar things or the same things over time is like, oh, hey, this is Rey and now they have somebody to connect with on that topic and quite often there's people like, hey, I wanted to solve this. I didn't know it was a problem for someone else too. Hey, how can we sort of go solve this? We're, we're still figuring out how we can sort of facilitate some of that stuff. But, uh, but it's been good connecting some of the groups. Cool. Cool. Well, I'm gonna go ahead and finish up this talk but, uh, I'm really glad you, you know, uh, dialed in, uh, you know, gave me a call and we can talk about it. It was very serendipitous. Yeah. Well, thanks for a few minutes and, yeah. All right, I'll talk to you soon. Bye bye. All right. All right. Uh, that was great. Uh, now, where was I? Oh, this is a Netflix only thing. Well, clearly, uh, it's not anybody can do this. And where are the action items? Pete. And I talked about that a little bit. Um, and what you can do about this. But that's one of the things too that a lot of times people are thirsting for action items. And that can be um a tricky thing to wrangle. Sometimes again, some, some risks may not have clear to find action items and you have to do a little more work to find what is the actual action item from that risk. So let's talk about the three takeaways uh from a day. So people communicating with each other in socio tech systems turns out it's kind of important, right? Um A lot of times as engineers, we love telling stories about uh you know, near miss this thing I did that, that almost took the site down. But didn't we also talk about, we love to talk about ways that we kept the site up and wrangled, you know, that uh database back to health. Uh without anybody noticing, these are water cooler conversations and they're important um to organizational learning and to how we play out. Um What happens during high consequence, high tempo events. This is kind of, you know, as I said, a water cooler. So this risk radar is a way to scale those conversations and disseminate some of those uh learnings outside of just what engineers are talking about that concerns them fundamentally. This is what that is and so play with it. Uh It's a format to structure that play with it. Uh do something that works for you. Takeaway. Number two, it's a technique to give voice to I told you. So now saying I told you so is not generally very productive, but it exhibits uh or indicates a frustration, right? People saying, hey, I was really worried about this and it blew up and I told you so, so risk radar is a way to sort of give voice to those concerns, but in a more actionable and definitely healthier way. Um Hopefully, if, if uh if we see a lot of folks concerned about the same thing, we can take action about it. Um And you know, it's, it's a little healthier than just saying I told you. So ha ha ha finally take away number three forms like risk, radar, cultivate uh adaptive capacity and interp predictability across levels of the org, right? So adaptive capacity, that's our ability to adapt to situations um under uh high consequence, high tempo events. Um and this, this the exchange of knowledge and exchange of what things are around, you know, risky things are on the mind of engineers increases our, our ability to cope with those things uh during an incident. And then interpret interp predictability is the concept of how can we lean on each other and other teams during these high stress high temple, high consequence incidents. Um And this builds that because it shares some of the context in a nonstress way in a nonstress forum about what they're doing, what they're worried about all of those things. And then of course, if you disseminate it out, as I mentioned with the minutes, that's super important, you can get some of this effect across all levels of the organization. So uh go forth, establish your own risk, radar sensor network and start finding out uh those risks with the already existing intelligence that you and your colleagues and your organization have. Uh I'm Jay Paul Reed, J Paul Reid on Twitter. That's all I got.

---
