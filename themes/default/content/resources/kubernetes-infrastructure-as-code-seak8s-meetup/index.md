---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Kubernetes and Infrastructure as Code at SEAK8s Meetup"
title: "Kubernetes and Infrastructure as Code at SEAK8s Meetup"
meta_desc: |
    Mike Metral speaking on Ephemeral Kubernetes: Workflows for Kubernetes Clusters and Development
url_slug: kubernetes-infrastructure-as-code-seak8s-meetup
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Kubernetes and Infrastructure as Code at SEAK8s Meetup"
  description: |
    Mike Metral speaking on Ephemeral Kubernetes: Workflows for Kubernetes Clusters and Development  - Infrastructure as Code using Pulumi - Managing the Kubernetes infrastructure ops loop - Managing the application dev loop  Talk repository: https://github.com/metral/gke-cicd
  sortable_date: 2020-01-31T18:04:17Z
  youtube_url: https://www.youtube.com/embed/2oNolWWRZXQ
transcript: |
    Awesome. All right. Uh Hello everyone. Uh My name is Mike Metro. I'm an engineer at Pulumi. Uh I work on the all the aspects of uh our tool chain. Um And today we were talking about the, the, uh on the heels of delivery comp, uh just like Angel did, I'm gonna be covering different ways. You can work with communities uh with C I CD. Uh And how kind of the versatility is the one that kind of shines in a couple of different ways. So, uh for starters, uh the common complaint that everyone talks about everyone is it's too hard, too much uh on ramp. Uh I don't care. I just want it to just load my app. Uh If I'm an Infra folks, I just want it to not fall over. If I'm uh somewhere in between, I want to do as little as possible. So, uh this is a very recurring theme. It only gets more complicated as the service area of the api expanse and unfortunately, it's become uh a huge deterrent to a lot of folks. Uh And for most it can be overkill for some, it can be just the right fit. But at some point, if you are in the game of managing containers, you will need some sort or orchestration engine in the piece and fits that bill uh in in my opinion, uh but at the same time, it may not be the right solution for everybody. So definitely keep that in mind. Uh what I'm trying to showcase here is how you as a developer or you as an Infra folks can really work on a couple of different planes uh using the ploy tool chain. Mhm So what is Pulumi, what is uh that we do with regards to communities and infrastructure? So for one as angel told us uh in his talk before, first off, thank you to Angel for the, for the, for giving this uh this talk on us and uh how that puts him with Circle C I. Um We're a huge fan of Circle C I. Um Pulumi is modern infrastructure as code. So you were familiar with tools like terraform puppet chef answerable. Um These are all tools that essentially were born uh just as the cloud was kind of getting going, right? So you have the chefs, the puppets, the answerable that are really mutating state on an actual machine. Um And you have something like um like terraform, which is trying to, to drive to a declarative state of the world but using a uh A DS L, right, the C language. Um the common like misconception about that is that at some point, you're gonna have walls of L you're going to have uh syntax errors that are gonna drive you up the wall. Um And unfortunately, you just don't have the constructs you need to use uh and manipulate this right from, from a truly kind of uh imperative standpoint. So, so the idea is you have no Gammel uh with Gloomy. Gloomy is a series of SDKS. We are completely open source. Um We are free and open for community individuals where we make our money is for organizations, but all our code is open source. You can uh you can pull down the tool chain and even store your states um locally in a bucket of your choice if you uh are not wanting to use our test. But the first thing that you should notice as someone coming from the world is that this very much kind of looks what you would expect right from a config file. Um You have uh very much the same kind of structure here. We've actually uh managed to leverage abstractions because now you have real programming languages, right? We support uh javascript typescript, Python go and we just really support for dot net. So CBF sharp uh C# uh So what we do is we expose a bunch of libraries in the language of your choice, you import that just like you would any other library use the same editor that you use, you use the same ID E use the same package manager uses the same test suites. All you essentially do is just write it in the language of your choice and declare the actual end state of what this infrastructure is. So we use imperative programming languages to drive to a declarative state of what might infrastructure should look like. So very kind of similar to what terraform is doing in that respect, right? Like I have two replicases. I want the replicas. I'm gonna keep driving that state until I have to have three reforms. But what you get out of code is all of the like the bells and whistles that developers are grown to love. You have type checking, you have lending, you have error completion, you have jumping to definition docs, you have unit testing, you have integration testing, you have the ability to create a distractions and calculations, to share code, to create libraries, to publish that to package managers, to share that with your coworkers uh that creates standards, right? And if I'm the networking team and my colleague, this is the identity team, they can standardize on what I am looks like and expose, expose either functions or artifacts that I'm supposed to be consuming just like I would an import statement, you know, import my buddy is I am uh library and I consume whatever role they give me or I consume whatever function they give me to create a role. Likewise, I can lock down networking and say no one's allowed to create public uh subnets, no one's allowed to create uh public IP S on any given uh resource in that subnet. So depending on how you want to mix and match that, really, the kind of gamut is, is available and with code you can manipulate it. However you want, let me ask questions. Simple C I uh Do you guys have like native support in their infrastructure or are they just like downloading? Because like, for example, in his example, when he did the CC I for the G ce, he had to install the G ce and I saw that, you know, you guys were just a call top of it. Um I mean, it, it, it, as I said, do you have partnerships with them or are you just that easy to integrate into any C I CD? Right. So we, so I'll show you the demo. Um I wasn't gonna do Circle C I before I knew Angel was showing up. So I switched it up and I showed this and could have actions just to show you another kind of option. But essentially the bloomy tool is, is the tool that's being um abstracted to some degree either in or say in circle C I or as an action and, and good help. But the idea is just a container. So it's a docker container that we have prebuilt with all of the. This is a great tool chain for GCP Azure, uh AWS plus our tool chain. So you can actually, you know, pop in api token log in and then the back end of your tool, it's just a container uh on the and in the CS CD. Yes. Right. So CS CD, that's coordinating with our S A or if you're using our S A by default. So what you do is when you do credit this code, this creates what's known as a resource graph. And that resource graph goes from parent all the way down to the leave. And so we'll start creating that hierarchy slowly as it goes. Uh And that gets stored in a state file, that state we by default stored on our S A. So we can do locking, concurrent locking of that state file. So if you're working in a team, you don't, you know, stopping each other changes. And essentially what that tool is doing, the C I is coordinating that state file with our A. So showing you previews actually enacting the update or uh or logging into your account. So similarly, just like we can define community code, we can do the same thing for so entire service catalog really of any of the cloud platforms. Um So uh in this case, GCP, I'm importing uh the ability to create a new firewall in a, in a subnet of GCP, I create a new VM with a machine type X boot disk. This um And what you now have is the ability to declarative write code in an imperative language uh and manipulate this and fund this. However you see fit, right? So you can tweak this in any, any edit the code is the desired state. So second I swap out the machine type from F one micro to an N one standard. It'll see. Hey, there's a, there's a diff here that's being changed, we can pinpoint to the exact prop because what we do in plume anything with an API pretty much we expose it through a library in the language of your choice. So we can think of flu as like an API of many A Pisa bucket of those is like the terra form providers. So we can tap into that ecosystem. Another bucket of that is we can talk directly into the cloud writers like top the cloud formation, talk to the templates and Azure top the templates and, and UCP and much like that, if you have an API, we have essentially the shell of a provider which is how we expose each of these uh utilities in our libraries. So if you have a API, you can implement your own only provider. Yes. Support for say self posted things like I'm using Zen or KBN. Yeah. So right now we have support for uh vsphere and uh on the on prem sort of thing. So yeah, so we can tap into those as well. Uh in addition to the cloud platforms. So what you now have is I mean through a code, you can preview these changes before they happen. You can make it like an actual decision to actually enact that. Um you have a full audit trail because it's code so you can track it to your source code and you can prove it through PR S, you can merge it, you can reject it, you can review it. Um And we also have integration for secret management. You can use, you know K MS on Aws, you can use the uh the vaults on, on, on UCP on Azure uh and even use your own cipher text uh if you wanted to. Um But more so uh what you really then buy is the ability to leverage any tool training platform of your choice because we are the cli tool. Uh We can plug into your source code and we can plug into any language of your choice through the libraries of the expose. You can work with many different tools that, that you've already used today, right N PM uh tip uh circle C I um on and on. And we work across all three clouds um as well as and here of ocean. So because Cori is just yet another API we can wrap that in a provider and expose that API through a library. So you now have the ability to create a deployment, you know, with completion as you would expect it just like anything else in uh in regular code. So to focus on Curtis, right? Um This is kind of like the state of the world we, we use, we call this like the K diagram um because this is like how deep you can go and how high you can kind of configure uh to run anything, the one common complaint um you can make it bigger. I can't uh I'll show that the there's a link at the end, I'll show you. So the biggest problem about working with communities as a developer as an operator is that you're never really coordinating um your work on a day to day to what's actually instead of staging a product, right? There's always a discrepancy in environments. So the the biggest problem is um I was here, I don't know how to do this. This is too hard, it's too complicated. I don't care. Um I just want something to, you know, take my note app and just run it on. Um I am an info person. I don't know what the best practices is to make sure this lockdown is secure that I have complete fault tolerance that all my node tools are gonna be configured to a point where I can easily migrate between the two without, you know, downtime, the questions are endless as you can imagine because this community is quite complex. And so you can see that the various layers that you have are, are quite cumbersome, right? You can work with the infrastructure itself to get the raw building blocks. You can then do manage clusters. If you're running something like gkeeksaks, then once you actually have the cluster up, you have the ability to then configure a multitude of, of properties depending on what you need. Off, logging policies, service matches, et cetera and on and on of the stack. Oh the X including things like it depends on like English controller, DN managers, managers. Um But the cool thing is that because we are an API if any guys, you can uh leverage many SDKS as we've noted on the left uh to work with each of these layers of the stack or mix and match. However you see fit. Um This is only what relates to communities, but we also expose the full service catalogs of all the major o writers. So if you do serve list, if you do um just rock compute and V MS, that's also all you're V to. So one of the, if I can remove this bar because I don't know, I guess not. All right. What I tried to do here is like what is the bare minimum I need from cluster, both on the infrastructure side and the cluster to have a cluster that's both production ready. That's limited privilege, least privilege, right? For uh the infrastructure identity as well as the identity. What is um the configuration cluster itself to make sure that it's fault tolerant that is segmented by not and more importantly, once uh that's all up and running, how do I share this cluster? Right? Multi tenancy, there's many properties in communities that allow you to configure multi tenancy at the bare minimum. You need name spaces. I am for these names spaces as well as our back, the names spaces and quotas, right? That's, that's the the bare minimum. You can't really see this on the bar, but also runtime policies, you can extend that to your arts content. But on the infrastructure side, that's what most of the off folks, off folks are working with. If I'm a developer, I don't care about any of this junk, right? I just have my app, I want to store in a container and then I want to leverage the resources and communities to make this go live and even to the point many people don't even want to learn the resources, they just want to ship a container and be done with it. So as you can imagine, all this setup is very cumbersome. If you don't know what you're doing, if you don't have the, if you already have a day job and you can't learn criminal on the side, right? Um If you don't know what the the proper dos and don't are, and more importantly, this is an evolving surface area that just kind of continues to, to grow and, and to get more complex. Um So the idea behind what we have at Pulumi is that because we have code and we create reusable code um because we can dispose of those libraries. We wanted to eliminate as much of the boilerplate Croft as possible while still giving you the raw building blocks. So you can choose to drop down to that native API that you're used to working with, right? Or you can use our, our libraries are really helpers. We don't like to call them abstraction because the notion of leakiness does is a real thing. It's about reducing the boilerplate. It's about improving the authorship experience. It's about improving kind of the the zero to the aha moment, right? So if I'm an person, I have my own responsibilities, I have to work with. If I'm as person, I have to do uh my own series of stuff. But as you noticed, right? Both Ops and Dev's folks are are kind of in the same kind of run of the mill uh cycles, right? Um They're the person who manages Infra, they're kind of managing two things, the cloud resources and the community is busted, right? So to go back to the earliest point, these are the basics, the cloud person is is iterating on identity on our back integration on source for buckets to storage containers, they're testing it, they're evaluating it, they're mining it, repeating with the cluster itself. They're creating the cluster, they creating the IMNS the cluster, they're in the back, the name faces quotas policies and the same kind of pipeline I tested it, I download it on back and eventually the ops gets to a point where like, all right, these clusters are solid, uh they're consumable for our apps, right? If they're like a platform team. Um and then we're gonna release that, that cluster uh to the apps uh folks to consume. So as you can see by decoupling this, because we have code, I can create an abstraction on clusters. You know, this is what our standard community clusters look like. No one's allowed to, to create clusters other than the S team. And the app folks just consume uh the credentials and, and basically a connection string um to, to work with Cuban fig on whatever platform on their end. So the app developer then consumes the all that access point into the cluster and they off, go off and do off their own loops, right? They have to build their apps, they have to test it, they have to run to make, to blast it into a doctor build. Uh They have to store it in the registry test out of L A for to repeat once the app is too fine tuned. Now it's actually the turn. So I'll put that into if I at a standard, right? Most applications these days are at least cloud native use some sort of persistent disc or volume. They have a fig map, you have secrets, they have employment services, they can have Englishes, they can have a bunch of Cr Ds that, I mean, the list is unless, but they go to the same pipeline. So the, as you can see, right, both us and Devs are doing the same sort of work. It would be so nice if both of those groups of folks had the ability to write code for whatever it is they're doing, test it, evaluate it and share it. And that's essentially kind of the the Hoppy bridge that Pulumi tends to, to fill. Um I wanna show a demo uh in a sec, but now you can have a, a high level of what Pulumi is and how we can configure infrastructure, pus deploy workloads into those clusters. Um And even decouple that uh whatever makes sense, we started focusing on some, some cool areas that we improve the developer experience around communities. So we just do something called Ploy Watch um much like I told you earlier where we have like this declarative state of changes, what you have, you know, it's very manual today. You have to do ploy preview. You ask that preview change looks good. Prove it. Do an update, rinse and repeat. Gloomy watch is kind of an ongoing loop that just never stops. Um And so what happens is the second I save my editor changes get deployed rolled out into my cluster on them. The wiser. So it, it helps with limiting the mechanics of actually working with us. Um And it's, and it's pretty easy as far as um once you have an established pipeline to just kind of work in your, in your own silo and save and then it goes off and shifts off into a cluster. Uh And that's kind of the the the mode that most developers want to work in. Similarly, we released uh a tool that's also in preview called flu mccurry. Where because we are, we have, we have code, right? We have the opportunity to not only tap into uh a live cluster, we can actually do fun stuff with it. So if you ever run a converted cluster, uh at some point, you ask, you ask you to call yourself the question like how many pods are out there running X version of my sequel, the standard today is to either keep control of your way through it or write your own plan and go app that's going to be a very tall order or you work to go. Uh And more so it is kind of um luckily, uh we have some smart folks at looming uh that were able to cobble uh what we call, which is a ability to query a live care clustering kind of T modes in both batch. And in streaming batch is kind of like uh a series of questions that runs to completion and, and streaming is the ability to just kind of watch uh an object change as it evolves um through the life cycle as it gets to play into communities as it lives in, cares as it lives or fails and whatnot. Um So that's kind of the gist of what I have to, to talk about it. Let's jump into it now and showcase some of this can people in the back seat. No. All right. It's gonna be fun. So, mm All right. So uh two categories, right? Infra on app. So we'll focus on info first. Um Angel showed off some of this uh in his, in his uh demo, I am also gonna leverage GKE because they are the fastest deploy, deploy of communities. So it makes for great demos. Uh I would not recommend EKS for no. So uh at the very least, right? Uh in that list I showed you you have to essentially set up identity a cluster and maybe some like default properties into that cluster. That's what an Infra team is concerned with. So here again, we're gonna operate at least privilege. I uh I create one service account that deploys the cluster uh into a GCP project. So these are isolated, you know, entities within Google, you can't control the entire account. So the C I CD uh endpoint of this will have a project owner and container admin on the on the project. So they can actually go off and instantiate the cluster but then we want to make sure that our application developers don't have the same privileges. So we go off and create a service account for them. Definitely locked down to um the following roles. They can only be a storage admin and a admin of the cluster that we give them storage admin is simply to be able to create buckets to store your, your containers in. So we can already be off to a much better start where we can share the same cluster and we can even lock them down to a particular news space. So in this identity, right, what we are doing is we create a service account for the developers. We give them storage admin threads, get the the key, the secret and create a bucket for them. Um All pretty straightforward stuff in the GK cluster just like angel is showing here, we can declarative state. I want my GK container to look like uh to look like this. I wanted to have these labels, these tags, whatever, how do you export the cup file? And then uh we had a touch of provider for crete that's just a wrap around Cuban fig. So all you need is a cup file to access it. So that way you can share actual resources around, right? As as any object um and have that be interchangeable. If you want to operate between different clusters in that same cluster, we're going to create an uh an app's name space again, you're seeing this all in code. So if you see one of the benefits of like jumping into working with code, I can go see the definition of this right here. Um I can see that here is what it takes to construct a name space and the sizing sucks on this, but I can see what's in a name space, an API version. I can see, I can see documentation, I can see metadata. Uh What's the metadata? Well, I can go to that too. Is that 9900 lines? Yeah. So this is the full API spec of communities and we absorb that into a library and expose it to you. OK. Yeah, that's not a part of this is not a part of No, no, this is not a part of the program. So I'm consuming the API that we of course. Yeah. OK. No. Yeah. This is not a, this is not 10,000 lines of code. Yeah, that would be the, the opposite way to move. Um But the cool thing is that we don't, we don't create new nouns. We don't create new API S, we don't create any new resources for you. It's the same resources you you've used to work with, we just expose it through language. But what you're saying, I make sure I didn't miss this earlier. What you're when you go ahead and create a cluster that you guys will actually create it to be a, you know, where you use best practices, so you don't make those mistakes of not knowing the best practices for locking them down. So you can kind of help eliminate some of the the the mistakes that can be made by some. No, absolutely not just nubes. I mean, folks, folks in the field, this is, this is a moving target, right? Is rapidly evolving. There's many, there's many new uh multi tendency means a lot of different things to a lot of different people, right? Um And that is kind of at the crux of of how to work with like the fault tolerance and making sure things don't fall over that things are gonna stay on, you know, when you're not looking, that's, that's kind of tend to be solved for the most part for uh for you by the providers, but they give you a vanilla shell of the cluster, they don't give you anything else. You just have to go in and configure your defaults and configure multi tendency and deploy workloads and share that cluster. So you're not having to worry that that's gonna fall over necessarily, but you're still starting from car block, right? Um And that is always gonna be the case. Mhm So is there a imagine that instead of using your library, I use the EP I library where I see the difference between the the, so the difference in that and for example, like, like I'll use bottle because everyone kind of understands bottle, right? You're still crafting the client from, from the initial API request to reading those responses to parsing those responses to storing it to your own objects, cashing it, manipulating it. That is a, that's the full like I wanna go full tilt and, and control everything. We are not doing any of that. So here we are talking because it's just an API request. We absorb the entire API into a library and then using C fig plus the client go library enact that into the cluster itself. So you're not writing the full clients from scratch, you're just, you're just be clearing. Yeah, you're just declaring a a space. This looks exactly what it will look like in Yale except I have the ability to clear a variable and the the ability to swap out which provider that gets created in. But this spec is the exact name space spec. So for the developers, I create an A space for them, I lock them down because I don't want them to go uh crazy on my, on my cluster, give them a bunch of parameters that are within range uh As far as CPU memory and resource quotas um and types of research they can create and then I even fine tuned them down and saying developers only allowed to access these API resources using uh R back roles and committees. But what you now have is the ability to declare all this reference these objects. So I not only create a role and create a binding that references my name space, that references also the actual dev role they created above. And so you try to do this in Yaml, you're doing a lot of copy basing, right? Or you're, you're trying to get outputs to, to be inserted or interpolated into your manifest of choice. Here, you're just using references you with anything else. And similarly, I can lock down uh not only the name space and how much they can consume resources in that name space and what resources they can consume, I can even create policies that say your run time is only allowed to use the following system capability, right? You're, you're locked down to, to not be able to, to tap into the host. You're not allowed to uh run as a privileged uh uh privileged process in the Linux name space. Um And you can see that all the way down to through for the rest of the configuration we have so we can by default and all this is exposed to you already, like I'll, I'll show that they help link at the end, but this is based on a bunch of reference guide in architecture that we've vetted, that have already worked. So we, we've done this in the field with customers as well as expertise from the team um across the past couple of years of running this stuff in production for for fortune 500 companies that give you a better starting point than just starting to trash. So um I'm running low on time so I'll, I'll fast forward through this. Um I didn't have time to show the whole C IC the demo, but as I'm a developer, uh now all I get is so in bloom, we have these notion called specs. So that program that I showed you for the infrastructure, I have a separate program for the for apps. An instantiation of that program is what we call stack. So you can have a de staging a prod of the same program. It gets to a point where you want to decouple these things, right? It just makes sense. I don't want one massive file for my cluster in my app, you know, all the all the defaults. So you, you break them up the stacks, the infrastructure of the apps. And here I'm actually referencing the output of the name space I created in the last program. So that cluster is in charge of creating all the properties that I am allowed to consume, do operate work within the guard rails. Here, I'm a consumer of that based on whatever my administrator gave me. So I'm creating the name space um that was given to me, I'm con uh consuming the Cuban fig file and the only uh the only hacking that is left to, to do to some degree is, is really on um on this much like uh angel showed in his, let me see if I can find it. Oh, I can't pull it up. I forget, forget where it's at anyways. It's just another file to do the G cloud off. Um So what I get from as a developer because I created a lockdown service account in the previous program, I can assume that and then uh I authenticate as that uh user before this program is run. So I can have decoupled pipelines in my C I CD that creates clusters with particular privileges that the boys into clusters with limited privileges. Um And you know, essentially lessen that that surface area. So I get to keep into a file from their previous stack. I get the name from the previous stack and I go off and create my program. Um And on this side, right, here's my note app, it's just standard not app. That's a hell of world. Um The left is the docker file, the the middle is the actual uh main and then here's the regulation TML file. Um But on the right is where you got to see um really what the kind of the power of, of having extractions are. So if you've ever written you, right, a persistive volume, a secret at the big map, the deployment of service, you're talking about hundreds of lines of code because we have code, we removed a lot of the boiler plate and you can define all those objects I just mentioned in 50 lines of code. So I can reference, I can create a new GCP registry here by importing the GCP library and say so import GCP from the UCP. I create a new registry gives me a new bucket. That's one line I pull down the local file uh directory. Uh note app, I pull the docker uh context out of that and I have a Docker image builder in code that pushes up to that repository. Uh So I can build it, I can create the registry, I can build the the docker container and I can push it up in 10 lines of code. Similarly, we took the surface area of the community's API or reduced that even further, you can now create a persistent volume claim and four lines of code. Um As you can imagine if you've written this, there's metadata fields, there's all these fields that need to be filled in. We need to take care of all that mind you. If this is too limited for you, you can you have the raw spec at your disposal to always drop in and use that that full spec. Likewise, we've done the same thing with the config map. So I only care about defining my data as to be some object, right? And here's a, here's a key value for a secret, same thing. We even have a, a random, a random generator that would generate two random uh entropy based uh passwords. So that in the community secret. Um And as you can see, right, like here we, this is the KX package we have the K eight. Is this the full API that you're used to working with? We just uh have an extension that lives on top of that. There. A lot of boilerplate, take the program and then pass them straight API, there's no involved. There's no Jason, there's no nothing. So that's one of the alle games uh of you never have to touch, you know, these, these Ds Ls ever again. And we, we came up with this notion we to around the team to around this uh for a while um of how to best encapsulate this. And if you've ever written the deployment in a service just on those two, you're looking at about 70 lines of code. And we have this notion of a called a pot builder and that is just the basics, right? So even with defining environment variables and queries sucks like this is a very tedious object oriented syntax manipulation you have to play with. It should just be a key value. So we need a key value. Your image should uh should always reference the, you know, again, we're working in code. So we're referencing the image we created earlier volume mouse, it should just be as easy as passing it versus in volume. And this thing on this end point there, you go. So this is the crux of the container, right? You can, this is one container, I can create an array of them. And the deployment is as simple as saying, here's this pod builder which is our our kind of our root uh object on the bottom to construct this spin it up two relatives. If that's not enough for you, you can always drop into the spec and see the full spec of as you would expect it and there you have it, you have namespace, you have, you have the spec, you have the metadata, you have all the stuff that you're used to working with. And likewise, a service should just be the ability to expose a certain kind on a deployment. So the service here is three lines, it says take the deployment, throw up mode, voucher type service in front of it, get me the end point, spit it out. So in all this 50 lines of code, we've reduced so much boilerplate and we create the exact semantic output that you would need for each of these resources. We don't create new nouns, we don't create new resources, we just remove the boilerplate question. So if you're working in pure J, are you able to do? Sorry if you're not working in a? Are you still able to do resources? Yes. So the Cr Ds are just another endpoint in the service area, right? So uh you can define the CRD to your in code as well. Yeah. And you can import them. Yeah. OK. A deal with three right there like 63. Yeah. Are you putting this in control? Yeah, this is all source control. No. So this, so mind you if, well, if you've ever worked with the community, the secret is not really a secret. It's, it's like a big map running in A S. Um So it, it is um so this is uh this is essentially referencing that this is obviously bad practice, right? You would not want to do this. You would need something like a vault or A K MS or something along those lines. Uh But the idea that, that I'm showing you here is whether this is password, this is random data, you know, to see something, you can just reference it as an environment valuable rather than having to cruft a bunch of specs across the board and copy, paste that. So what you're proposing is that like when we saw Angels presentation, when we saw his files, we saw a file for um uh circle C I. Then we saw uh we could see files for uh terraform and these files look uh uh different. But what you're saying is that for a developer, they could be working on files for their application, they could be working on files for their infrastructure and they could be working possibly for the files that are on their um uh process as code which would be in the circle C I. But the first two, the application code and infrastructure code are in the same language, which helps people understand what the hell is going on with KTIS. Because you're, you're gonna make your cnet's cluster from scratch, put the application on it, which I find quite fascinating because uh the company I work with the Cooper clusters or app here and you're always putting stuff into it, right? So to to go one step further, you don't have to use the same language. So I can write my cluster and typescript and my application developers can describe their resource for their app in Python because right now all, all it's being shared is the output of that cluster like you config and what name space am I supposed to be working in? I can consume that however, I need. So you don't have to use the same language if you don't want to questions, I have two other questions. Sorry, how do you execute this? How do you, so the blooming tool is essentially it, right? So I will, since I'm already out of time um here, I'll show you a quick change like on like on the infrastructure developer, I had a whole thing with with good hub actions, but circle C I actually has way better documentation. So uh I actually had that running quicker, quicker than github action. So shout out to Circle C I for getting there in order Um So for example, if I decided that I wanted to make the developer not only be a storage admin, I wanna say they also can do like cloud sequel or whatever. Um Someone help me out as it rolls cloud sequel to admin one GKE. Yeah. Yeah. OK. Um So that is a single line of change. I can do a ploy preview. It'll and it'll tone in on the exact property that's changing. So this is gonna create a profile that's not good enough. Let's show you some more output. I can see a full rich diff and you can see that I'm actually adding in this object and a new I am binding to the roles about single do ain we have a panel that shows you all of that um With regards to um So this looks like, so I can see the preview of this similarly in my dashboard, I can see the rich diff and if you're working across an org, you can see like who did what I changed this on this commit linked to that commit and whatnot. Um And even more so you have the ability to enforce policies at a governance level. So I can say, hey, no one's allowed to spin up an S3 bucket with a public endpoint. No one's allowed to create uh a service on communities that has a load bound surge. Yes. All the way back. Yes. Yes. Um So I think the question I was asked about customer resources and this is sort of related. But you know, there is involved. In other words, you may have all you may have outing on it. So you know, those go up and down and go up and now other resources move around, right? How was gonna react to that when you uh if you know in terms of, for example, the previous show, but also when you wanna go and change something, knowing that the state may have evolved since the last time. Yeah, great question. So I have two answers. So let's look at the infrastructure and then look at the piece, right? So if I went in and said my VM is of machine type, whatever N one standard and I decided to um to stand that up and then you came into the dashboard on aws and you said delete the, the virtual machine. So the state of my world thinks that that VM was created, you went in to the back, deleted it and now it's gone. So next time I get, I have the ability to do a refresh. And that's is something that you would run either before a preview or before an update to get the state of the world based on, on what it's basically comparing what it thinks the state of the world is versus what the reality is and then trying to reconcile that. So that's on the easier side. That's because we have the the, we have an insight into the API through AWS uh for an HP A for example, like hori horizontal scale and or any controller for that matter, you controllers who states fully live in that CD. So we don't have that, that access into X CD. Nor should you expose that, right? Because CD is the key to your kingdom here. So even that, so that is operating in a fine window like GCP will say, like, you know, if your HP A is between two and five, it's gonna potentially spike up to seven, it may spike up down to two. You may have an average of about four or five. Even they don't necessarily make a claim as to how many notes you're gonna have at any given time, right? Because it's based on burst, it's based on availability based on utilization. Um and based also on kind of on your account status. Uh So that's the sort of stuff we don't have an insight and, and we can't be better in, but the reality is it's a very kind of murky problem because the controls and are just a reminder of their own right? And there's too many of them coupled that with too many Cr Ds, it's just to move from a service area for us to kind of have a good foothold in where here as you can see the state of the code that I'm writing is what I'm expecting it to be I can deploy an HP A but beyond that, I don't, I'm kind of walled off from that. Is there an ability to then just ignore certain things for the purposes of our? And I don't think where I say, you know, I know those are gonna change. Let me not look at that, let me look at the other. Yeah, you can ignore changes on certain properties. Yeah. And so for, for I saw the libraries for managing the life cycle in cluster, I saw your libraries eab I, who are you guys planning to say, for example API. Yeah. So plus RP I is a is a good question. Uh So for those who are familiar plus API is basically the, you know, I feel like every year we we in the community reinvent, how do we understand? Plus, right? Um Plus API is, is the current effort that the community is putting their weight behind. Um We have our eyes on it. We don't have any opinions on it necessarily just because it's still an evolving space. Uh We, we are in the mentality of that to some degree, right? Like unless you're on, on prem the cloud vendors are kind of one in the space, right? Um And it's easier to just your credit card than it is to try to, to be an srh or one of these things. Um So the the reality is if there's enough meat in the bones from a cluster API perspective that it makes sense for us to integrate. Absolutely. It's just another API, right? So if it's an API, we can wrap it in a provider and explode it through our library. So the same way that you can eat there and you have also not sure we have a, we have, I guess how easy it is for somebody, you guys, one of those for any other API for example, open shift. Yeah. So exactly. So we've actually got a request for Openshift. Um So anything that has a API is pretty much one of the easiest things we can do. So um we have providers for F five. we just added support for um uh for Digital Ocean. I mean, if there's an API, we can wrap around it. So the, the for the most part right now it's kind of like Pulumi employee guided, right? Because it's still kind of a novel space, but we do have customers that are actually running their own providers. How cost is, I mean, we have documentation, I think people spend, spend uh something like two or three days to get something going. So it's a matter of days. Um How are you? So I I imagine you, you know, you, you're creating objects in your, in your API. No, so we, we, we don't, we don't interface at all. We don't touch your credits. We don't, we don't touch your API, we, we just the API request initiate from your client machine, we build up the graph and we just make sure that graph is matching what the request from the client is actually very, what I meant to say was that um you know, you may be instantiating, for example, like the, the, the, the, the uh uh project or whatever, right? Uh I mean, uh but like it, you're tracking those relevant back and uh uh sort of uh clients, right? Like they, they, they change it. Sure. You mean the controller? It's almost like evolving. Yeah. So uh if it's a native first class citizen resource, then that's what the refresh, right? That's what's stretching the state at that current moment and then going to actually enact it when you do an update. Obviously, there's a window of time that if I happen to like switch the hood under it, right? What I'll get is a failed update. But it, it, the thing is we do it create before our deletes. So we have to completely create the resource in its totality, get a, get a, a secure uh you know, a guarantee on the transaction and then we'll tear down the old stuff. But until that creation deletes, we, we don't bother with that. So we do it in a very safe way. You do it like gaming complex, right? So by default, a lot of our resources, we have pen like a suffix, like a random suffix. You can disable that if you really want to kind of like control the naming of it. But we do that as a, as a safety default. So you can have the same, you know, VM with the same profile, you know, in a loop 100 times if you want. Yeah, one of the questions I had was earlier, you stated the one thing that, that you, that differentiates you from a product was that you guys can utilize any programming language like Python, what are some of the other key differential or key differentials that separate you from another product like Terra, which might be a little bit more mature or have been around the world. Yeah, definitely. I mean, let's, let's be Frank, right? Like we are standing on the shoulders of giants here, right? Like Terraform ha has was the first mover they've instantiated uh a a movement of, of being proactive about how you declare your infrastructure and how you manage an infrastructure. The reality is anyone's worked in Terraform long enough, the management of that or the HCL really? Um it becomes cumbersome, it becomes a pain, it becomes even more a pain when you're working on a distributed team. Um It's, you know, there's, there's always hack, there's a bunch, I would say it's not, it's not just HCL there and there's a bunch of blue coat and baskets helping the profit up, right? Um And so that is unfortunately the state of the world. Um but they they have set a precedent really for how folks should be managing infrastructure and we should not take that lightly, right? Like the reality is now we we kind of were born also in the post cloud era, right? They were born 10 years ago with vagrants was kind of the early onset of that. Uh And so now there is there's more paradigms that kind of first class citizens to us like do containers. As you can see, we can build a container in one line, we can push it to registry. Like those are functionalities that that are gonna require a bunch of HCL and it may not be as fluid. Not to mention you have no referencing, right? You can create modules, but I guarantee you pull and pluck two people out of here. The modules are not that reusable or not that contain because in our current form, I mean, it, it, it almost becomes a nightmare with all the different files that you can have everywhere and you guys overcome a lot of that problem. Yeah. So it's funny enough we can, we have the ability to and I'm running out of time already uh way past over time. Uh We have the ability to convert our form to like we can convert like 90% of it. Um So you don't have to like boil the I'll be around if anyone has questions. Um Everybody in Boston. OK.
---
