---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Ep 010: What's New In Pulumi?"
title: "Ep 010: What's New In Pulumi?"
meta_desc: |
    This week Luke covers new features and community contributions from the last month. More cloud!
url_slug: ep-010-whats-new-pulumi
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Ep 010: What's New In Pulumi?"
  description: |
    This week Luke covers new features and community contributions from the last month. More cloud!
  sortable_date: 2018-08-22T19:35:44Z
  youtube_url: https://www.youtube.com/embed/u0aSHhfUnMc
transcript: |
    All right, good morning, everyone. Uh Welcome to this week's episode of Pulumi TV. Uh My name is Lou Cobin. Uh Today, I'm here to talk about some of what's new uh with Pulumi for Kubernetes. Uh So last week we released uh Pulumi 0.15 which is the latest release of uh of the Pulumi uh uh tool chain and libraries and frameworks. And one of the major features of this release was uh new support for KTIS and improvements across uh a lot of the existing support for KTIS. Um So to put that in context, Pulumi really lets you sort of manage all kinds of resources uh in the cloud. So everything from resources inside your cloud provider inside aws and Azure and GCP, as well as resources um that are deployed uh via s whether that's on premise or in one of those cloud providers. Um And so with the support for as well as the support for open stack that we released with 0.15 now can sort of take your entire kind of cloud application uh and manage and deploy those resources with Pulumi. So today, I'm gonna really dive a little bit deeper into kind of just using Pulumi directly for working with uh Cober resources. And what Pulumi brings is really the ability to kind of structure the way you think about deployments to Carbines in a bit more formal way. And that's from a few different kind of perspectives. One, you get to sort of describe uh the dependencies between components that you're deploying to knees and make sure that you stage those uh rollouts of different components uh in an intentional way. Um Instead of just, you know, coop control dash F uh to, to, to push some YAML up to com. Uh Here, we can describe and orchestrate sort of interesting and more complex deployments um And make those uh be able to, you know, make one change and then wait for that change to have been applied so that we are in a stable state and then make another change. So we'll see how we can use Pulumi to describe that sort of thing. Additionally, Pulumi of course, lets you use programming languages, so software to write your applications and your deployments instead of just using YAML. And so even though we still are using a declarative kind of technique where you, you're describing the goal state of your infrastructure, the ability to use code, lets you sort of describe usable components, create abstractions, give names to things, do make things better. And so we'll see a bunch of the ways in which being able to use a real programming language. In this case, we use javascript and typescript, uh gives us a bunch of sort of ability to, to structure our code in sort of more formal ways and benefit from kind of software engineering practices. Um And finally, the ability to sort of combine uh Pulumi support for uh COTIS with Pulumi support for AWS and Azure and GCP means you can uh build applications that span both. And we've seen uh when we talk to, to users and customers of Cober, they're frequently uh also users of other cloud platforms. Um And so they want to build applications that span both that store store objects in S3 or that use a managed database uh in R DS for example, uh but run their compute within uh KTIS. And so this ability to, to build applications that span both uh public cloud infrastructure and KTIS for compute um is one of the really unique things uh that, that uh Pulumi uh provides. So with that, let's just see a few kind of concrete examples of uh of what it looks like to use uh Pulumi with KTIS. So I'll come over to uh visual studio code uh And we'll look at just a simple example here. Um So let me go into this folder. Uh First off, I should note um in our examples repository here. So this is github dot com slash Pulumi slash examples and we have quite a lot of examples overall. Uh So we have examples for using Aws for Azure uh for our cloud library, which is sort of a high level library that, that crosses the different clouds uh for GCP and for, and as part of the release last week, we actually added three new examples of coins to highlight a few more different ways you can apply uh Pulumi uh to cos application development. So I'm going to walk through each of those examples today, kind of show off some of the interesting things that those examples uh highlight. So the first thing I'm gonna do is is go look at the CTS uh guestbook example. And so let me just go into that folder here. And for those who, who aren't familiar with this, um the the guestbook example is sort of one of the canonical examples that release has had um in their tutorials ever since it was first released publicly. Um And it walks through deploying a simple application in this case, is actually a PHP application um uh that's a dark application uh um and is being deployed with some red uh master and slave instances as well as a deployment uh that scales out a number of pods to run the front end uh um uh HDP service as well as a service to actually um um pro provide access to that. And so uh if you go into the documentation, you see lots of material where they cover kind of walking through doing this using the KTIS Yaml. And you can see, you know, there's, there's quite a lot of Yaml, even for this fairly simple app, it's, you know, uh there's a lot of details, you kind of have to fill out and to apply using coop control, apply dash F. Uh And so it's, it's a bit involved even just to kind of stand up uh this example. But, but it's a good example to go through to get a sense of kind of um cumbers basics. So in this, uh in this case, we actually went and took that example and um and ported it and showing what it looks like uh in Pulumi. And so I'll walk through a few of the sort of most salient uh points in this code and then we'll see kind of what the work flow looks like to actually work with it. So the first thing is uh we're using the Pulumi community library. And so this library is how we get access to all the cnet support. Um And this library actually uh provides access to everything that's available in communities. So every kind of resource that is available within communities is projected and usable from this library. And so I can come in here and say something like, you know, let X equals new Ks dot And you see, I get access to everything that's within um uh you know, this library. So apps V one I can get replica sets, statement sets, sets, uh all of the capabilities including uh bleeding edge things that are only recently added uh into the cubers API surface area. And this will actually um based on the uh the cluster that I'm connected to, this will actually connect to that and make sure that the um the API is supported. Um And then if it's not supported, we will actually give you early errors saying that that capability is not supported in your cluster. Um And so you can access through the API everything that's available in communities. Um And that will correctly uh work or error in a useful way. Um If you're running in a cluster that doesn't yet support that capability. So even just getting that intelligence, there is actually pretty handy. One of the nice benefits of being inside a programming language is we can sort of, you know, get that, you know, Ks dot uh you know, this kind of ability to explore the API surface area is something that's really nice when we're kind of using um a tool like your code and language like like javascript or typescript here. Um But let's go see what it looks like to actually use that. So the second thing you'll see is that we actually have a local file dot slash util where we have some of the utilities. And so I can click on that and we see that this is a way to sort of break up our code into multiple files to sort of factor it in the same way, we might some sort of application code where we factor out a helper function here which deploys sort of a, a particular pattern. In this case, you know, it's returning a deployment, but it's a, it's, it's creating a deployment with a particular kind of pattern, a particular way of applying a name as a set of labels for both the selector uh and the um and the labels to apply on the actual uh spec itself. And so in this case, and also in this case, just to deploy a single container. And so this just provides a really simple api surface area to a common pattern that we might want to use throughout this application. And now if we want to make changes to this, we can do it in one place and have those be applied everywhere. And we could do this without having to just do sort of templating or that sort of thing where we just, you know, match up strings or whatever. Here it is actually software. We're getting type checking, we're getting, you know, completion list, we're able to document this with, with a comment, all the things we sort of expect from kind of a software engineering thing and we'll see how we use that utility in just a second. The next thing is Pulumi has a notion of configuration and so I can actually provide external configuration to one of these Pulumi programs before deploying it. And so, in this case, we've parameterized it by a configuration parameter is mini cube. And this will decide whether or not we deploy it using cluster IP or our load balancer just because load balancers are not currently supported in Mni Cobe. Um And so this allows us to sort of parameterize the way that our application can be deployed and allow users of the application or people who are going to stand up this same code base to deploy multiple instances of it with different kind of parameter organizations. And so let me uh come down and before I actually walk through the individual pieces of code, let's see what it looks like to actually use this. Um So I can say gloomy stack and knit and I'm just gonna say guest book. Um Actually, first off, let me just show you one other thing. Um for these examples, I'm actually going to um I'm gonna run them against GKE. Um So you can see, I actually have a handful of contexts in my coup control. Um So it's I'm wrapping a little bit but you see, I have, you know, do for desktop, I have mini Cobe, I have an A K Azure container service cluster and then I have a couple of GKE clusters as well. Um And so we can support any of these uh with the Pulumi Kriti support. Um But today, I'm going to use Gkegke has very nice uh core support generally. And so I'm going to use that for some of the demos here. And so whatever I've picked is my current context uh on coop control will be the default will attached to with the Pulumi Cober provider. You can of course override that you can provide your own coop config you can provide your own context to pick as part of configuration of the application. Uh But by default, uh we'll just kind of do the right thing and pick up the ambient context that's been provided. So, with that, I'm gonna say Pulumi stack and knit um and Pulumi stack and knit, lets me create a new instance of this application. Um And so, in this case, I'm gonna say Pulumi stack and knit uh Luke uh guestbook uh GK. OK. Um So now I've got that and now I'm gonna say Pulumi update and this will go and try and apply um all of the changes described in this uh Pulumi application uh into my target environment. And we should see this will actually give me an error. Um And it will tell me that the guest book is Mni Cobe configuration parameter is required. And that's because we said this configuration parameter is required. Um And so the application can't be deployed without providing a setting pieces. So I can come in here and say glum config set. Uh Let me just grab that. And I'll say it's false because we're going to run this in GK. So let me now say Pulumi update, this will actually go and show me what it's going to need to change, to deploy this application. Now, the way the plume works, uh we uh by default, always show a preview of what changes we're going to make uh to your target environment before we go ahead and actually deploy those. And this is a really nice way to understand what implication there is to the action you're about to take on your target environment. In this case, we see we're going to deploy six things, three deployments, a front end and then the Reddi master and slave associated with that and a service front end and the services to support those two redis capabilities. Uh If I say details, I get to see the, the full details of what this is going to deploy. And this looks a lot like the, the Kubernetes Jason or Yael that you might see. Uh if you were deploying this, I'm gonna go ahead and say yes and let that proceed. Uh And while it does, I'll show you what some of the code uh here looks like. So we see that we use that util dot deploy container to deploy a simple container with just the parameter we care about the name, the image, it's going to specify the resource requests and the ports that need to be exposed we can then describe the services using core V one service. Again, really, the only text here is kind of the stuff that is uh is really required for this particular application to be stood up. What do the same thing for the red slaves? And roughly the same thing for the front end. The biggest difference for the front end is of course, we're actually able to write sort of custom code here to say if it's mini cube, then cluster IPL load balancer. And so his ability to write arbitrary code, we could have this be arbitrary logic that reads something from disk that makes a network request. Anything we might want, we can do that just in line as part of constructing the JSON or YAML kind of specifications for these components of the service. And so this is a really nice and kind of natural way to do that once you're working within a programming language like javascript here, and then finally, we're going to expose sort of the key piece of information related to this deployment, which is what is the IP address of this service that's running now inside my target cos cluster. In fact, here again, we're going to switch on whether this was mini coup or not because it was mini coup, we'll get that cluster IP. If it wasn't, then we'll get the load balancer and find its ingress IP address. And so we see when we actually ran that um it took just, you know, what did it take uh 52 seconds to kind of do that deployment? Uh And it created the deployments and then created the services. Uh We got some information about, you know, the um the IP address being allocated for the front end and about the end points being created for all of those. So we got some useful kind of status during that deployment about what state each of these resources was in as it was being deployed into my community cluster. But ultimately, the most useful thing is that I got this front end IP address and so I can do something like, you know, uh open HTP, colon slash slash and I'll just do uh Pulumi stack, output front end IP, that's not gonna work. OK? So there we go. Now, we've got a guest book, uh application running. Uh And I'll just say hello from Pulumi, not sure why that didn't work. Um But we have a guestbook application, right? Um Try it one more time, right? Uh Not sure what's going on inside the GK close to there. Um But we will come back and look at that uh after we've looked at some of the other examples um as well. Now, one thing to notice this deployment is actually tracked inside the Pulumi console as well. And so we see that the stack that we stood up, I can come to app dot Pulumi dot com and see the information about that stack. So I can see that configuration I provided, I can see that output, I can see all the different updates I've done to this stack. And I can see all the different resources as well that are available within this stack, including a nice graphical view. So that's a quick look at what I can do uh to build one of these. So now the other interesting thing I might want to do here is say, you know, bluing uh config set. Uh And I wanna say is uh let me see what my configures. So I list them, I configure and now it's set to fault. But imagine I want to change this to truth. Uh take a, take a look at that. So now I've changed that to true. And now if I want Pulumi update, we'll see something different. We'll actually see kind of a dip of what's going to change. In this case, the only thing that, that uh change impacted was the value for the service. But because this is changing this service from a cluster IP based or from a load balancer to a cluster IP based service, that's a change that is actually does not allow to be made to an existing resource. So it would reject that change if we tried to make that change in place. Instead, we would have to, to make this change, we have to have to replace that resource. So we have to create a new service that is oft cluster IP and then delete the old service. And so if we want to go ahead and do this, uh Pulumi will let us know that we're about to replace this thing. And that's going to be a destructive change because it's actually going to change the externally visible IP address. Um And so we will see this, we'll say, OK, we want to make that change at this point. We're going to say yes. And this will go ahead and uh and do a few things first, create the replacement. Um So to make sure that the new thing is stood up before we tear down the old thing. Uh And that will stand up the service with a cluster IP. And then as soon as that's done and we verify that that worked correctly, then we'll tear it down and you'll see the front end IP is now different because this is now the cluster IP based front end IP. And then if I can remember how to do this co control port forward uh service slash. And what was the service? Here we go. Uh Does that work that way? OK. So now we're port forwarding to that service uh on port 80 81 on our machine, uh port 80 inside the inside the cluster. And so let's see what we have running at uh 80 81. Now. So here we have that guestbook running on that proceed service against that cluster IP. We don't have a load balancer exposed on the GKE cluster, but we can still access it uh using that new IP address. So a couple of things there, one you know the ability to easily sort of configure uh these kind of applications and have those uh configurations via code actually lead to interesting changes to the deployed infrastructure. Uh But then those interesting changes being described and, and being uh explained through the Pulumi cl I in terms of the specific implications they're going to have on your infrastructure. So that can be audited, reviewed and before actually doing the deployment. OK. So that, that's a simple example. Uh I can then come and say fluy destroy if I want to tear this thing down, uh That'll tell me it's going to delete all of these resources. I say yes and it will deploy uh each of the services and then each of the deployments uh as well. So just give that a second to complete. Well, that's going, let's uh go over and find uh one of the new applications that we want to take a look at. So let's next look at this um uh config map uh rollout example. All right. So in this example, uh there's a couple of uh interesting things we kind of want to highlight. So this example is really about how do we orchestrate changes um to an existing application. And so one example that, you know, we've, we've seen uh uh some folks who talk to bring up, that's a pain point. Uh For some folks in using Cobert using Coop control and trying to coordinate deployments is when I have a change to a config map and I want to actually cause that to uh roll over a service that depends on or deployment that depends on that config map. Um So this example here, what we're going to do is uh post a engine uh config file. Uh So let me open that up as well just to give you a sense. So we have a default config for engine engine, which is just going to forward me to Pulumi dot github dot IO. Uh And I'm, I'm going to store this in a config map and then I'm going to create a deployment which actually mounts that config map. And so this is all just fairly standard COTIS and then I'm going to expose a service that similar to the previous example uh just as a front end to that particular deployment. So what we're going to do is first we'll stand this up show just that we can bring this application up as you'd expect. And then we'll see what happens when we try and change that config map and how we can coordinate the deployment of that config map and the implications it has on the change to uh our deployment object. So let's take a look at that, um, we're going to come over here and go to KTIS TS config map rollout. And again, I'm gonna Pulumi stack of knits uh uh config map with GK. Uh and then I'll say Pulumi update. Uh And again, I need to uh set this config variable. So let's do Pulumi being set. And OK, so now let's do Pulumi update. And this will just like before, um show me the things it's going to create. In this case, it's a little bit simpler. It's just that config map that deployment and that service. And so I'll go ahead and say yes, and we'll deploy these out uh into uh our target cluster. Now, one other thing that I'll note just briefly here is uh we actually to get that uh that default dot com, we actually just use no FS dot red file sync. Um And this is sort of handy this, this just shows us that we can do whatever we want to uh you know, from a code perspective because we have access to a no, just run time to do this deployment. We can just read a file off a disk or we could have retrieved this from a network share, we could have gone and uh used some secrets management system that we have credentials for only on our deployment environment to go and read that out of our uh you know, uh parameter store or whatever we were using inside our cloud service. To store these secrets. Um Anything we want to do to construct the inputs to a program, we can do programmatic here, but it'll still be used as input to define a declarative, desired state. And then as we saw, we'll preview what implications that has for the changes to the application. And so even if that file changed on disk, we'll still show a preview of here's what changes are going to need to happen as a result of that. And so here I now have uh this and so I can say curl, you know, uh oh I need to do dash L to for to follow redirects. Um And so here we see, we're actually hitting Pulumi dot com and this is the title for the the Pulumi dot com web page. Um And so our server that's forwarding reverse proxy to Pulumi dot com is deployed and working inside GK with that load balancer deployed using this application. So what we want to do now is just change that uh config map. And so maybe I come over here and I will say, you know, do, do do, do you know just google dot com. OK. So I'm just gonna save that on disk and come over here and say Pulumi update. And like we talked about because I was using that sort of FS dot read file in node. This the input from this file is now actually part of my specification of my desired state. And so just by changing that on disk, it actually changes what my application is saying, its ultimate desired state is. And so we'll see that Pulumi tells me what it thinks it needs to do to achieve this new desired state of this new, newly forwarded address. And there's two things here. The first is that config map, it needs to get replaced. We need to create a new config map inside our, our cluster with the new information. And then we need to update our deployments to point at that new config map. And then ultimately, we'll tear down the old config map because it's no longer being used. And so I can again come in here and look at the details. Uh We can see the exact details of what's going to change. Um So, for example, uh we see that Pulumi dot github dot IO changing to google dot com. Uh And we see the uh the deployment changing its config map name from this one to this one. So we can look at all the details and make sure we're really comfortable with that change before saying yes. And again, just like we saw before this will create a replacement, say it replaced it and then update the deployment uh with those changes and finally delete uh the original. Um so it happened very quickly. Uh but all those steps uh actually happened in order. And so now if I go and hit that same URL. Uh We should see I get different content back. Um Maybe go google dot com doesn't turn correctly. Well, we definitely get different content back. Uh It looks like it's an error four or four not found. Uh Maybe we have to go to www dot google dot com. Uh Just for fun. I'll do an update and see if that works. No, no. Uh not sure why it's not liking the upstream of, of that site. But uh but regardless, uh um we'll see that we've got different content. So the, the rollout did uh did work correctly there. OK. So that's an example of just kind of how we coordinate these things. And this is where I think uh Pulumi in general comes in very, very handy. The Pulumi fundamentally understands the dependencies between different resources in my application. And so this uh if I come back over here to the code I was looking at in this code, uh We see that this config map here X config uh is a resource. And then I get the config map name by grabbing the metadata name property. And then I use this config map name as the input to the volume here. And so by doing this, by passing an output of the config map as an input to engine instead of just having two strings which might happen to match. Uh I actually am declaring to Pulumi that there's a dependency between these things. And So it should make sure that whenever this changes, it make the appropriate changes to the engine resource here or the deployment resource. And this is the core of sort of Pulumi Planning engine is its ability to understand dependencies and understand when changes to one resource imply that another resource needs to be updated in place or it's self replaced. This dependency information can also be provided explicitly so I can provide depends on And if I want to explicitly say I depend on that thing and not just rely on the implicit dependencies via these parameters being passed through. I can do that as well. But by default, I get very explicit sort of dependency information being captured uh just by the core structure of my code. And this is something that when we do uh application development targeting sort of the major cloud providers is really critical because they have much more structured sort of, you know, dependency information where to, to create some certain resource I have to have previously created several others in cos this is less true. Uh There are, there are many resources where I can stand up both a deployment and a service and uh wait for, they'll just sort of internally kind of keep cycling until uh the other one is ready. Um But there are many cases where I actually do intentionally want to cause certain updates to happen because a dependent resource is changing and oftentimes those things are pretty difficult to coordinate using. And so folks end up having to kind of invent a bunch of scripting outside of Kris itself to coordinate certain kinds of release processes. And this is the sort of thing we really want to make just a simple part of the authoring process for deployments um by using uh Pulumi. Um So this example again, uh just exposes uh kind of this is mini cub and the ability to, to factor over these things. So before we go, let's look at just one last uh example here. Um And that is this Helm wordpress example. So in the previous two examples, sort of one of the salient characteristics of them was that we kind of wrote all of the Kubera resources inside a Pulumi program. And so that meant that if we had existing YAML files or we had existing uh helm templates, um We were talking about sort of rewriting those things inside Pulumi and doing that does provide many uh many benefits like the ability that we saw in the last example to actually declare and understand dependencies and track those and do coordinated rollouts. Um And obviously the authoring benefits of just writing this stuff in, in software and being able to extract over things. Um But obviously, uh folks using coupons have lots of existing carbonate artifacts, either uh defined using existing uh uh YAML files or using existing Helm charts. And so using the uh Pulumi Kubernetes, uh support, we actually also have the ability to import either Helm charts or Kubernetes L files. And this allows you to take existing assets as is and just incorporate them into a Pulumi program and take advantage of Pulumi for sort of coordinating the deployment of those assets. Um and for potentially marrying that with the deployment to Aws and Azure inside the same program. And so in this example, we're just going to deploy wordpress. And so we're going to use the Helm chart, we're going to use the stable repository that Helm manages. We're going to specify the version of that we want and the chart name inside the stable repository, which is wordpress. Uh We're going to then grab, we know that inside that uh Wordpress Helm chart, several resources get created and one of them is a V one service whose name is WPD dash wordpress. Um And so we'll go and grab that resource out and then we'll read some properties off of that to expose what the front end IP address is for this. So let's take a look at that uh here as well. Uh Helm wordpress. And like before, I'll just say Pulumi stack and knits uh Wordpress GK and I'll just say Pulumi update. And I suspect just like before we'll need to specify this is mini coop thing. I should note this, this is mini coup thing is something that we've done in these examples. You can of course in your own applications provide whatever configuration you want and you don't have to provide this kind of is MNI Cob configuration setting. And if your deployments tend to be all to a particular environment that you know, does support some things, you can make these optional configuration that's defaulted to the right defaults for your environment. For these examples, we chose to make these required config to make sure that folks have a good experience and and and don't have things fail unexpectedly because they're running in in one off mini cube or an environment that does support load balancers. And so again, I'll set this to false and now we'll run that Pulumi update one more time. So this is gonna create uh 13 resources. So a fair few more. One of the key things on there is here that's different is we're actually creating a component. And so Pulumi has this notion of components which are uh resources that you can create. In this case, this one here uh that themselves don't manage any particular resource in a, in an external uh cloud environment or Kubena cluster, but virtually manage a variety of other resources. And so in this case, this chart uh manages a bunch of other other Pulumi resources, each of which is a specific resource tracked in an external provider in this case in the Cubana cluster. And so we'll see that we actually get those nested underneath each other. And so we each chart that we deploy will actually be a different node in this graph. And we'll be able to see all the different components that we've deployed as well as all the individual details of those components. So I'll go ahead and say yes, the key thing here is that we actually just extracted all this information out of that helm chart. And so we actually did all the same things that helm does go and grab that chart, template it out using the helm templating system and then uh create the YAML files uh that uh that cuz expects and then read those YAML files in and populate a set of uh Pulumi objects to represent what we want to deploy out into uh KTIS. And so just like before, you know, we see all this deployment and we see the progress as this is happening, the ability to get an insight into what's happening during our deployment is a key thing here. We can see which pieces are already created. We can see that this service is actually still creating that needs to allocate a load balancer. So it takes a little bit longer and we see that the deployment of wordpress itself is still creating, that's the actual deploying the pods and making sure that that is healthy uh which requires pulling down that darker image and a bunch of other things. Um And so we see now that the the service end point is available and we're just waiting for this to deploy. And in fact, we can come over here and look in the um uh Google cloud console. So if I come over and look in the Kubernetes clusters, uh let's look at the workloads, just look at our cluster, maybe we're not deploying into this one. Let me just uh see, maybe, maybe I'm deploying into a different cluster here. Uh No, there you go. Uh So, yeah, so we see that, that uh WP DEV uh service is actually deployed here. Um uh And uh as well as the Maria DB instance that we specified, I mean, so if I come here, we can see the external end points available for the HTP and HDPS versions of that service. So I'll give this a second to finish deploying. I recall this does take a little bit um to deploy this particular uh chart. I think the word press uh darker image takes a while to pull down and then to uh to deploy, we got a warning that the, the pod failed. Um So one of the nice things actually is that we do get these warnings um uh and information and feedback about uh failures to deploy uh the application. Um One thing I'm gonna do, I'll just click hit, cancel here. So one thing we can do is if, if we're failing to deploy uh one of these things possibly because we don't have enough room in our cluster or something like that. Um Let me just control, see, and we'll see uh what happened. Um, uh, looks like we were, uh uh since we're not able to deploy, let me actually just do one thing. I may have too much stuff in my cluster. And so we may be not able to schedule the um, deployment of this. So let's do the config map rollout and I'll just do a Pulumi destroy here uh to, to remove the resources that I was just uh to play. OK. Uh So now I've got that uh rolled out. Let me make sure the other one is deployed as well. Uh Which one was that guest book? OK. Nothing to deploy there. So now I'll come back uh and we'll look at our home chart. Uh So the first thing we'll do is we'll just do a Pulumi refresh uh to make sure that we uh capture any state that was in the cluster and make sure that that's uh adopted into our um uh our current state. So Pulumi refresh will actually go out to the cluster. Uh make sure that we've updated ourselves with the information from the cluster. Um And then we can run Pulumi update to try and continue to do the update from the state that the cluster actually is in. And so we'll see here. It'll tell us, oops, right? Looks like we hit a uh bug there. Um Let me just try, let me try and we'll start this thing again now that we've got some room in the cluster. Right. No, it's not gonna work either. All right. Let me just create a new stack. Um I will config set that as well and we'll just do a quick Pulumi update. Actually, that probably won't work either because we have all the resources deployed from the last one. All right. Well, we could, uh, we could here go and sort of de bug uh what's going on inside this particular cluster um in this particular service. But uh um we have used up quite a bit of the time uh today. So um I'll just kind of skip that step. Um uh We could stand up a new stack, we could tear down the old one using Pulumi and we could also go in and use the console to understand kind of what the detailed status of this is uh inside the cluster. Um So that was a quick tour of kind of how we can use Pulumi to do KTIS deployments. You'll see there's a bunch of examples that we didn't cover here on other things. There's a very large example of using KTIS for a quite complex application, the sock shop sample application. It's also kind of an example of deploying Jenkins. This is sort of taking one of the helm charts for Jenkins showing what a full application including state, full sets looks like using Pulumi and, and some other simpler ones around just exposing a deployment to the internet. And so these are some simple examples. Um We also have uh an interesting example, um some examples of using a KS uh to use Azure community service and to use E KS. Um And so I'll just quickly show that e cases example just because it's, it's interesting, we might come back and look at this in the future with Pulumi, we can sort of one command deploy an EKS cluster on AWS. And then we can combine that with deploying Kums resources into that Eks cluster. And so just like we saw in all the previous examples today, we can easily deploy knas resources, but we can also do things like stand up an EKS cluster plus, deploy resources into it to get a full end to end application, stood up in one Pulumi update and managed using one command. Um And so using this Eks uh Pulumi Eks library, uh we'll see that it's just as simple as kind of standing up a new Eks cluster and this is something we'll have more to talk about kind of in future sessions. Um But it's a really nice thing to combine with the fundamental support uh for OK. So with that, uh um I'll finish up for today. Um As a reminder, you can uh get started with Pulumi Pulumi dot com or at Pulumi dot IO, you can join us on our Slack channel and the link up here. Um You can come and check out the github repositories for all the different components of Pulumi, which are uh which are open source. Um And of course, you can use Pulumi today for doing community deployments for doing uh raw infrastructure on AWS or Azure or GCP and for doing kind of higher level container and serverless application development. Um check it out uh today uh and join us on uh and in the future for other episode of Pulumi TV. Thanks a lot for joining. Uh We'll see you again next week.

---
