---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Snowflake - Day-two Operation of Multi-cloud Kubernetes and Vault | CES 2020"
title: "Snowflake - Day-two Operation of Multi-cloud Kubernetes..."
meta_desc: |
    Snowflake is multi-cloud. So is its infrastructure. For two years, Snowflake’s platform team has been building and operating 100 (and growing) Kube...
url_slug: snowflake-daytwo-operation-multicloud-kubernetes-vault-ces-2020
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Snowflake - Day-two Operation of Multi-cloud Kubernetes and Vault | CES 2020"
  description: |
    Snowflake is multi-cloud. So is its infrastructure. For two years, Snowflake’s platform team has been building and operating 100 (and growing) Kubernetes clusters on AWS, Azure, and GCP. Today, we run on average a total of 60k Pods to unlock $7M annual savings.  We use Pulumi to provision cloud resources and manage HashiCorp Vault. In this talk, I will present how Pulumi has enabled Snowflake’s scale and growth: * How we leverage Pulumi Automation API to build custom rollout strategy for all Pulumi stacks * How we achieve blue-green upgrades for Kubernetes node pools * How we manage HashiCorp Vault using Pulumi: - rotating issuing certs (that signs Istio private gateway TLS cert) - static secrets (such as Teleport join-root token so k8s users could use one CLI to access all clusters and nodes) - cloud-provider secret engine (to generate scoped and short-lived tokens for services and automation) * How we generate and manage cloud-agnostic Kubernetes manifests by integrating with Pulumi stack outputs * How we use Pulumi Operator in CICD for auto-apply and audit  This talk differs from the one my colleagues did in the Cloud Engineering Summit 2020. They focused on the container platform design (logging, monitoring, networking, etc). I will lean more towards implementation and the day-2 experience of using Pulumi.  Talk by: Charles Xu
  sortable_date: 2021-10-20T23:01:26Z
  youtube_url: https://www.youtube.com/embed/0iAwwtjQvhw
transcript: |
    Well, hello everyone. Thank you so much for joining me today. My name is Charles and today I would love to tell you more about our multi cloud experience, building a multi tenant container platforms on Ruber net use and vault. A bit more about me. I work on the container platform team at Snow float about more than a year and a half ago, my team started to build a to build and operate a cloud agnostic container platforms based on net. And today's talk is mostly about our experience and lessons of doing so I am excited about cloud native infrastructure as well as the ecosystem. So I've been a contributor to several open source projects in this domain. Previously, I worked with Cruz a self-driving car startup and my job was to design and implement a hybrid cloud through the Nega platform spanning GCP as well as on premise infrastructure. And before that, I was working at Google on the team, the infamous open source service match. You can learn more about me and my personal websites as well as by scan the QR I would like to begin my presentations by sharing it with you. The key takeaways of this talk. I I want you to take this message with you before I dive into the stories and analysis behind them. And then I will explain what snowflake is. Uh what is the data cloud and what is, what is the implications for the snowflake infrastructure. And then I'll give you an overview of the our container platforms. Uh What are its current scales? What are some technologies that we use? And uh what are the applications that we run on this platform? And then I'll dive right into the cloud technology of distractions and explain to you how this strategy has enabled us to expand our support into the three major cloud providers so efficiently. And Pulumi has been a very important tool uh to unlock the project's success. Um I will share examples of our experience of using Pulumi to provision cloud resources as well as managing vaults. And uh from this experience, I want to point you at some of the key characteristics or features that you should be looking for in your next provision tools. And lastly, I'll discuss some open questions with multi cloud that my team is still actively working on. So takeaways cloud agnostic abstractions prevents fragmentation and proliferation of identities, policies and tools, but it's not always possible proliferation right here means the fact that you have to use different accounts and and different user account and service accounts to access comparable services on different cloud. And it's even harder to manage policies because the IM boundaries and IM policies are, are totally different concepts and different API objects and the tools that you use to access those clouds are services or the client libraries are also different. So essentially you have the problem of recommendations where you're doing one thing for Azure and it's totally different things for Amazon and another different kind of set up for GCP. And that's just not scalable. And how do you assign different identities in different clouds that belongs to this essentially the same principles and governing the policies around that identity association. That's a challenge and, and cloud agnostic distractions definitely help in this case. But we will also discuss what are the cases that such abstractions is not possible yet. Secondly, declarative infrastructure is insufficient to solve life cycle management, invest in a tool that allows registration life cycle management right here refers to a cluster of virgin upgrades or stepping out additional clusters by some predefined configurations. Orchestration becomes a key right here. When we're operating at a scale of hundreds of clusters, invest in a provisioning tools that has the melting point that supports this complicated orchestration because your infrastructure might be integrated with application onboarding and deployments um as well as non cloud native infrastructure. And thirdly, your infrastructure pro commissioner is either your meta data store or orchestrated by a meditator store and the store must be quri we used to store this metadata within uh an internal wiki page or this metadata is scattered around the REMS across our Coates. Those are very hard to query and has been a number one headache in terms of implementing orchestrations where automation is on top of different sets of tools that provisions the infrastructure and apps. So make sure that your infrastructure provides the interface that allows them to be query and orchestrated or you define this metadata within your provision itself that exposed an API to make it query. So the Snowflake overview Snowflake presents itself as the data cloud that sits on top of the three biggest public cloud providers regardless of where our customer data sits. Snow provides one uniform execution platforms that unlocks all the data related functionalities such as data engineering, data, warehousing and data sharing and because the snow products are multi cloud by nature. So are our infrastructure like I alluded to earlier, our containment platform has experienced tremendous growth in the recent months. Currently, we are running 100 and 10 Busters and my team is still building a lot more because of the business need. All the clusters averaged about 3000 notes in total and that's about 60,000 containers because the cluster, all those scales, uh those are the average numbers. We built the container platforms on top of the managed offerings to reduce operational overhead for the control S. But we do a lot more customizations and also add-ons on the clusters to make them a container platforms that supports multi tendencies. All the clusters are original clusters or multi A Zs and is deployed around the world. The clusters are multi tenants. We support many different teams at Snowflake for their applications and then teams share the same clusters and oftentimes many apps share the same note, a multi tenancy has unlocked around $7 million savings in last year and we expect a lot more statements this year. And our continual platform is integrated with the legacy VM based infrastructure. Snowflake was found in 2012 and that's before Neti was available. So many of the infrastructure are still VM based. We have to integrate with the existing infrastructure to make sure there's network line assignment, there's private nest resolution. We're able to deliver the platform of this scale and scope because of the cloud native abstractions, we put a lot of thoughts into the subsystems that we use to reduce the customizations that we have to make for each individual clouds. We use Octa to reduce the proliferation of identity. Every users are assigned one Octa identity and assigned to several group membership. Each name space is printed. Access to exactly one group and Octa combined with teleport ensured that users will only use one teleport ci I to access all the different clusters and V MS on all different clouds. One lessons we learned from this project is that we should try as much as possible to push up the policies into cloud native components such as pushing up network policies and match external draft policies, authorization policies and uh routing rules, uh firewall rules or uh op a gatekeeper policies to further enhance multi tenancies we developed in house custom resource definitions that abstract away the provisioning of plot storage buckets and objects as well as K MS services by different clouds also for vault policies for different tenants. So uh each tenant running in the name space will have a dedicated sub pa on vault that they can use as the secret engine to store any kinds of secrets that they see fit. And lastly for logging and monitoring. We're relying on the core snowflake offering by itself kind of like dog food in our own products where we are streaming all the container logs to snowflakes using a product called snow pipe. Snowflake allows us to essentially write sequel to query our logs like I mentioned before. Pulumi has been a great fit for my team to provision the cloud resources because Pulumi enables automation tools and hence rapid. And for scale, we use gloomy micros stacks or multis stacks where we divided up the provisioning of each cluster into three separate chunks, the network compute and sequel and doing so drastically reduced. Pulumi preview time, which is sort of similar to terraform plan. Pulumi also makes cross stack references really easy. So all the dependencies among the stack can be properly captured the bloomy automation api is really powerful. There are at least four use cases that I've seen in our internal code leveraging this feature, I'll focus on covering the first two where we implemented blue green upgrades for rub not pools to minimize any kinds of disruptions as well as instant during the outputs. We also generate cloud specific trone manifests from Pulumi outputs and I'll explain why we decided to define trone manifest outside of polluting and how Pulumi still makes any kinds of custom to really easy. In addition to those two, we have implemented custom rollout strategies for Pulumi stacks, which is important because we have hundreds of clusters that we operate and we want to do some kind of coronary testing before we roll out this code changes to all the clusters. And lastly, we leverage Pulumi operator which is a sort of agent pool CS CV solutions so that we don't have to manually apply hundreds of stacks. The blue green upgrades for no pools, blueprint upgrades for no pools is very similar for blueprint upgrades for say any services where you provision a new version of the backend service. And then after you validate it, the new service is healthy and ready. We redirect all the traffic to the new version of the server and retire the old version. The blueprint upgrades for no pools allows fast reverts and there's no chance for stuck between different versions. The upgrade steps are creating new, no poles, coring and draining the old pools and delete the old no pools after workload has been migrated to the new pools and are running healthily. The problems with implementing blueprint upgrades is that manual upgrades on hundreds of clusters is just error prone. It doesn't scale, especially because we expect to build a lot more in the future. Moreover, we cannot rely on cloud providers auto upgrade feature because we have a really special T interest setup which is prompted by the product requirements that we must preserve the client source IP in every IP package combined with the fact that Azure doesn't have a cloud native low balancer where the the Azure low balancers is using the nose as the back end instead of the pods. So the traffic has to be routed to the nose and then it's IP tabled to the Ingres gateway pots. And we do value consistency across different clouds and we do want to have a consistent architecture across cloud. And therefore we arrived at a special architecture where we're running in in a dedicated that doesn't auto scale and we're running the is still gateway as a demon set pots. This kind of setup requires special coordinations during gluten upgrades because when the intel increase pots are shifted or migrated to new sets of nodes, the old steel nodes are still the back ends of the low balancer receiving client traffic. However, there's no more instill in pots on that node to handle such client traffic essentially, that means the low balancer is routing decline traffic into a black hole. And that's some kind of downtime that we cannot tolerate. Therefore, for the to pool upgrade, we kind of have to deregister the backing nodes from the low balancer and then cordon and drain the to gateway pods over to the new poles. We are able to automate the entire blue green upgrade procedures using the polluting automation API we built some custom tools around this API that allows us to edit and apply the polluting steps according to the upgrade steps that I just described. And we proceed one step at a time with some pre IPOD condition checks in between the steps to make sure that the steps are healthy and executed correctly. And unlike other infrastructures code systems, Pulumi requires no TSL it exposed the full fledged programming language distractions directly to the user which is so powerful when we're trying to integrate with additional custom tools and orchestration systems. The bottom line is that declarative infrastructure is insufficient to solve life cycle management. Invest in a tool that allows orchestration and automation and orchestration are so important to sustain at the scale that we operate. Another tool that we build around Pulumi is to solve the cloud specific COTIS manifests issue. Our application users need to customize their KTIS manifests to be able to run on multiple clusters or clouds. The reason is that the container image hosts with the low balancer labels with the pot identity annotations are usually different across cloud. The problem is that we are managing KTIS manifests outside of Pulumi. The reason is mostly because a most open source projects that we use only release an installation Gammel and it's nontrivial work to translate that to the polluting setup. And second, the cluster space almost always digress from infrastructure as code sets because of the dynamic nature of the cluster due to reasons like different controllers or a horizontal. And lastly, we run a multi tenant platform where we want our users to self manage their own Pernetti manifests. We don't want to be the bottleneck where we have to approve every configuration changes related to applications. But we also don't want to grant all the users equivalent access to gluing and our configuration platforms. Given the fact that we're building the cub that is manifested outside of polluting the cluster specific values are still stored in polluting because the the cloud resources and the cluster itself is provisioned by polluting. So we need to build a tool that allows us to generate those primi manifests customized given the cloud specific values. And that's why we built overlay manager, a YAML rendering engine. The overlay manager will read the Pulumi stack outputs using the API and generating the overlays that feeds into customs which renders the final this manifests that was applied by A CD in the cloud native community. We also saw alternative solution such as using the DS L doing so still needs the input data from front end framework to manage the recruitment that is configuration the infrastructure provisioning tool. Some of the examples of this DS L approach includes Opon or Q. The bottom line is that your infrastructure commissioner is either your mandated store or orchestrated by a mandated store where the store must be quri. In addition to Curtis and cloud resources, we also use Pulumi to provision and manage vault deployments. Vault or vault is a critical piece in our secret service and also private PK I, we use Pulumi to initialize and configure vault. For example, we use vault to issue and rotate the issue. And C A search for search manager and search manager will sign the TLS search used to terminate our private http S traffic. We also replicate sta secrets across deployments and regions using Pulumi to orchestrate this. And lastly, we enabled the cloud provider, secret engine so that clients or applications can obtain from vault short-lived tokens to talk to cloud providers instead of having to store long lived static tokens which is less secure. The tenant onboarding is outside of polo recall. Our platform is multi tenant. So we implemented this vault policy custom resource definition where the platform user can define this vault policy so that they can bind a list of vault paths to a specific group magnetic service account and their applications to just use such service account when interacting with the vault that's deployed in the cluster. An example of such policy is shown on the right hand side, my team has made some progress with multi cloud but some open questions remain. For example, applications still have to be cloud aware. They need to use cloud specific client libraries to interact with cloud services and requiring code changes. For each cloud providers, we want to support. For example, if the application needs to read a file from the block storage bucket or write to a message queue or pops up topic top identity that translates a service account into a cloud service account only solves the authorization and authentication problems. The CR DS that we described earlier only resolves the resource provisioning aspect. Hence, the interaction between the applications and the cloud providers remain cloud specific. Essentially, you have to write the same code many times and once for each cloud providers. And secondly, cloud agnostic abstractions often terminates tics cloud resources and policies that cannot be pushed up remains heterogeneous across clouds. One example is when we use certain manager and ACNE protocols to automatically renew our cluster public certificates that terminates the the public htdps traffic. In order to solve the ACME DNS 01 challenge, we have to make some DNS text record. So we want to reduce the cloud DNS permissions for search manager to only making text records. However, we could not do so on GCP at least because there's no record level permission control and the boundary is the entire GCP project. So essentially we have to configure the permissions and security boundary controls per cloud. And this is the end of my talk. Thank you so much for being with me for the past 20 minutes. And if you are also excited about multi cloud and distributed systems contained platforms and open source software, my team is hiring aggressively and please scan the QR code on the left and get in touch with us. Thank you so much.
---
