---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Cloud Engineering Summit 2020: Managing Your Application and Infrastructure in One CI/CD Pipeline"
title: "Cloud Engineering Summit 2020: Managing Your Application..."
meta_desc: |
    In recent times, we have seen infrastructure automation play a very important role in building and shipping world class applications fast. We have ...
url_slug: cloud-engineering-summit-2020-managing-your-application-infrastructure-one-cicd-pipeline
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Cloud Engineering Summit 2020: Managing Your Application and Infrastructure in One CI/CD Pipeline"
  description: |
    In recent times, we have seen infrastructure automation play a very important role in building and shipping world class applications fast. We have seen how tools like Docker, Ansible, Puppet & Terraform can be used to automate infrastructure deployments.  In this session, Adora Nwodo talks about the concepts of Infrastructure as code (IaC) and how you're able to treat your infrastructure deployment code the same way you treat your source code by being able to test, version and gracefully rollback your infrastructure deployment code.
  sortable_date: 2020-11-11T00:29:58Z
  youtube_url: https://www.youtube.com/embed/CRmX3G9NKMU
transcript: |
    Hello, my name is Adora and you are welcome to Pulumi Cloud Engineering Summit. I am very excited to be giving this talk today and in my talk, I would be taking you through how to manage your cloud applications and infrastructure deployment in one C IC pipeline. But before I go any further or dive into the main details of today's talk, I would want to quickly introduce myself. So as I said, at the beginning of the talk, my name is Adora and I am a software engineer at Microsoft mixed Reality. Um And I am a tech content creator as Adora Hack. I create a lot of youtube videos for developers and I write articles as well. I'm the co-founder of on stack, which is a community for developers to learn stuff hands on. So we organize meetups where we mostly do workshops as opposed to anything else. I'm also on the advisory board for Vrar Nigeria, which is the Nigerian chapter for the Vrar Global Association. And in a way, I guess this kind of makes sense because I am somebody that works in mixed reality and somebody that is really enthusiastic about extended reality and what we can do as people that live in this world with that technology. So before anything straight, you know, let's just go, let's just take a trip down memory lane, um seeing what's currently, you know, happening now and how I see has made a lot of things easier in terms of, you know, how we are able to manage our infrastructure. Sometimes we need to think back to where we came from to sort of appreciate where we currently are, you know, today and just looking at what it was in the past for people that were trying to do infrastructure deployment or just even somehow create infrastructure for what ever applications or services, whatever it is that they were trying to build in the past, it was a very tedious and error prone process and I explain why. So I go to a today and I choose to create a resource group, I choose to create an app service plan and then I go ahead and create a key as well. I go ahead and um create a static web app as well. I go ahead and create multiple resources that I need to bring my websites to life, right? And as I'm creating these resources, I'm documenting them somehow but maybe some somewhere in the middle of my entire devops process, I have a life size or something goes wrong and I have to quickly make some kind of configuration change to the particular environments that had the problem. But somehow I forgot to, for whatever reason, documents that change or anything like that. And now the state of the environments that I made that quick fix in and all my other environments will be different. And if I want to now create an entirely new environment, I will be creating of the knowledge that I already have of the thing that was probably documented that if it was actually even documented at all, and it's very difficult to maintain states across, you know, your different environments when you're trying to do deployment in steps. So you can, so if you have like a development environment, you have a staging environment and you have a production environment, you can't confidently say that your staging environment or mirrors your production environment or vice versa because in that moment, you're not sure anymore because of individual tweaks you've made here and they just to get something to work and you weren't maybe for some reason able to document or skipped your mind or you just wasn't even one of those things, right? Isc gives us, you know, version control ISC allows us to deploy our things incrementally. And because talking about Pulumi, it gives us a way to actually apply a setting design pattern to whatever infrastructure definition thing we want to do. Because with Pulumi, you're going to be using regular programming languages and then you can decide, OK, I want to create for different regions. I want it to be represented in this particular way. So as I'm going to be designing my cloud application, as I'm going to be designing my service, as I'm going to be designing that app, I can also be thinking about ways to actually also design my infrastructure code thing if that makes sense. And I, like I said, I think Pulumi is amazing because it gives us the ability to create our infrastructure with familiar programming languages. And you can see this storage account over here. So this is Pulumi with type scripts. And during the course of this whole talk, I will be using typescripts as a reference. But with Pulumi, you can actually use a bunch of other programming languages. You can use C# you can use Python, you can use dot net and so many more amazing programming languages. So in this particular slide, we can see the typescript definition of a storage account. So I want to use Pulumi to create a storage account with, I want to use Pulumi typescript to create a storage account resource. And this is how I go ahead to unit do that. Now that I've given an overview on what Pulumi is and what Pulumi can sort of like do for us. I try not to go too deep into that because that's not what this talk is really focused on. But now I've given a brief overview on that. I am going straight into the next part of this talk which is integrating Pulumi as part of our deployment process. And there are two scenarios. So I'm going to be stating each scenario and possible implementations for those scenarios. So the first scenario is you know, separating infrastructure deployment from our social school deployment. So for whatever reason, and this is not what this talk is focused on because like I said at the beginning of this talk, this talk is focused on being able to deploy our cloud applications and our infrastructure side by side in one C I CD pipeline. So this is a valid scenario for integrating Pulumi as part of our deployment process. And I just want to touch on you before I move on to the next thing which is the scenario that we actually care about in this context. So the first scenario is separating infrastructure deployment from our source code deployment. And there are basically two ways to do that and you might want to do this thing for whatever reason at all. The first way is having multiple reports. And then you could have like one report for where all your infrastructure code would be. And then you could have another report for where all your application source code would be. Basically the second scenario is having your source and your infrastructure code in the same report, but having multiple pipelines for those things. And depending on whatever conditions you set the multiple pipelines will get triggered on different occasions. So it could be that you only want to trigger the pipeline that does the infrastructure deployment. When you actually edit code in the infrastructure directory. Every other time you want to run the pipeline that does the source deployment or you can decide however whatever condition that would make you want to have multiple pipelines and trigger them on, on different locations. This is also a second scenario where you can, you know, separate your infrastructure deployment from your source code deployment. And then the second scenario, which is the one we are interested in in today's talk is deploying infrastructure and source code changes simultaneously. Now, in this scenario, there are two ways to implement it. So the first way to implement this is by deploying your infrastructure with Pulumi tasks and your source code with some custom YA templates that you can write yourself. The second scenario would be deploying your infrastructure and your source code with custom Pulumi templates. So we're going to talk about using Pulumi tasks in an Azure pipeline and you can do well, you can do most of all these things regardless of whatever tool that you are using, right. So if you are using github, for example, if you are using Azure devos, for example, if you're using anything at all, if you're using circle ci I, you can do all these things, you can do all these things with Pulumi as well. But for this talk, I'm basically talking about Azure because that's what I'm more familiar with. So using Pulumi task and Azure pipeline, um Pulumi tasks would help you, you know, handle all the things that you need to do before you actually run the Pulumi command. So all the setting up installing of the Pulumi cli and all the things that you need and then all you need to do basically is call, is use that Pulumi task and specify the command you want to call along with other important things like your Pulumi access to kin for authentication. So we can see these two codes depend side by side. One is code for defining a function app resource in Pulumi using typescript. And the other is using Pulumi tasks. What we would actually need to write to be able to run these Pulumi thing in Azure pipelines. So as we can see, we have a function app and we've given it the name, my function app, we have specified the app service plan, the location, our resource group and the things that we need in this function app resource, if we want to deploy this function app resource to some Azure subscription, so that we can, you know, actually deploy an Azure function there. And we can run the code and all of that, we will be writing some ya and we'll be writing some Pulumi tasks. So I have two Pulumi tasks here because I want to run two different Pulumi commands. So I've created a Pulumi task that does a preview for me. A preview on all my resources is just to be able to compare the current Pulumi State with what I want to do to decide. OK, how many things do I want to update? How many things do I want to create? How many things am I deleting and what is actually going to get replaced just to identify how the state is going to be different. So I just want to be able to see what it looks like. And if it's all good, then go ahead and run a Pulumi up and Pulumi up is actually what upgrade my Pulumi state to what I have currently specified that I want my new state to be in. So if I had do a stuff running before and I don't feel like using do anymore and I want to switch to a serverless architecture, I can remove all the do things and then switch to using a function app in an app service plan and have all those things going for me. So Pulumi compares that state and does all of that for me. So I would do a Pulumi preview and do a Pulumi up. However, if you look at these scripts properly, all that happens here is the infrastructure updates. It doesn't in any way actually update my source code. And when I started this talk, I talked about deploying our infrastructure and source code side by side in one C IC pipeline. So this is not what we need. However, this next thing is closer to what we need, which is after running my Pulumi preview and my Pulumi up, I can go ahead to run a custom YA template that goes to deploy my function to my new Pulumi resource in Azure for me. And as we can see here, that's what's currently happening on the last line. And as we can see here, the names of the function apps are the same. So the function app name in my code is the same name in the pipeline. So that when I say, OK, I'm creating this template to go and deploy this function. For me, it goes to deploy the function to this particular functions resource to this particular function app. So alright, this is the first implementation for our scenario that I talked about initially, which is deploying our Infra with Pulumi tasks and deploying our soft with custom templates. Now there's a second way to actually do this, which is the way that I prefer. The second way to do this is using custom Pulumi scripts in an Azure pipeline. So as opposed to using the Pulumi tasks themselves, you can customize things to how you know you want them to be. And now let's take a look at how that works. I'm going to be talking about this in the context of a function app. But if you are doing do and you're doing do a containers. This also applies as well. But I'm going to be using, I'm going to be saying this in the context of a function app because I feel it's a lot faster to get by. So Pulumi has something called an archive function app that allows you deploy a function archive alongside the function app, Azure resource when you are running Pulumi up. So as opposed to just creating an Azure function app, creating that resource, if you use an archive function app, and you specify the path to a deployment archive to an actual function, it will also deploy that function for you in one step. So you don't have to do too much. So what this means that in like unlike the previous scenario, our Infra and our source code gets deployed in one step in one task at once, you don't have to actually do two things. You don't have to create a Pulumi task and then go ahead to call a custom template that does that all these things could be done in one step. So here I have my code for an archive function app. We can see that um I it's a little bit different from what I had before with just the um normal function app resource because now I am adding something called a deployment archive. I want to specify the path to the actual Azure function that I want Pulumi to help me deploy it to my Azure function app resource I have, I want to have built that function and I want to have a path to that function and I want to pass that path to Pulumi so that Pulumi can help me deploy whatever is in that path to my Azure function app. That's just basically what it is. And for me to go even further, I want to show you two different files and I want to show you why these two different files are important. So we have the Pulumi config. So depending on how many Pulumi stacks you have, you would have multiple config. So now I have a stack, I call it the test stack. And your config are you can use your config to specify things that you want to be different across your different stacks across your different environment. It could be that OK. You want your, for example, the location, that's one thing that we can use. In this case, let's say, OK, you want your test stack to be deployed to West Europe, you want your staging to be deployed to like a West US two and then you want your production to be deployed to like a France central. In that kind of scenario, it's always easy to specify those details that are stack related, that are environments related in your Pulumi stack. And because of that I have chosen because even in the pipeline, I will be able to update my Pulumi stack config by running this command. Pulumi config sets whatever the config name is and the config value I will be able to perform these updates in the pipeline. And I'm trying to run away from scenarios where I have to had code a deployment path. Because what if things change? And for whatever reason my function app does not build to that specific path anymore that I deploy something empty to my function app. And I think that my function app is there when it's actually not there. So I want to be able to automate this whole process from the beginning to the end, I don't have to have code at all. So we're going to be paying attention to the Pulumi conflict to the Pulumi conflict. And we're also going to be paying attention to the command that will help us set our archive path. If we go back to the source code, we can see that we have created an instance of the Pulumi conflict so that we have access. So that's in the code and we can now get config values from our config. So in this case, in the code, I will be able to get deployment archive, config values and I can do whatever I want with it. So that means that when I set the value for my function deployment archive in the pipeline, and I run a Pulumi up and Pulumi is going through my code and doing all of all the things that it does to deploy infrastructure for me. What's going to happen is and because I ran that command, my config got updated and when Pulumi gets to my code and sees that it requires the deployment archive config value for my config, it goes to fetch that. And because it's already there, it fetches that path, puts that path in my archive function app. And the web plum is helping me create that archive function app. It creates it, it fetches the built function from the path that I've specified from my archive. And it goes ahead to deploy whatever is in that path to my function app itself sounds amazing, right? So when we run the command, as we can see already the the configure set as we can see this. Now, let's get to Azure pipelines. So this is what the pipeline would look like. Instead of running a ploy task, I'm going to be running these scripts and I've broken the script down into two different shell scripts. So I have a script to do set just in case I want to do the same set up somewhere else so that I follow the programming rules that say um don't repeat yourself. And I've broken these scripts down into two things. One that actually does all the setting up and the other one that does the Pulumi cli related things for me. And like I said, initially, depending on where your Pulumi, you can decide to be using Pulumi cloud. And if you're using Pulumi cloud, then you'd have to pass on your access token to do authentication. But if you are using your own cloud, like you have your own storage account and your own storage blob, you need to pass in like your arm client secret, your subscription ID, your arm client id, and your arm tenant ID. Because this thing today that I'm talking about in the pipeline currently works with service principal authentication. So you need service principal authentication to do what I'm saying that Pulumi can do for you in the pipeline today. So let's look at our script for setting up. So what we're going to be doing is downloading Pulumi logging into Pulumi and downloading new Js for our setup. So when it's time to run the Pulumi Cli script, then it's important to add the Pulumi the path to the Pulumi executable to our path environment variable. It's very important. So when we try to run the Pulumi command, you can pick it up and run. So the first thing we want to do is to switch to our Pulumi path, the path where our Pulumi project is and in this case, it is the in Infra path. So I'm going to switch to Infra, right? And then after doing that, I want to install M PM and I want to build my Pulumi typescript project. If that is necessary. Once I'm done doing that, I want to select my stack that I'm in. And in this case, I'm using a test stack. So I go ahead and I run Pulumi stack select test. And after doing that, I can set my deployment archive config value, I go ahead and I set that config value to the archive path that I had already built. You know, because initially I talked about this before we get to the Pulumi path, there will be a chance that the function that we actually have, we would have built, it would have tested it. We would have published artifacts, we would have done all of that. So we published the artifacts with a particular path. And that is the path that we want because once we specify that path to Pulumi, Pulumi goes to deploy and that path to our function. So I'm going to do a Pulumi config set deployment archive and I'm going to put that path right there and I'm passing it into this script, right? I'm passing the path into this script so that it's dynamic and I don't have to hard code this path at any time. And after doing this, I also run a Pulumi config get just in case for whatever reason, my path wasn't set so that it feels early on. And I know just so that I don't go through that whole process of trying to run the Pulumi up and then it doesn't deploy anything. And I go to my app to my function app. And I see that my function is empty and I wonder why for a few hours, I don't want to get into that debugging rabbit hole. So, and I just want to put this out there just to be sure that it actually sets before I move on. And after I have done the important things, which is after I have set up after I have switched my stack and after I have set my deployment archive, I can go ahead and just run my Pulumi up. And what's going to happen is Pulumi is going to create my Azure function app resource for me. Pulumi is going to deploy the code in the path that I specified to the Azure function app for me and I did not have to do it in more than one step. So on that note, we've seen how we can be able to use Pulumi to deploy both our infrastructure and our source code in one step. And like I said earlier on this works beyond functions, right? I talked about the archive function now because it's a lot easier, but I've also done this with do as well. So I know for a fact that this actually works. All you need to do is update the container registry and and when you Pulumi or Pulumi goes ahead to redeploy the thing for you. So in this case where we were updating our deployment archive path for functions, if you are doing some kind of do a or coti related things, you would probably need to update your container registry as well. And it's the same effect. It goes ahead to redeploy, it checks the current state and if there's any change at all, it redeploys the thing for you. So now you might be wondering if Pulumi is able to do this for me? Me, what happens next time when I did not make any changes to my infrastructure, but I have updated my code and because I have updated my code, I want to obviously deploy the updated code to Pulumi. Like I said, states, the new pass in your archive function app is not going to be the same as the pass that you had before because once you do like ac slash archive slash path two slash at least something will be different even if it's just the build ID of the function. And because of that Pulumi takes that up and goes ahead to redeploy that function to that function app for you every time. So because the state is different from when you did it yesterday at 4 p.m. and now that you want to do it again today at 2 p.m. Pulumi says that the current states and the new proposed states are not the same because the path to the archives are not the same, right? So Pulumi goes ahead to redeploy that function on your behalf and Pulumi does that every time So you, so you would it will never be the case of because you did not update your infrastructure code. You are not going to get your updated source code. So far as every time you run the pipeline, you build the code. If that happens, then Pulumi would always help you redeploy that built code to your function or to the container or whatever it is that you need, depending on how many times you do it. So, on this note, I, like I said earlier, we can now use Pulumi to deploy our Infra and our source code in one step. And that makes me really excited. Hi, Ted. Thank you so much for sticking around and watching my talk. Um, like I said, I'm, I'm really honored to be giving this talk and I'm glad that I gave this talk and on that note. Thank you and bye.
---
