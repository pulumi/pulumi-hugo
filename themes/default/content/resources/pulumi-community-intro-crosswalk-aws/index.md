---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Pulumi Community - Intro to Crosswalk for AWS"
title: "Pulumi Community - Intro to Crosswalk for AWS"
meta_desc: |
    Meet the team behind Pulumi Crosswalk for AWS, see some of what it can do across AWS ECS, EKS, Lambda, and other AWS workloads, and hear from partn...
url_slug: pulumi-community-intro-crosswalk-aws
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Pulumi Community - Intro to Crosswalk for AWS"
  description: |
    Meet the team behind Pulumi Crosswalk for AWS, see some of what it can do across AWS ECS, EKS, Lambda, and other AWS workloads, and hear from partners Tableau and AWS on how they are using EKS to get Kubernetes running in AWS.  For more information about Pulumi Crosswalk for AWS, check out:  - Blog: https://blog.pulumi.com/introducing-pulumi-crosswalk-for-aws-the-easiest-way-to-aws - Press release: https://info.pulumi.com/press-release/pulumi-crosswalk-for-aws-accelerates-delivery-of-well-architected-infrastructure-as-code - Documentation and getting started guide: https://pulumi.io/crosswalk/aws
  sortable_date: 2019-06-14T19:35:36Z
  youtube_url: https://www.youtube.com/embed/PQNfLqUHu64
transcript: |
    All right. I think we finally get this thing up and running. Um So thanks for joining everybody. Um This is a community call to introduce uh some of the cool stuff that we just launched earlier this week um to help you program Aws. Uh So something called uh Fluy Crosswalk for Aws, which is, uh our CEO is gonna walk through what that is uh on the call. We're gonna do some fun demos to see, you know, all the way from containers to, to server. Um And you know, some, some, some exciting things you can do with crosswalk. Um We've also got some guests here. Um, our friend Trevor from Aws, uh, and, er, from Tableau is gonna talk through sort of how they've been able to use crosswalk to, uh, go into production with in Amazon. Um So with that, I'm gonna hand it over to Luke. Uh Luke is gonna walk through a lot of the more exciting sort of tech details, uh and then sort of uh em see the whole, the whole call but, uh definitely looking forward to hear what people think and we'll have a quick Q and A at the very end. So, thanks. Take it away, Luke. Cool. Yeah, so thanks everyone for kind of joining us. Um So, yeah, this week we, uh, you know, kind of announced Bloomy Crosswalk for Aws. Um And I wanted to talk about kind of what Bloomy crosswalk for Aws is, uh, in the context of kind of Pulumi is that that many folks um who might join this call probably or using bloomy and using pieces of, of what is part of the crosswalk and they work. So a real kind of goal with bloomy uh crosswalk for AD BS was to provide kind of the easiest way to use the A BS platform. Um And so I think that sort of uh sort of is a few different pieces. One is, you know, we really want to build on top of kind of the reliable infrastructures code platform that kind of Pulumi offers and that's, you know, using real program languages, having sort of software engineering practices you can apply to your infrastructure uh and really going beyond that and sort of building uh reusable abstractions uh that you can use within your organization uh for your infrastructure so that you can avoid copy pasting uh and can really be more productive uh with whatever platform you're working with. But on top of Aws in particular, you know, we, we've had many of the users and customers of Pulumi are using aws and one of the things we really want to enable for them is sort of two key things that the crosswalk brands, one is building on top of best practices. And so we want to take sort of the common best practices, infrastructure patterns across a lot of different parts of the Aws platform, make those really accessible built in. You don't have to re invent that stuff. You don't have to rediscover it every time you go and do a new project instead, you know, you can use things like a VPC and get all the best practices for vpc's built in with just one line of code and then customize only when you need to. Similarly, if you're working with, you know, E CS or fargate, easily get the best practices for how to set those up, how to connect with load balancers, all that sort of thing, but make it really easy to get started and that sort of easy to get started is really the last piece which is we really want to make it easier than it's ever been to work with all these primitives of the database platform. And so really taking it from just having all the building blocks available, which Aws provides and has always been part of kind of what offers to making it really easy. So things which used to take weeks maybe now take hours. Um and, and that lets you know, you be much more productive in how you kind of build applications uh for AWS uh and get them sort of in their iteration and ultimately into production. Um And so we've built this kind of support across a variety of different parts of the A S platform. And we're really just getting started here. We, we see this over time expanding uh to cover many different parts of, of the platform, but to begin with, we kind of focused in on a few areas. So uh one of those is serves, um you know, obviously there's a lot of great services primitives uh in the A S platform, things like Lamb and API gateway, but then tons and tons of other event sources uh for folks who have been using Pulumi with and serves for a while. You're already familiar with some of the things we're doing here. Uh But we really have provided sort of one of the easiest ways to sort of just take a piece of infrastructure, hook up an event handler and take advantage of sort of server this code within your infrastructure as part of Pulumi and as part of cross, we've done a similar thing with sort of containers and on top of EC and far again, great building services for kind of container workloads on Aws. Trying to make those just so much easier to use, make it so that you can go from zero to having a production sort of ready deployment of your containers in just a few minutes. Uh instead of taking you know, most of the day or, or, or longer. Um And then that they build on top of those best practices so that you can continue to evolve your application to get that. Um And then the third sort of big area is, uh is Eks and Ktis. And of course, Pulumi has had great support for Ktis for, for a while. Um We more recently added really good support for EK and as part of crosswalk, we're taking that even further and making that part of the sort of whole ecosystem of these these higher level abstractions. And that again lets you take best practices set up of EK, take that from something which you have to read 30 pages of documentation on turn into something which is sort of one line of code to get started and get up and running and so kind of throughout the rest of this call. I wanted to spend some time demoing a few of these different areas of crosswalk, giving a sense of how you can use these to sort of accelerate the way that you're building applications, whether it's for serverless or for Ktis or for some of the other areas that the crosswalk covers going forward. Of course, this is just the beginning. We, we are going to be covering lots more areas of the platform uh over time. Uh We already do some things to make I am better. We have a lot more in, in, in our plans for the future. We do some things to make cloudwatch simpler. We have a lot more in our plans for that. Um And generally, we're looking at every part of the A US platform and how can we make that even easier? So we're really excited to get feedback from folks as they start using crosswalk to give us guidance on sort of where we can uh take this uh concept even further. And of course, for the folks who aren't using AWS, although our focus, you know, with Cross A S is obviously on the A DS platform, we are looking at taking this pattern to other clouds in the future as well. Um And so for folks who are working with those platforms who see things they like here, you know, definitely give us the feedback about where you'd like to see those same patterns applied on AWS, on GCP on, on any of the other platforms that you're working with. Uh today. Uh So that's sort of a high level overview. I think we'll, we'll, I have some questions at the end, but I do want to take some time to give uh give some of the folks on the team a chance to kind of demo a few of these areas. Um And so the first one, I thought it would be good to demo is sort of eks and some of the work we're doing with. Um And to do do that, I'm gonna hand it over to, to Mike Metro, who's one of the engineers on the team who's done a lot of the great work on uh on that EKS provider uh for Pulumi. So Mike uh take it away. Thanks, Luke. Let me go ahead and share my screen and we can get started. All right, can everyone see my screen? Yep. Awesome. Great. So to introduce uh the EKS package, as Luke was saying a lot of the same functionality that, that you uh may have worked with or, or may have heard of with regards to the crosswalk around Aws and Aws X um has really moved up the stack in two and that's what we have here in the EPS package. It is a, a simple way in Pulumi to encode define how you want to provision your plus uh on Eks and how you want to actually go and set those up into production. Um Mind you, this is also a separate package from our package. Uh um If you're not familiar with it, this is ultimately what allows you to deploy workloads into an existing. So if the EKF repository is how you manage your clusters with the package is how you actually deploy resources from the API into those. Yes. Um Picture one of the cool things we can do is we can leverage um our package banners in this case. No, but to, to facilitate uh how we get these packages. And so Uh In this case, I'm using N PM and it's pretty simple because to get started with, it's really just a couple of lines of code. So uh in this definition, uh all I'm going to do is create a new cluster. Uh that specifies that, hey, I'm going to be leveraging the EKS package from. And in that, I'm going to find a new resource called cluster and I have to give it an A my cluster because we take the management aspect of it away from you as far as instantiating managed control plan in communities on a w the cool thing about using general purpose languages is now we can access properties of these resources just like we do with other applications. And so this is no different and this is how we actually manage to configure ourselves to extract the Q config file from cluster. But as you can see to spit up an EP cluster, it's just freelance this code. So as soon as I spin this up, I took the little of actually spin this up for us. But if I were to do me up, you'll see that um the updates here I put in. So no matter how many times I run this update, it will continuously give me the same state that I expect. And that is that the cluster is up and running and I didn't make any changes. So I my my next update. Sure enough, it'll tell me I have no resources were available to update. So I'm not going to do anything. This is a no. And because I can export my C config for my cluster, this allows me to share these properties into very easily. So I have an output called Q config one. And the way I access my cluster in is no different than setting up my Q. But so I have a command here in ping, there's this notion of operating insects and outputs. Uh In this case, I created the Q config output as you saw in that pre designer code. Once I pull that output out of pluming, let's actually look at that output. You can export many different variables here. In this case, I have the Q config file. So sure enough, I'm going to export that file that, that structure into a file Q got based on, I'm going to export it just how Q control expects me to use it. And then I'm going to leverage Q control just like I know and love from working with core. And sure enough, I have my two node cluster up and running. And again, this is just in three lines of code. It's really that simple. So if you're not looking for any being too scripted, if you know, you just want to test this, this is great. Uh I keep control just like I already did, right? I have pads, I can inspect those pods, I can describe uh my workloads accordingly. Uh If I check out the AWS node, I may not have any logs here. But nevertheless, I can still go and inspect it just like I'm still looking at and that's pretty much all there is to it. So the simple case is great. And by default with the cluster, we deploy a dashboard, uh the dashboard should be specific. So let's show you what that's like, I'm going to set up a Q control proxy on my end on my local machine that will allow me to get into dashboard with Pulumi, you also have a dashboard to control all the resources. So in this cluster, my cluster, I can see the notion of my staff, I can see all the variables that I have been exported. In this. In this case, my file don't worry, I'm not flashing anything too sensitive. This is at the end of the day, leveraging the AWS C on my client as well as the AWS file that data from my client. Pulumi doesn't see it in my secrets. It doesn't see it in my cloud credentials, doesn't see any of the the vital information that's important to me. And at the end of the day with here, it's just going to ultimately depend on the aws I authenticator to authenticate me against the cluster. So I'm not exposing anything too sensitive here, which is great security. First practices are, are always something and we try to. So as I, I worked in my stack, I can create many different updates and you'll see that on this dashboard, you can share this dashboard with your teams. You can expect what changes actually went into each of these updates and changes will propagate. Here. In this case, I have no changes, but I can check out my Dis Los and see the actual uh the actual JSON spec that's being spit out and I can even go and see all of the resources that I created in this cluster transparently. So look at all these resources, there's, there's tens of them, there's dozens of them. And I only specified again, three lines of code which is pretty great. It allows me to, to leverage that to the best of my ability without any need the complexity and that's really what crosswalk has ended up solving. Similarly, I can see my resources in a nice little graph view so you can map around and and see how the dependency tree works. With regards to the plugs, I can inspect each of these right. I can go into these resources and see their properties and even see more information if I want on their details. So to show you the dashboard of the cluster, I just spun up, I'm going to actually show you the resources. So I spun up the dashboard which is by default enabled in this cluster. It's just hidden behind the abstraction of like cluster resources and if I have to keep proxy running, I can now hit the actual dashboard service. So let's go ahead and do that. Now, in on our dashboard, we actually expose links to all the resources in an accessible way for your copywriters as well as and this, it, it just depends um being set up. So I into the dashboard. And sure enough, I can see all of my my vitals as, as I need them, I can see an overview of my cluster and I can see the nodes, how many different workloads I have their statuses, their age. I can look at their logs and I'm off to the races. This is pretty great. Now, this is a simple case, right? More often than not a three liner is great, not only for demos and testing and for for ephemeral workloads, but sometimes you want to be configuring truly production ready systems. So given the power of crosswalk, we can simplify a lot of the, the, the nitty gritty. But if you really care, I'm configuring uh all of those details. We sure enough, expose those those abilities for you. So I'm gonna show you a more advanced case. So I just switched tabs. I just went uh to this current tab right here at high terminal. And in this, I'm gonna be a little bit more specific about how I actually go and specify that. So if you notice first things first, I'm gonna define a B PC using the AWS X library. If you noticed in my previous example, in the simple, I didn't even expose a VPC. The VPC is actually one of the things that's abstracted by the definition of this poster if I don't provide one. So off to the races with a WX has already kind of eliminated a lot of that set up for me. But in the case that I want to have more control and more more configuration, I can certainly go ahead and do so because we expose all of these libraries in code, I can leverage the same bells and whistles and, and tools that I'm used to working with as a developer such as my ID auto completion link checking, type checking and, and all of the abilities that allowed me to be a better developer. I've been programmatically stripping out. So in my VPC, I can go off and do things like, hey, you can immediately see my Lenor saying, hey, what is this? And so if I, if I look, it will actually say that there's no value set up on, on the property. So I actually probably set something up but can already see that I can set up my Cider block and I can go ahead and set that up. If I want to be specific about what Cider I want to use, I can be specific about some defaults. In this case, we set these, that's true for you. But if you wanted to, for whatever reason, be specific here, I can go ahead and do that as well for DNS support and the data associates. And you could even go and inspect all these definitions and see the, see the actual documentation here in code. So this is, this is a huge advantage as I'm building out my infrastructure, I can see what properties are available to me, how they're configurable if they're read only what the type of them is. And I can actually use that to my advantage to script the parts that are important to me. So as you can see here, I can create a new VPC. And in this VPC, I specified those properties similarly, I can leverage aws X and the AWS package as well to create I AM around roles and instance profiles that allow me to leverage the I AM properties for my cluster. If you notice that I'm using a, a local class that I created for myself. And this is one of the benefits of using colonial with real general purpose languages, I can leverage abstractions in classes and functions just like I would anything else to ultimately create abstractions that make sense to me. So in this case, I said I wanted to create a facility to create a role very simply. And in this case, because s requires that I give these falling three properties for a node to be a part of A, I can go off and script that and attach each of these managed policies listed here to a new role that I created in the aws I package. So this is great because I can configure my BPC to, to my specificity, I can create roles in this profile. And now I can be more, more fine grained about how I want to configure my cluster. And then you can already see some of the advantages that that either not specifying these information gets you as far as simplicity. But you can already see the full breadth of what we can support in the ETS package. So I can specify the BBC ID that I just created here. And something that I'm going to go into, I can set my desired capacity for the auto scaling group that will ultimately back this cluster. I can do a deployment of the dashboard. In this case, I'm gonna set, I can set up uh cloud watch logs for my control plane, uh different functionality from the API the the authenticator and for more enterprises function, we've heard a lot of our users say, hey, we would love to tag all of the features and sources, sorry, tag on all the resources that I have under management. And sure enough, we have been rolling that out. Thanks to our great community that been who've been contributing both in feedback to us in our Slack community channel, which we highly encourage everyone to join if you haven't already as well as opening issues for us. And even some folks are even taking some pr so we're seeing some great traction, not just from the, from the staff, but also really from the community engaging and wanting this to be this package flourish. So with that said, right, I can assign tags that make sense to me. I can for the resources that the support tagging, I can do a little more quiet and brain control in this place, I start finding tags for my security groups and I can even do things where in this case, I'm just finding the cluster by definition. This will create a default note group for me. But I wanted to create an additional note group. In this case, a spot instance I can certainly do so I can, I can use the package and the node group class to anti go through at the API a new node group that I'll attach to this cluster I defined up here. I specify the instance type to spot pricing. I can, I could add some labels and some paint so I could critized pod workloads and the pod specs that go into that by targeting these particular nodes. If I know my my pod should be running on spot instances. And again, we expose more tags that are valuable to users and to and to really in effect to really get into production such as if you've ever worked for the cluster autos scale. Learn cnet's, you, you have to script some some tagging on the proper ass. So Cabernet's discovery mechanism works in this case because we create a new cluster. We gave it the name of example, not group spot. The cool thing about ploy in this case is that we have auto naming on resources by default, that will attend a random suffix to each other the resources. So you can run these multiple times and create workloads if that's something you want to do. But because of the dynamic naming aspect, we can't have lean into it until the cluster script set up. But through leveraging real languages and even leveraging lambda functions through typescript. In this, in this case, I can take the property name of this cluster cluster two dot co cluster name and I can do a lambda function on that where I can leverage the cluster name and it's dynamic rent time whatever that value is. And I can use that in the tag as the cluster scalar add on expects me to. So with that said I can also export the cup and fit file of that cluster. I had already gone and done the liberty of of running the clusters for us in this case. So just like in the simple cluster, I can see I have various uh I have various clusters here that allow me to expose the resource I just described, I can look at all the pods that are running across this and I can deploy the same workload um that I, I didn't get a chance to do the simple one. But in this case, that really highlights the con the concert of all of the packages truly at work. So I've leveraged the AWS package, the A W FX package and the EKS package to create my clusters and all the dependencies it has from an perspective. And that's got the pick of the liberty of standing it up. And now I'm going to actually deploy a real workload in this case, an engine X deployment and then load type service into that cluster number two. So if you've ever worked with tunes, we expose the API spec of all of their objects exactly as you expect them, we don't create a new API resource model. We don't force you to learn a new spec if you've ever worked with deployment, this looks identical to what you expect it to do. So, so in engine, I will give it my metadata with some labels. I repli accounts. I will then specify the name, the image and then expose the reports and some early for the service that will front this deployment. I'm going to say here's my metadata, here's my spec around the load balancer and I'm going to target the the next labels that I used previously. And sure enough, you can see that in this, in this line right here in this definition. I'm saying my provider is in fact, this cluster. So off the gates, you can see how, how we can script workloads to target particular clusters that don't have to be the same cluster. Every cluster has a innes and particularly in bloomy, how we expose communities for us. We don't hear if C is running on cloud number one, cloud, number two or cloud number three at the end of the day, that's just going to the dependent of keep fig file. And this provider is essentially just a wrapper around the keep and fig file. So if this pus on AWS, if it's running on GP, if it's running on APF or if it's something that you manage yourself in an on prime situation, this is no different. So we can target our workloads to, to use that particular Buster and then I can leverage the, the, the benefits I have again with how we expose the resources and the properties to say, hey, once this service is up, look at it, slow down your address and give me the host name so I can get the service that gets created. So with that change that actually runs that update with Pulumi, you can also see a bit more richer dips if I pass in the dash dash di lag. And so you'll see what actually is going to change in specific as I do this update. So this will take a second or two to kick off as the, as the deployment runs. But because we leverage client go to work with the API server, we can have the ability to give you information as it is prevail. So if you never keep control, you don't have to use two control to do Q control. Get Q control. Describe look at logs, we automatically bubble up all that information for you as it's happening. And sure enough in a matter of seconds to be specific, we are able to deploy this workload into the buster that we just set up. So I will hit this URL and it'll take a second or two because the writers always take a minute or two for the low balancers to respond to you. But if I look in this example, I can really see that I can not only, you know, play with pcs and with I AM roles from the Busters, but in Cabernet's, I now have the ability to use the ID to, to improve the officership experience around. I think how we're scripting this, this actual resource I can go and chase down the spec here that actually maps to, to the resource that we work with the interface that was essentially exposed around the raw API. And this is great because we don't create new API models. We don't force you to learn a new, a new API subsystem we expose as you expect it to. So let me try to get this URL one more time, give it another minute or two. Let me try cash. I just please come out. So I'm going to curl my Pulumi output Pulumi output because it's the, I can say grab that variable and let's hit it with the curl and sure enough and genetic response. So this is just some of the great stuff we can do with, with Aws, with Eks and really with, with all of the packages we make available with crosswalk. We highly encourage you to check it out, open up any issues for any feedback that, that we can improve on and let us know how we're doing on our Slack community channel. Thanks. I'll turn it over back to you, Luke. Great. Yeah, thanks a lot, Mike. So I think, you know, Mike piloted a ton of great stuff, you know, with, with Eks support and generally with uh you know, with KTIS. You know, one of the things when I sort of summarize everything that Mike showed there really is, you know, if you want to do infrastructure as code for EK, in particular, Pulumi is really sort of the only way today to do that to really describe the full set up of your, your EK cluster, your VPC S and your, the resources you have to put in there to make successful. Uh And so, you know, uh Pulumi really was to bring a robust infrastructure code to uh communities uh and to EK in particular uh and, and make sure to a whole bunch of details of that. So um I definitely wanna cover a few other areas as well of, of what we're doing. And so uh I'd like to hand it over to, to, to talk a little bit about uh some of the things we're doing uh in, in some of the other areas of, of a s so uh go for it. Yeah, sure. Let me just make sure I can share my screen and let's see if that comes up. OK. So I'm going to take a little different take than what Mike did. So where the previous thing really kind of dove deep into Kubernetes and you know that whole entire area, I'm going to actually do this more for people who may not necessarily be familiar with Pulumi and are getting started and kind of want to see, you know, what value it provides. And I'm going to do that by using a real world app I built that takes a image of Aws, including the Lambda and API gateway space and kind of shows how we can use all of the breadth of Aws and all of the resources it provides while also making life easier with higher level abstractions. So for people who are already familiar with Pulumi, some of this may be rehashing, but hopefully you've also learned something new and for people who don't know it, maybe this will kind of motivate you to kind of dip your feet into this space. So the example I'm doing is something I wrote during one of our recent hackathons, I basically created a little slack bot that would tell me about mentions of my name so that I could go back after the fact and kind of see what was going on just to give you an idea about what that looks like. Here's a little example of the channel that I have with the little bot called mentioned bo and it just gives me a way to go back in time and be like, oh yeah, you know, I was mentioned over here, let me go back and make sure I've taken care of everything there. We get a ton of messages every day. So this just helps me keep things organized. Also, I should say this is an example that we had in our samples repo. So if you're interested in trying this out, you can actually just go over there, uh sink it down, work with it, change it however you want. So let's get started and actually start looking at the code. So what you'll often see in almost any Pulumi application is these top three lines and they're just really the way to get access to the Pulumi resources that we're going to need here for the purposes of this demo. We're using No Js and the Pulumi touch script API for that. So the top line just gives me access to the main Pulumi Abi the second line is what we would consider sort of our una opinionated low level access to the entire Aws set of resources out there. If I go into it, you'll see all sorts of modules that kind of match what you might expect to see from the breadth of Aws. And we really try to make it so that you can get to everything and can configure things however you want. The last line, uh Aws X is our crosswalk library. So the X is kind of a crosswalk. Uh If I go into this, you'll still see a whole lot of modules there. And these are the areas where we've tried to build, you know what we think of as more convenient abstractions for working with these things. We'll take care of a lot of defaults for you. We'll combine things in useful ways and we're gonna get a chance to start seeing that in just a few lines. Um The next two lines are just a couple of real no Js packages. The first one is query string and the next one is super agent. They help out with building URL S and talking TP. Um I'm kind of showing it there just to show off that this is a real no Js application. You have access to the entire wealth of packages out there. Pretty much all of N PM is at your disposal. You're not limited to just things that Pulumi has built. So all of your existing skills and javascript and typescript and node should carry over really nicely here. So at the bottom, we'll jump ahead a little bit at the code. I just wanted to call this out. You can see a few lines that relate to getting configuration. Um because I'm going to need to talk to Slack and Slack is going to need to talk to me and we're going to need some tokens to do this. And what's nice here is I haven't had to embed any tokens into my sources. Cope. We're using Pulumi config system. These values can be encrypted at rest, you know, and it just means a kind of a better pattern for, for doing this sort of thing. So moving on a little bit from there, I'm going to have just a couple of resources uh defined in my program and notice that these are both Aws dot Resources. So these are really actually just the low level real um Aws resources that give access to the breadth of Aws. So we have a Dynamo DV table. It's not that important. It's just for storing some information. And we have a topic that we've created. And the reason for this topic is kind of interesting. Um If you ever have talked or used this lack API S, uh you'll know that they really want your system to respond very quickly so they will push messages into you. Uh But if you don't respond immediately to them, they'll consider something that they'll think something is going wrong and they'll keep resending the messages and eventually we give up. So because of that, when we hear about the messages from them, we don't want to really do much at all. We just want to shunt everything over onto this topic and then give it back to them and then we'll process the topic later using a serverless lambda. Um, this could be sort of any queuing resource you kind of wanted. You could use SQS if you wanted, you could use MQ. Uh We don't decide that for you, you know, that's up to you based on whatever you think is the right thing. Um In this case, the topic, we didn't even need to change anything. But if we take a quick look at the table, you know, you can see, I pretty much have access to all the types of things that a dynamo table would, would give me the ability to configure. So in this case, like I'm going to pay per request. So now that we've got that out of the way, we're gonna start getting into the very first, very interesting um crosswalk component and, and this is gonna be a chance for us to kind of show um how crosswalk can really raise the abstraction bar and make it much easier to do uh development against Aws. So normally, if I was trying to build a system like this, I need to wait for Slack to send me messages and they want to send me messages over http a standard way to do that would be to just create an API gateway breast api. But if you've ever kind of used that system before, you may feel that it's kind of a difficult thing to work with. You. Oftentimes have to set up a lot of open API specification. You have to set up breast Apis and deployments and stages. And it's kind of a lot of things you have to do when you're really just trying to say, I want to be able to get a message over http and deal with it. So what we have here is what we call the crosswalk API gateway API. And what this does is this gives uh an API to you that's sort of much more in the No Js style of listening to Http. So what you can kind of see here into it is that I'm basically just saying I want to receive post messages at some slash events and points and then I want to do something when that happens. And this is actually rather interesting what's going on here. The thing we're saying we want to do is actually execute this little bit of javascript code. So right away, we've actually just done something that normally would be extremely difficult to do when coding against the cloud. This little javascript function is actually become an aws lamb up and that Aws lambda will be hooked up by us to this rest API and when this rest API is triggered, the Lander will get passed the information and can process it and return something out. Now, to be clear, you don't have to pass a javascript function here. You could actually pass a real resource for an aws lightened up, you know. So I could say Aws dot lambda dot function dot gett or make up a new one. And that would actually work great in practice. For example, if you had an existing Lambda function, maybe something written in a different language or maybe something a different team wrote, you're totally welcome to use that. So even though we give this flexibility to provide your own function, you don't have to, you don't have to use ours and you can use your existing infrastructure or do things in a different way. Another nice thing is because this is typescript as Mike kind of showed if I go into event, um you see all of this information about what you can do with the event as you would expect. There's the body, there's the headers, there's the path that sort of thing. And, and this really helps from a coding perspective, know what's allowed and know what you can do here. So I'm gonna scroll down a little bit. It's not that important to know kind of all the little details of what's going on here. You can see that in the sample, one thing I want to call out as well is this event handler is going to end up calling this little helper down here called on event callback. And I'm showing that actually to kind of demonstrate that we're not just taking that little javascript function above and just spitting it, splitting it into a Lambda. We're really analyzing your code and figuring out all the things that can carry along with it. So in here we call, we call this helper, this, this call back and Pulumi will figure that out and pass this along as well as part of your aw slam done. Ok. Now dive into this for just a second because it's actually really interesting. This is going to do the thing we said before, which is we're going to take the message from Slack and all we're gonna do is we're going to put it into our SNS topic to be processed later. And here's another real powerful part about polluting. So notice that in this piece of code, I'm referencing topic, which was the resource created above. Normally, if you had to create an Aws lambda that needed to talk to your topic, you'd have to find some way for it to know about that resource. Maybe it have the heart, maybe it would have the A R and hard coded in. Maybe you spit it into the environment variable somehow you need some sort of mechanism here. Thanks to the fact that this is all one piece of unified code, even though this is the code that will run in Atlanta, it can talk to all the other resources I've defined without any issue at all. And in fact, if I change anything about my topic, maybe doing anything that causes it to get a new, er, and we rerun our program, the land will get updated automatically. It's not a secondary thing you have to think about. And that's really kind of one of the powerful things we think about when you're making a whole polluting application that contains your resources and the connections between that. So at this point, if we've heard about a message from Slack, we'll have taken it and we'll put it on our topic. So that's kind of been the publishing portion of things. Um But you still need a way to get at the message and then deal with it. And so let's take a look at how we do that here. So, uh I've got the topic again and then we have this little simple on event helper here. And this is kind of very similar to what you might find in many programming languages where you can attach a little call back to something. And this is actually going to use the same mechanism we showed for api gateway above where you just pass it a little function and we're going to make a Lambda for you on your behalf. Um I'm running a little alone time, so I'm going to speed things up a little bit. Um So at this point, we'll have our two functions, our two Lambda have been created and we'll have a totally working app. But at the same time, I don't think of this program as complete yet. And the reason for that is, you know, I don't really have any insight into what's going on in this app. And let's say more of the team starts using the little bot or we even want to product it. And Pulumi wants to switch over to creating Slack Box. I'm gonna want a way to know how well things are doing and to make sure that my functions are behaving properly and with cross block, that's really easy to do as well. So what I have down here is two lines which are basically the way to get at the lamb of functions that are going to be created. I can say API, I can get the lamb of function for the API gateway and I can get the one for the topic subscription I just made. And then what we have in crosswalk are ways to get at metrics for all the resources in your system. In this case, because it's a function metric, we're going to get it out of the land space, name space. I can create an alarm really simply which basically says, hey, you know, if my endpoint is taking longer than five seconds over a 15 minute period. That's not OK. I need to know about that. And then finally, I'm going to go through this very quickly. I can in my code easily, just create a dashboard that will allow me to look and see what's going on and get insights on things. And this dashboard contains my keys, my, you know, my percentage duration levels and then it also has it's going to contain a little line for where that alarm was from before. And just to show you what that looks like when I run all of this, I end up getting a really useful dashboard like this, that tells me how the health of the service is going as you can see on the receiving end. Um I'm actually doing fine. I'm normally not coming up there at any point. And then the processing side, we can also see how well that's doing. Usually those spikes are, you know, sometimes talking to Slack is a little bit on the slow side. The nice thing about this is really all I did was create about, you know, four resources of my own, um wrote some very simple code. But at the end of the day, all of these resources are created and configured for you and will be kept up to date as one cohesive application that you can maintain altogether. There's no out of bound artifacts. Um and anything you do will get updated normally. So um that's about it, you know. Yeah. OK. Yeah. So I think, you know, that's a really great example of kind of the other end of the spectrum where we're kind of doing some of that serverless kind of workload and just going really simply, you know, with, with a page full of code to having a really full little kind of service there. Um Plus having metrics and the things built in And really one of the things I think that is most exciting is we can mix and match between that and some of the stuff that might show and some of the Fargate stuff that we didn't have a chance show here, but there's lots of information about that as well as part of the cross launch. So I think that ability to mix and match these things is, is really great. Um One of the things I I think has been really interesting about this project and for folks who have been sort of part of the Pulumi community for a little while is we've obviously built all these libraries along with a lot of users and customers over the last, you know, several months. And so many of these have been out there in various forms and have been iterating for a little while. And so key to that has been getting that feedback early often from kind of users customers uh of, of these libraries. And so I wanted to spend some time talking to, uh, Eric Shame, uh, from Te and Eric's been, uh, you know, his team has been, uh, using some of these, uh, packages, uh, over the last few days and I just wanted to sort of, uh, talk to him about kind of the experience, uh, that his team has had and, and, and they've been a really great help in, in helping us shape, uh, several of the components that we talked about here. Uh So, first Eric uh are you there? Yeah, I'm here. Great. All right. Well, great to talk to you. Um So I think the, the first question is just kind of uh can you tell folks about kind of what your team uh what your team does that at Tableau? Uh Yes, I'm a developer on an infrastructure platform team working with Tableau online and Table Online. It's our online product. We have 21 of them is Tableau online, one is Table public. And um the historically, we Tableau online was really just running an instance of the on prem server, but Tableau hosted it and then it, it all came from this monolithic code base that originally started as a desktop app. And so um the past couple of years, um we've been slowly working at breaking up that monolithic code base, switching to a more micro services architecture. And um my team is now taking the, the work on to continue all those services and provide the platform where we can run all that. And um, I guess with respect to Pulumi pretty early on in the project, we, uh we looked at different options for how we manage infrastructure as code and we knew that we'd have a lot of it to work with. Um, and, you know, everyone, everyone was in terraform, I think it's, it was pretty standard across the industry. And a couple of people on my team, they had tried out here a few months went by, they tried it out again, some more features came in and said, hey, this is really worth the shot. And we started coding against Pulumi as a proof of concept and saw that we got, you know, pretty rapid iteration on it and also um pretty rapid response when we come up with issues or requests and so on. And so now um what we have is a whole bunch of different Pulumi projects and we're, I think we're at the order of like 50 to 100 stacks right now and we still haven't fully built out all of our infrastructure. But um those stacks represent things like EKS clusters. So we have an EKS uh cluster project. Um And that's sort of the core of what, what we're doing. Um That's the base project on which we build all of our other projects. And so the E can cluster projects and we define the cluster, we define several node groups. Um So some examples are that we run uh for doing um I am role, role based off for services. So at the service level, uh and so we provision another node group just for the server, we provision a couple node groups because um different teams have created services that have different requirements in terms of the instances that we need for EC2. So we have one node group that's specific to a very high memory usage uh workload that we have. We have a couple of groups that are lower in memory but require uh high CPU. And then we have special storage requirements because of the different um uh database work that we do. And, and you know the extracts that we take from those databases and tableaux. Uh And then aside from the, from the actual sort of hardware piece of it, we also have in that cluster project, um new relic monitoring. So we install it through uh through Pulumi. And in the same project, we do our Splunk forwarder set up, we do um all of our, all of our logging goes to Splunk. We have a few other logging things that fluent D is connected to send, send things to various places. Um And then also we have our um horizontal pod auto scaling definitions and our uh cluster auto scaling definitions and resources provisioned in that one project. And because we have so many teams on boarding and new services uh kind of everybody wants their own name space in our clusters. So we decided to, to uh to break out the name spacing into a separate project with a separate set of set acts. And um we're using, we're using one stack for name space to manage things like our role definitions, our role bindings the resource and quotas limits for those name spaces. There's certain things that we have to prepackage into name spaces for developers, various config apps secrets and on persistent volume. Uh So, yeah, we've managed to break that all out. In addition, we have other, other projects related to the things like our um artifact storage and S3. Uh we have ECR that we are where we published our doer images. So it's really across the board. We've, we've standardized on using Pulumi to do to do all that work. And so far it's actually been been great, especially with the interaction between the team and the Pulumi team and the community. We get, we get really rapid response and I think the longest we've really waited for something is like a sprint, maybe two sprints um for, for the bigger asset that we have um for the bug fixes it like really quick turn around. So I've been, I've been really happy with it and um yeah, is there anything else specific that you'd want me to kind of talk about? Yeah, I think, I think that's a great summary and I think it's really interesting to hear some of the breadth of, of what you guys are doing from, you know, uh everything from raw Aws sort of infrastructure to, to some of the sort of life cycle things around ECR and that sort of thing. So really covering a lot of uh breadth of the platform and obviously doing it in a, in a, you know, pretty serious uh workload that you guys have there. Um Curious, you know, like, uh you know, as you guys think about, you know, where uh where you want to see kind of bloomy and crosswalk radio evolve uh going forward, you know, are there some key areas that, that you guys sort of are, are really eager to see uh bloomy go even further with? Yeah. So um a couple of things, I guess one is uh we use stack referencing between our projects in order to kind of build on top of stacks uh to have this hierarchical structure of how we make our snacks. Um And so that's, it's been really beneficial for us. Uh One of the thing that we're trying to do though is um with regards to is one of the best practices that's coming out is this idea of having many small clusters rather than one monolithic cluster for your workloads. And so um there's kind of two components of this one is there's gonna be overhead with managing all those clusters and then, you know, the service mesh on top of that and federating the clusters and so on. But the, the thing that we're currently designing and working through is the notion that we want to do blue green cluster deployments. And so the idea is for any given cluster, we want to be able to create a new one in its place, migrate the workload and then destroy the old ones. And so I think the, the ask that we'll have is gonna, is gonna be some feature in Pulumi around that around um sort of automating that process because we know that we can already do um Pulumi will already create before destroy or create and replace, before destroy. And so I think it's taking that concept to a larger level to encompass the EKF clusters, the node groups, the the other stacks that reference that cluster and having them sort of automatically updated. I think there's gonna be a lot of feature work that we can think of um around that. Another thing that we are thinking of is um we don't want to have to refer to a stack by name, right. So uh we wanna, we wanna have sort of this um abstraction layer where instead of talking about a stack by its name or an EKF cluster by its name, we want to talk about it by its properties and sort of say we want the sandbox active cluster or maybe the sandbox standby cluster and, and then that would sort of pull up all the info. And I think that right now we have that available through stack tagging. And so we've started to tag all of our stacks in with certain sort of functional characteristics of them so that we can uh so we can start to build some kind of layer on top of on top of that. So we can do in indirect with our referencing. And I think that would really help because then instead of having people, um for example, a developer that wants to do something with a particular stack, they would just reference the online primary instead of the name of the stack. And when we then update it or replace the stack entirely, all we have to do is update these tags on there and everybody will automatically get the benefit and have that information propagated. So those are the kinds of things we're looking at. Um I don't think that there's yet like a industry standard on how to do blue green cluster migration or um workload migration uh that it's still sort of in its infancy. But, and I think we'll see some maturity around that, especially as a WF aws gets into the game into that particular game. Um Yeah. So those are the things that come to mind right now. But no, that's great. I think both of those are examples of things where, you know, I think uh with the first example with the um you know, blue green clusters and cluster upgrades. You know, I think we know that that's something that today kind of, you know, aws and E could sort of just leave it to, to you to kind of manually do it. A lot of folks like yourselves really want to go to automate that process as much as possible. And that's a thing that can, can try and help with. Right. We can go beyond what uh what a primitives are provided and we can help you to automate that one for the infrastructures code way. So I think, you know, there, there's some things we're, we're already working on there to try to make that process even kind of smoother than it is with what you guys are working on today. And then obviously the, the kind of stack tagging and things I think we know, you know, I spoke to build up these very large project with lots of interconnections um having those in directions, having that ability to sort of tie those thing together and see the whole picture um is really important. So another area that like we're really excited to, to work with you guys and many other uh folks in the community who are, who are building larger and larger uh applications on top of. Um So, so great. Thanks a lot, Eric. Uh It was really great to hear about that and uh thank you to you and everyone on your team for all the feedback uh uh so far on a crosswalk. Yeah, thank you. Um, cool. All right. Well, that was, uh, that was it, I think for today. Um, just for folks who haven't yet, uh, gone and tried to, um, check out, uh, crosswalk, um, or Pulumi generally, uh, you can go to, uh, Pulumi dot com, uh, to, to check out, uh, crosswalk. There's some great material there on the front page and you through, um, into sort of a blog post, you wrote some really deep articles that walk you through um using all the various different uh pieces of surface area that, that uh sorry and Mike talked about here today. Um And so definitely jump in there. Uh If uh folks aren't yet in the gloomy community slack, uh There's a link to our Slack there on gloomy dot com and you can join there, ask questions um and get help from, from everyone in the community uh on getting started. Uh So thanks a lot for joining us today. Um And uh definitely uh come join us on the Slack or, or on an email if you have any other questions. So, thanks everyone and have a great day. Bye bye.

---
