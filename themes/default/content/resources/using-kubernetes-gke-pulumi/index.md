---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Using Kubernetes on GKE with Pulumi"
title: "Using Kubernetes on GKE with Pulumi"
meta_desc: |
    Pulumi CTO Luke Hoban walks through getting started using GKE and Kubernetes with Pulumi.
url_slug: using-kubernetes-gke-pulumi
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Using Kubernetes on GKE with Pulumi"
  description: |
    Pulumi CTO Luke Hoban walks through getting started using GKE and Kubernetes with Pulumi.
  sortable_date: 2019-02-06T23:01:27Z
  youtube_url: https://www.youtube.com/embed/MAqpBxKCslo
transcript: |
    Uh So first off for folks kind of getting started with this, um you know, no matter what it is, what platform it is you're targeting uh with Pulumi, the, the best thing to do is really to come in. Uh either, you know, jump in on to one of these icons here for the platform you're interested in or uh go to getting started and find the platform that uh that you're interested in. And so I'll start with uh with Google cloud platform. Uh And so we can come into the uh instructions here and the landing page here gives us uh some of the key things we need to know some of the examples we can go look at for sort of a full running app, sort of very minimal, like, you know, what is the, the simplest possible program look like some links over to the API documentation for those libraries. And then so finally, kind of some of how we can configure the providers so that we can connect up our deployments to the particular projects and accounts and credentials we want to use to deploy the best. Um And so this is definitely a good place to kind of get started to orient yourself. Um As you're starting up for the first time using any one of these platforms, whether it's Aws, Azure GCP T open stack or any of the other platforms that we, uh we support. And so what I'll do is actually come over here and just kind of go to a, um, kind of a blank slate and, uh, and just kind of from scratch, uh work through building up uh an example that uses uh GKE. Uh And actually what I'll do is first show, you know, we actually have a, a fully functioning sort of example here of using Google engine, just click on this. And this is in our examples, repo you know, you can come in here, this is sort of um you know, show us how to spin up the Google container cluster, how to uh you know, set up some of the configuration that you might want and then finally how to deploy some resources into that. So we're largely going to kind of recreate some of these pieces. But if you want to see something that's sort of the finished working example of this, I'd encourage you to kind of go just look at that, look at that example, but just to give you a feel for what this looks like going from zero. I'll, I'll start just from scratch here. And so I can do something like here, Pulumi New uh I'm in this empty folder, GKE demo. Uh Actually, I just bump up the fonts a little bit here. What I can do is come and pick out the oops, pick out the GCP typescript example to start with. And this will just give me um a very simple uh project to deploy on GK. Now, uh you know, that's for the GCP project to deploy into uh I happen to an account that I have credentials for locally on this machine. I happen to have a Pulumi development uh project. This would be dependent on kind of what projects you already have set up. Uh And of course, with Pulumi, you can manage your projects as well if you want to create a custom project and then deploy resources into that. Um But for me, I'm just gonna make sure I use an ambient uh project and one that already exists when we do that, we'll see that. Now I get prompted to, you know, with a simple uh this template just deploys a GCP storage bucket. I'll just go ahead and say yes to deploy that. Um Just so I get something deployed and can uh can get a feel for what things look like. Uh Right away. You now, I have this file as well which describes this templated project that I created. So I'm just importing the GCP library. I am creating a storage bucket and I'm exporting its RL. And so now we've got uh we've got a Google cloud storage bucket deploy. As always, I can also come over here and see, you know, what resources are part of this project. So that uh that storage bucket is right here and all the details about it uh are inside the console. OK? Um But what we wanted to do instead was actually create a GK A cluster. So let's kind of like play around with this and see what we might want to do. So the first thing we can do is to just say uh equals new. Um And of course, the the sort of first thing you can do here is just use the teens and things to kind of figure out what is available here. And so I type in containers and we see that there's kind of two things. So I type in container and now I've got a cluster here, so reasonably easy to kind of go and find that, you know, we've recently added examples into our documentation. And so those also show up nicely kind of inside, inside the tool tips here. So as well as me getting kind of an overview of how this works, I can also see an example of kind of what a real use case of it looks like. And this gives me a good sense of how to use maybe this master off, you know, what kind of values am I supposed to provide there? Um How do I do node config that sort of thing. Uh So let me call this cluster. Uh And now let's go ahead and create this. And so, uh you know, there's a bunch of different options available here. Uh One that I'll need to do is to set up the zone. Well, actually, you know, what I'll do is I'll just show, you know, it looks like I can call this with nothing. Uh And so I'll just see what I can do with that. I'll say cluster dot you know ID. Um And so I'll just create that and, and deploy the, the, the cluster ID. Um I'll say, pull me up to go and deploy this and it should say that we're going to create this cluster and we're going to delete that bucket that we're no longer using. Um And so we get kind of exactly what we expect there. You should notice, of course, this is a desired state model. And so that bucket that's no longer here, we no longer have that in our desired state. And so it's going to get removed as we go and move to that desired state. And of course, as usual, I can see the details and see, you know what um uh what, what setting I'm, I'm passing here for those different uh things. So uh we noticed that it immediately tells us that this cluster cannot determine zone set in the resource and set it in provider level zone. And so the only reason I didn't get a static error here is because I could actually have this provided through some ambient configuration. So I could do you know Pulumi config set GCP zone uh us central one A and so I could do this to just set it ambient. So anything that needs its own, can, can default into that. Um But I, what instead of doing that, I'll actually provide it directly in line here. Um And so I'll say us central 18 which is uh one of the zones available in uh Google, Google platform. Now, what I'll do is I'll just say skip preview here for the next one so that I don't, instead of seeing the preview and then doing the update since I'm kind of in this just uh development mode. Uh I'm just gonna quickly go through and try the updates every time without looking at the preview. I wouldn't want to do this if I had sort of real infrastructure I cared about deployed. Um But as I'm just building up my infrastructure and I don't care if uh if something goes wrong, um It's, it's faster to kind of do that in the loop. So, you know, I get another error that initial node count must be greater than zero. So I can come in here and say initial node count is three. Just try that again. Now we're going to go ahead and, and create that cluster. Um So uh one of those things obviously about uh um Google engine is uh these things spin up very quickly. So this should only take, I think it takes, you know, two minutes or so. Um But while we're doing that, let's kind of look at like what the next thing we'll, we'll want to do is so, one of the nice things in Pulumi is that we can um as well as creating this GCP resource to create this KTIS cluster, we can actually create KTIS resources. And so, for example, I can come over here and say, uh you know, I could say from, from Pulumi cnet. And of course, I need to actually make sure I'm going to open up another window here. Uh And I'll just say M PM install at Pulumi Co uh since I'm using javascript here and node, uh I can just install any of the Pulumi libraries to get access to those capabilities. And so in this case, uh Pulumi Ktis gives me access to all of the different API S available in cnet's to use those to deploy things as well. Uh And so now I have that available and we'll see, I've got this KTIS here. And so what I want to do is now, I want to actually connect up to this cluster that I'm in the process of creating uh on GKE. And I want to use that to deploy things into the knas cluster. And so the first step I need to do is to create a provider. And so I can say new kubernetes dot provider. And what this does is it gives me an instance of the provider that is connected up to that cluster. And so I call this GK uh you see, I can do that using a few different things I can say, you know, cluster contact names, space coop config is is sort of the easiest one to use. That lets me specify the entire sort of configuration I want for that cluster. Now, one slight challenge is that uh on GKE uh unlike on a KS and, and some of the other platforms, they don't actually expose. Um you know, I I might, might want to have a cob config available here, but there's nothing, there's nothing with that name. And so when I stand up this cluster, it doesn't expose as a property, the cob config I need to use to access it. So if you go back to that example that I showed you uh it actually had a little solution to that built in. Uh There's some code here that, you know, describes, I want to manufacture a GKE style coup config uh which is sort of a unique uh style of coup config that that's hooked up to some of the specific things that GKE does. Um And so this is, you know, uh for folks who are familiar with GK with uh with Cobert generally this is mostly kind of a normal coup config file or we've just templated in some of the things that we do get from the Cobert cluster. So the uh the clusters uh C A certificate, the end point of the cluster and some information about the context. So let me just go and grab that. Um I'll put it over here. So I'll just say uh the coup config uh is this. And I think I didn't call it, I called it cluster. So let's just um grab the clusters, grab the cluster's name, grab the cluster's endpoint and grab the cluster's uh master off. OK. So now that I've got that I can do KNS config OK? So now I've created this provider and I can use that to then uh deploy resources. Um And so, for example, in this case, I can say constant deployment, I'll just try to do the simplest uh deployment I can tones. So now I can say cos dot V one dot dot apps do V one. And again, like we see the completion list here, give me access to sort of seeing everything that's available inside KTIS. Um And in this case, I'm doing an apps V one deployment uh And I'll call this engine. Uh And now I can go and see exactly what I need to specify to uh define a legal deployment. Um In this case, I wanted to, for the, to provide the um the spec for the deployment. Uh I want to provide the uh let's do the template for the deployment, uh which will be what I want to actually specify. Uh And in that I want to um specify the tags for the deployment. So let me actually uh do some engine labels. So I'll create some labels I can use here in uh in the metadata. I want to set the labels to be the engine labels. And then I think I need to specify a selector somewhere. Uh There we go selector and I'll select the match labels and your next labels. Yes, I can't spell the word labels. OK. So uh so there we go, I've set up some basic uh you know, cooper deployments that uh you know, has a selector which will pick up all of the pods with this label and then a template which will template out each of the pods inside my um uh inside my thing. And so I can say, you know, replicas is two or something to, to stand up two of those. Uh And now I want to actually specify the spec for the containers themselves. And so this is where I'll do things like um is that right? Yeah, the pods back. OK. Uh And so inside here I will do things like containers. Um And then I'll say image engine engine. OK? So we can see what our name. I also need a name. OK. So pretty quickly, you see there. I got a few of those benefits of, you know, using the ID, getting those error checking on the fly, getting tool tips and help. I can see that this container thing is a, is a pod spec I can come in here and I can, you know, click through these things and see exactly all the documentation of what I want to use. So very handy to be able to do that. But now I've created this deployment which will deploy two copies of the engine next container into, into my class that I just described. Now, uh we see that that deployment I was doing previously actually succeeded. And so, you know, two minutes, 28 seconds, deploy the uh the cluster. And now if I do Pulumi up to skip preview, what we should see is we had now also deploy. Um oh actually, there's one thing I wanna, I'm gonna cancel that really quick. One thing I want to do is make sure that I deploy this into my. Um It's I wanna make sure I provide this into my uh what do they call that thing uh provider? OK. I'll call it KS provider. Um So this provider that I have, that is my connection up to KTIS. I want to make sure I use that to deploy into uh and I want to do that so that uh instead of picking up any potential uh cluster, I might have available my ambience configuration I want to specify the specific one that I just created within this program. Uh So let me go ahead and do that. We'll see who created that provider and now we're going and creating the deployment itself. And so we'll see when the deployment stands up, you know, waiting for the replica set to be marked available. A few more things happen. Ok. There we go. And now we've actually deployed that so we should be able to see is uh if I come in here, let's open up the Google cloud console, we're in our uh we're in that same Pulumi development project that I was just talking about. Let's go over to engine, look at our clusters. I think this is the one, this is the one in us central one a that we just stood up. So I'll go in here. Uh And now if I, I guess I've got to go look at the workloads on here. Oh, there we go. Uh So this is that, you know, that cluster we just saw um I'm running this engine X deployment. There's two of two pods that we just described. Um So we can see all that information about uh my uh my cluster that I just stood up and the deployment I did into it, you see, it's pretty quick, you know, just in, you know, a handful of lines of code here being able to stand up a cluster and actually deploy some stuff into it all using a single kind of API and that's a, that's a nice thing, you know, I can, of course, now combine that with doing things like, you know, I could uh you know, uh go back and recreate that bucket, for example and say new GCP dot storage dot bucket or I could create a new GCP dot uh SQL dot database. Um If I want to create a sequel that managed SQL database inside uh GCP, uh I could do that and now I could reference, you know, I could grab the connection strings for that, that database and pass them as environment variables into this deployment of, of my application image. And it's really easy to combine the best of, you know, your managed services inside GK and inside Google cloud for in this example, with kind of that is the is the API for doing my my compute. Um So I could just complete this example really quick and, and try and get something that I can show off end to end. I'll just say service equals new uh for dot co dot P one dot service. Um This will give me a a, you know, a service end point that I can use to target this thing. And so I also call this engine and here I want to do spec uh type, make it a load balancer. Uh And I want to uh make the selector mm what type of selector expect to be uh that's just my engine level. Yeah. Um So this will create a load balanced uh service targeting uh those labels. And so let me just see what happens if I now go and stand up. Yeah, 90 ports. Yeah. And I can go again and I can see, you know what is ports expecting to be expect to be a service port, which is a port required port and then optional name, node port protocol and target port. Um So in this case, we know that our, our image exposes port 80. So I'll just say, OK. Uh So I'll just go ahead and do that. I'll just format this. So we get a nice invitation and I'll go ahead and try that one again. This is going to take all the containers that map this engine label, which is these two of both and just expose port 80 of them on the load balancer that we create. Uh And so the service is uh you know, finding the pods to direct traffic to. Uh So it's gonna find, try to find those two pods matching engine X labels. Now it's attempting to allocate an IP address to the service. So that's because we have the load balancer, we actually have to, you know, allocate a load balancer in a Google cloud and point that at the service. And you notice that this is a nice thing that we provide this sort of status here. So unlike you know, using coop control or something to deploy these, where you just kind of uh put these, uh you know, you say throw these at the API server and don't get any feedback about kind of what the status is here. We're actually giving you status on kind of what are the key steps we need to take to get this thing to be healthy um And giving that feedback immediately here. And so after a few seconds, we see it uh it succeeds and gets created. Um And so now we've actually got that service running inside our cluster with a load balancer in Google cloud connected to it. It's like an export sort of the um end point for that uh X IP. Uh And so I can do service dot status. So the service, the status will actually be populated because we wait for it to finish deploying. The service is actually populated with uh the running status of the um of the thing. And so I can say status goes to uh status dot And we got load balancer information on there. We got re uh and then we've got an IP so I can just do that uh run this, run this again and we now should now we need to export data or else it won't work. So that said nothing was changed this time, we are going to export the load balancer ingress IP address off of that service. We, we just created. And now we see that it's running at this end point. And if I curl that, we should see, we get welcome to engine X. And so yeah, we've actually stood up a service running. You know, this could have been anything I want, I could have stood up wordpress, I could have connected wordpress up to that managed SQL database. You can imagine taking this further. You can imagine taking your own apps. And if you want to get those apps running really quickly inside Google Cloud, for example, you know, doing this is is a simple way to take your app, get it running inside a kind of robust kna based environment on Google cloud, taking advantage of, you know, low balancers and a variety of other managed services as part of that. And again, the key thing is here, you have the full flexibility so you now can go and modify anything you want here or you can modify things, you know, in that cluster itself. Uh So there's lots of different capabilities around uh you know, configuring the Cobert cluster and you can go and configure any of the the resources. And so all of that is available from within that one frame there. So OK, so that was a really simple uh example using uh

---
