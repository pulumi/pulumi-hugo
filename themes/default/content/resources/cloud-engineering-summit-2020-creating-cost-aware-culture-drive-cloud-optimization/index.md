---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Cloud Engineering Summit 2020: Creating a Cost Aware Culture to Drive Cloud Optimization"
title: "Cloud Engineering Summit 2020: Creating a Cost Aware..."
meta_desc: |
    As companies transition to AWS, the flexibility in your costs can often bring concerns on how you manage it and how do you avoid that surprise bill...
url_slug: cloud-engineering-summit-2020-creating-cost-aware-culture-drive-cloud-optimization
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Cloud Engineering Summit 2020: Creating a Cost Aware Culture to Drive Cloud Optimization"
  description: |
    As companies transition to AWS, the flexibility in your costs can often bring concerns on how you manage it and how do you avoid that surprise bill at the end of the month. Cultural change is often needed in organizations as they move from IT being primarily fixed costs to pay-as-you-go pricing. A great cost culture is where IT, Finance, and your Business are working closely together, reviewing the IT strategy and spend. Having this cost culture will ensure that the cost of running on AWS is forefront in any strategic decisions or even during the everyday monitoring of the environment.
  sortable_date: 2020-11-11T00:29:46Z
  youtube_url: https://www.youtube.com/embed/KaMYF017qlQ
transcript: |
    Hi, my name is Alex head and I'm talking today about creating a cost aware culture to drive cloud optimization. I work for Amazon web services and I run a team called Optics Optimization Intelligence for cloud systems. And we connect the dots between technology, finance and business for some of our largest global and strategic customers to give you a little bit more detail on what a typical engagement for my team would look like. Here are some examples. So things like a well optimized review, which is where we would go over those low hanging fruit and top five opportunity to optimize and become more efficient. A cost intelligence dashboard which is a tool that my team created to give customers a little bit more insight into their cost and usage data and ways to visualize it that might be beneficial for leaders in an organization. And also the people whose hands are on the keyboards, uh learning opportunities. And we call one of ours a fin hack which is kind of a hackathon to save money and be more efficient in driving that efficiency and optimization. And a huge topic that we talk about is developing. And integrating cost culture into a company. And that's a lot of what we're gonna go through today. So, working with a wide range of customers and also having previously been a customer myself, I've seen a lot of different cloud journeys and I've seen companies that are born in the cloud. I've seen companies that have done big migrations or have had multi cloud environments. It all ranges between the company and the industry and the size. But one thing that is pretty consistent is they'll start out. And as you can see on this graph kind of slowly start their footprint and test around. And then all of a sudden they have two months that they just go way up and they realize that they need to put in some controls to track their footprint and track their cost and really grab insights from them. And so when developing that cost aware culture, we really want to start at the basics and grow to, you know, where you should be doing this on a day to day basis. Even if there's already things in play and mechanisms that are going on, it really helps to go through and redefine this and make sure that it's accessible to everyone. So today, I'm gonna break this up into four different topics. So first is establishing the visibility, then defining success, implementing controls and then how do we drive that accountability and right, how do we get people to care and all that really leads to implementing this cost aware culture that doesn't necessarily have a, a fire drill like you might see in this graph of. Oh no, I spent too much or oh no, this footprint grew really big but makes it so that it's a day to day thing that's implemented in development processes of being really aware of what we're doing and the cost implications of that. So first let's start with the visibility and this has to be the first step. You have to know where people are getting their data and how they're viewing it and doesn't make sense for every part of the business. The key things are we wanna be right? We don't want to change every week. Hey, now look at this report for your data or hey, finance is gonna use this tool but teams you can use this tool, you wanna find something and create something that people across the organization can use. Next would be accessibility. Is it something that just team leads or managers can see or can anyone go see it? And that's really important because if you want people to care about their cost and their optimization, they need to be able to see the nitty gritty of it and detailed, right? We want as much detail as possible and if we can see an overview for someone who might not want to see what oh this individual EC2 instance is doing exactly this with cost, then allow that view too. But the detail is important in case people want to dig down into it. If people understand the data, they're more likely to work with the data. My team created the cost intelligence dashboard. So a well architected lab that anyone can do and it creates these views that you're seeing here. So things like what's my usage cost and how is that growing? Where do I need to be aware? You know, what is my deep dive into storage look like or compute and having different team views. So maybe you log on and you're part of project a and you just see kind of project A's details. Um If we're reporting back to the organization on these views that we can give people this tool as a dashboard to really drive those. And it's important a tool like this. For example, anyone can go in and create their views that just them can see, right? But the underlying data is consistent and what everyone is using. And so it really gives that happy medium of we've defined the data, we've defined the visibility, but we also are giving people the flexibility to learn in their own way and get to know this data and present it in a way that makes sense for what they're doing and what their goals are. So once that visibility is established and and not everyone will get it on the first try, right? Be open to trying multiple tooling or messing around with the raw data yourself or combining different data sources. But it's important once that visibility is established to then define success, what does good look like for you and your organization and what does good look like for each team? So here I listed out some of like the top kpis that I see customers track across the board. And first one being percent growth, which is not necessarily gonna tell you how optimized you are, but always a good one to see, right? Are we tracking normal? Are we looking back historically, when we release a product, our growth percentage usually goes up to this or when we sunset something, we're able to see this change and it's just a good metric to kind of consistently watch also great for when it comes to forecasting and budgeting for your next quarter or year. Serverless growth is is also a big one, right? Um A lot of teams might have a goal around going serverless or what products that have higher serverless growth. What do they look like? How do we change this architecture and how do we define that? The next two are two that I think everyone no matter what, no matter what cloud platform you're on or no matter the size of your team should be tracking and that is storage and compute unit cost. And that's important because you can grow or you can turn things off and your spend can go up and down and up and down. But the unit cost is gonna be a consistent measure of how efficient you are. So say you're tracking your storage unit cost and you know that for every gigabyte stored, it costs me this amount and then you do a huge push to move a bunch of stuff into storage. But you do it in a way that you're utilizing different tiers and you're making, putting a lot into cold storage. And even though those storage costs went up, you're also gonna watch that storage unit cost go down because you've become more efficient and how you're doing it. And the same thing goes for compute. So maybe you're using instances that are better for your environment that are right sized better and you're gonna see that unit cost get better. And even though your footprint might be growing, it's also really helpful for when you have a new team or new project coming on because they'll have a benchmark, they'll know, ok, these teams have a unit cost about of this when using storage and compute. So we need to make sure that that's kind of our benchmark if we have to be at that point or better. And then my personal favorite is elasticity and that's because this one is so easy to calculate the savings to really mess around with and watch the changes in and watch, help teams get better at it. And so if you're building an application in the cloud. One of the reasons you're doing it is because you're getting that elasticity, but not everyone uses it and a lot of things get left on 24 7 and it might be a sandbox uh environment or a non production environment that really is only needed during core hours of the day. Or maybe it's something that can size down um on certain hours and then size back up. And here in the graph, you can kind of see typical kind of Saturday, Sunday, if it drops what, what those savings might look like. And with elasticity, it is so easy to track those savings and to track that impact that you're gonna have and to make improvements. So I always say even if you don't necessarily have a mechanism like a full instant schedule or something like that, that's turning things on, see your elasticity and see how it gets better or worse or maybe how it changes on time of year just to really map that out and, and kind of track that. So some Aws specific KPIS that I look at are first by, by tags. So, you know, if you're tagging your resources, what percentage of your environment's tagged or what's the number of minimum tags that everything needs to have? Um, or that ratio of what's your production resources to non production resources? Does that make sense? Is your non production resources way higher? Should that be the case should we make them more elastic? What is that conversation that you should be having? EC2? I always look at the max CPU when starting an analysis on, on someone's EC2 environment. And that's because average is a little bit more disputable. And maybe in your environment it makes sense to look at average. But to me, if I'm looking at the last 30 or 45 days of your environment and I see that you never hit a max CPU of more than 15% then that's probably something we should look at and maybe there's a reason, right? Maybe this is a memory intensive instance and you don't really need that CPU and we have a further conversation, but it's a good thing to track and a good baseline to set, right? What it, what what max CPU do you want your instances to be hitting? Um Obviously, we don't want them all sitting at 100%. We want that kind of happy medium. But what is that? And what are you defining it as? Um and setting again that benchmark of this is important when bringing on a new product or a new team, you know, we hit a max CPU of this. Uh Also you could, that is something that may not be as easy to calculate uh savings wise as elasticity, but it is easy to calculate as OK. Well, when we're at this max CPU, ours unit cost looks like this and then if we were to increase that max CPU by only 5% this is what our unit cost looks like and really driving those decisions with data that you have at your hands spot to on demand ratio. So with spot instances, you know, is your, if your compute or your EC2 environment is growing, is your spot environment growing? Are you trying different ways to use different mechanisms to bring that EC2 cost down? Um If we see a customer, for example, start using a lot more spot instances, then we usually see their EC2 unit costs go down and spot is gonna be a good way to also calculate savings, right? You can go in and say, OK, well, if I ran this instance on demand, it would have cost me 60% more. Um and tying savings back to these metrics is doing that consistent mechanism of having it and finance and business talk and stay in the loop with each other and really make decisions that help all parts of that business. Uh instant age. This isn't necessarily one that can help you kind of right off the bat. But I always like looking at it because what's the average age of your instance? I mean, sometimes you can go in and average age would be, you know, almost like 300 plus days, which means that there were probably some EC2 instances that were released since then that you might benefit from or it might mean that there's some really old stuff out there that is skewing that average. Um, but it's just a good thing to track and know and watch, you know how that benefits essentially. Usually if you're gonna have a lower average age for your EC2, then that compute unit cost is gonna go down a bit because you're using less expensive instances and newer instances and a lot of times when you do that migration, maybe you realize, oh, I didn't really need this size of instance and I go to an even smaller instance type and that also plays into the generation of instances, right? I mean, if you're running something that came out 10 years ago, you can probably benefit by moving to an instance type that was released last year and has, you know, a better technology and a better pricing structure just because of how old it is. Um something to, you know, set benchmarks around when, when I look at customers environments, I always say if there's anything that's original EC2 original like am one or ac one, then we probably need to change it up or, or maybe it got left on which can happen and it's a good benchmark to say, hey, we're watching this. So keep innovating, right? Keep changing and keep adding different instance types and really seeing what works best. There's so many options out there for these teams that you wanna encourage yourself or your team or your company. To keep trying new things and taking advantage of that and then storage. So if, if I'm tracking storage growth and I'm tracking storage unit cost and from in AWS terms, you know, that S3 cost are people using different tiers. Uh you know, we have less expensive tiers than just S3 standards. So here I show kind of percent in si A as in infrequent access growth and glacier growth with a cold storage. So if your storage footprint is growing, are those tiers growing too? Right? Are people thinking in a way of oh, I can also move these things to a less expensive tier and just making that a part of process. If you track what good looks like. If you say, OK, when your storage is growing, these things should also be growing, then it becomes a part of that thought process as people build new things and add things and grow your business. So as a recap, kind of when it comes to the best practices when saying what does good look like? We first, we don't want to pick too many Kpis. So we just looked at 10, 15 Kpis. We wouldn't want to say, hey, let's go track all of that. Um We wanna make sure it makes sense to our environment and what's important to you also quality over quantity, right? I mean, if you're tracking a bunch just to see, then people aren't gonna care as much and people aren't going to, you know, think of 12 things that they need to look at before they start a proof of concept. Next is kind of defining that cadence. Now, this doesn't mean that people only see these metrics quarterly or monthly. But when are they being reported back? And when are we gonna show those successes? We wanna make sure going back to the first step that the visibility is there for anyone to check at any time. But that they also are aware of the cadence of what you care about, right? For tracking these every day, we're probably not gonna see much of a shift. Whereas if we were to track them maybe once a month, then we're able to kind of show. Ok, this changed. Now, why did it change? Or these were the monthly savings that you received because of those changes that really plays into number three on this list. So calculate the benefit of the benchmarks. If our elasticity goes here, we're gonna save this much on on our current environment. If we can make our EC2 unit cost to go to this point, then our environment is gonna get to this point. So really showing the benefit there because that's gonna tie back in finance, right? These are adjustments that really the technology side of the company are gonna have to make. But we also want to keep those dots connected and make sure that finance understands why they should care and really also understand the benefit of the work that someone put in. If they did all this work to, you know, put in policies to change storage tiers, we wanna be able to celebrate that and say, hey, finance, because the team did this, we saw these amount of savings and then last is granular but not too granular, right? We don't wanna necessarily look at these KPIS across the board, say you have 20 accounts or you know, three big products and they have multiple accounts working with them. We don't wanna just look across the board at those metrics. We wanna get a little bit more granular so that people can actually make changes and also drive where something might be coming from, maybe one product is significantly more expensive than the other. And then you can really drive to where that comes from and also set those benchmarks, right? So most of our teams are about here when it comes to these KPIS. So why aren't you there or you know, why is this team doing better and really defining that success to, to get that granularity, you really have to implement some controls because as I said, for most customers looking across spend, isn't that helpful, right? It's not giving us that many insights and it's, it's more of a general number. And so we wanna make sure that we're using resources to achieve granularity. So some of the AWS resources would be um Aws organizations or our linked account structure um or tagging and, and as an example of kind of some successful ways that I've seen this done and levels of granularity would be using AWS organizations to kind of define products. So here in the example, I show say the product is SDK and teams. So we know that accounts that fall into these buckets are are those products. Then we, we take it a step further and we looked at, ok, let's name our linked accounts so that we know and understand what they are. Um And it's to me, I see a lot of people name those linked accounts based off of the environment. So for teams say we have a production and a non production environment. OK? That's good where we're, you know, we're getting that more level of granularity. How do we take it one more step further? And that's gonna be by tagging the resources in those accounts. Now, these are just examples of some that I've seen um you know, been important for customers but things like what version of the product is this? Um V two V one or maybe uh future version or you can really track like, ok, well, V one costs us this much or V one has this unit cost, but V two has this unit cost cost center. Again, you want to bring back in finance and business into that technology decision. You want to if you're gonna mandate certain tags, so that you get those insights from a technical standpoint, you also want to see how it's gonna benefit finance, right? And business and, and really being able to relay those costs back. It's also super helpful when it comes to budget season and forecasting because you're gonna have right then and there. Ok, I have to present a budget for cost center 80. Now let me go see what all resources fall into that and then schedule. Um This is one that I always tell people to do, even if you're not using like an instant schedule or anything like that. But just the labeling a resource of, is this a 24 7 resource? Is this something that is only ever touched during the day or maybe it's something that, you know, does have to be on 24 7, but has some flexibility and defining that is gonna help a lot really see what kind of flexibility and elasticity you have opportunity wise and, and give you a little bit more granularity. And now here I picked kind of three tags to mandate, right? I think it gets tough when you get more than, than three tags. Um definitely more than five because that's asking for a lot of, of questions in that standpoint, right? So you know, say you're, you're checking out um at the store and they ask you six questions before you can buy something. You're a little bit more hesitant to check out there. So you know, make sure that if you're mandating some of this and that you're, you're being kind of reasonable in that granularity standpoint, right? And like I said, you're being granular, but you're not being too granular to where we, you know, things are gonna kind of get lost and, and maintenance and hygiene of that data gets tough. So to mandate some of those tagging and enforce the tagging to make sure that people are doing this and you're getting accurate data, you know that visibility and that defining success isn't gonna mean anything if it's not clean data and you know, accurate and and says the right data, the right information that you need. And so I give some examples here of two things that you can do in Pulumi that um help with that enforcement. So using policy is code and, and that enabling that policy pack to say you have to have these three tags when you create this. And one of the things that I like about that is when it comes to tagging, you could, if, if people kind of go rogue, you could end up with hundreds of thousands of tags, right? So you could have environment spelled five different ways, capitalized all caps abbreviated. Whereas when you're enforcing tags this way, you can kind of say, OK, this is the tag that you're adding. So you know, don't go rogue in that standpoint. Um And then infrastructure is code to automate some of that tagging and, and looking at some of those things that you've created through Pulumi and being able to go back and, and change them or maybe you've shifted some cost centers and you can kind of go back and automate that. So last is, is driving that accountability. Um You know, why, why do people care? How, how do you actually make this a part of your culture and you know, not just something that people say, oh, it's, you know, oh it's budget season, we have to do this, but something that people think about when they're drawing up that architecture plan and they're thinking about when they're thinking of new products or new versions of things to bring on. Um And these are, you know, some of the ways that I have have done have seen customers be successful in this standpoint. And the first thing is really that game I right. So make it fun to save money. So go and, you know, show when people have saved more money or, or put, you know, a reward out there. Um It's so common for companies to, you know, say, hey, here's a list of everyone who needs to right size or who has idle instances sitting out there. But if you're gonna do that, you also need to reward the good, you know, say, OK, here's a list of all these teams were able to bring their unit costs to this point or this team started using spot instances and we saw this amount of savings and so, you know, gaming the process of uh really saving money and optimization. Um One of the things I referenced before is we, we sometimes do an event called a fin hack, which is where we learn some of these levers of optimization. Maybe it's a spot instance, maybe it's tiered storage or, or maybe it's diving into this cost and usage data and then we all go break up into groups and gonna use that new knowledge to find ways to save money and and see who can find the most savings, right? Um Make it fun to save money, then you want to reward, right? So like I said, you don't just want to send a list of, hey, here's all the people that need to save money and um or that aren't doing a good job. You want to say here's the people that were successful and here's the opportunity and then you want to set a regular cadence, right? You want people to know that on the 30th of every month or maybe it's the first Monday of every month, they're gonna know where they sit, right? They're gonna know that someone is looking at this and not only noticing if something might be bad or there might be something that uh needs to be fixed, but also noticing when you're doing something good and that you've put kind of effort in there and and driving that accountability, right? You, you give them the right tools. Now, how are you getting them to care? And so as a as a recap for all this. So, you know, we talked first about that visibility piece and making sure that customers or that people on your team can see the cost and usage data, right? You're not gonna be able to make anyone aware of their cost if they can't see it. And also if they're not all using the same consistent way to view it, and once you kind of establish that visibility and that way that people can go, then you define what does that good look like. So when using this data, you want to make sure that you are looking at these top five things because that is what we've defined as success and those can change, right? You're not locked into them, but you have to define them and you have to document them. OK? So we've been given visibility, we know what it looks like to be good. But how do we get that granularity to actually action on that? Right? So to actually make that data and that success KP I important to us and that is where we implement controls, right? We implement ways that it's doesn't have to be an afterthought to add that level of granularity through something like tagging. It's just automatically a part of the process. Um you know, taking that one less step out of it and making people automatically get that granularity when they build something, then driving that accountability. Right? You've, you've automated the granularity, you've told people what it looks like to be good and successful and you've given them the right visibility so that they can go through and, and see that data and really in real time react to it. Right? Not just get a report at the end of the month that they're gonna react to when they could have started making changes before. And you've done all those steps and now you're gonna drive them to be accountable and to actually put it in their day to day, right? This last step is really where you make it a part of your culture and that is it for my uh talk today and let me know if you have any questions. Thank you for having me.

---
