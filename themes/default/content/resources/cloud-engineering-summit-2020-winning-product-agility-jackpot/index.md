---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Cloud Engineering Summit 2020: Winning the Product Agility Jackpot"
title: "Cloud Engineering Summit 2020: Winning the Product..."
meta_desc: |
    Learn how a social gaming company from Australia builds their product stacks to maximize product agility and engineering efficiency. The talk cover...
url_slug: cloud-engineering-summit-2020-winning-product-agility-jackpot
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Cloud Engineering Summit 2020: Winning the Product Agility Jackpot"
  description: |
    Learn how a social gaming company from Australia builds their product stacks to maximize product agility and engineering efficiency. The talk covers effective ways to leverage containers, infrastructure-as-code and the cloud to build product stacks that not only deliver business value but also make engineers excited to work on them.
  sortable_date: 2020-11-11T00:28:44Z
  youtube_url: https://www.youtube.com/embed/QrdNIhCWW2A
transcript: |
    What's up everybody? Thanks for tuning in to my presentation. I hope you've been enjoying the summit so far. My name's Luke and for the last 14 or so months, I've been having an absolute blast working at a place called VGW. VGW is a social gaming company founded in Perth, Western Australia, which is also where I live. Um And we have a couple of pretty cool game products on the market. Uh I'm lucky enough to be a site reliability engineer for one of them called Chumba Casino Chamber Casino is an online social casino currently serving customers in the USA and Canada. Um And what I'll be talking about today is how I've been working with the team at Chamba to uh to do this. So these are two metrics we use um of a handful of different metrics to track um our software de de delivery performance, we got these metrics out of a book called Accelerate. Um I'm sure some of you have probably heard of and or read this book. Um But I will give a quick brief summary just to get everybody on the same page. Uh like it says on the cover the book is about uh building and scaling high performing tech organizations. And in the book, it explores um the various factors that impact software delivery. Their research suggests that if you can optimize these four metrics, um you will deliver faster uh and more reliably than your competitors. Now, I've only got two of the four up at the moment. And that's largely because pretty much everything I'm gonna talk about today is pretty directly related to uh these particular two metrics. So the things I'm gonna cover today um are infrastructure is code. Um I'm gonna talk about some principles we use at Chamber when writing infrastructure is code, I'm gonna talk about um some deployments, uh stuff. So principles we use for deployments and how we kind of unpicked our, our existing deployments infrastructure. And lastly, I'm gonna touch a little bit on how uh when you get the, these first two parts, right? You can start to really reap the benefits of, of D A and everything that do A provides. So let's get started on infrastructure as code. So, um I'm a big fan of infrastructures code. I've been working with a lot over the last several years of my career. So, um when I started in July of last year at uh at Chamber Casino, um I was pretty keen to see what they had. I knew they were on Aws. So I was expecting um probably cloud formation, um maybe some terraform but uh, in my first few days, they mentioned that they actually had a custom in-house built, uh, Python code base, um, that a handful of, um, architects had built, um, uh, quite a while back, but we're no longer at the company. So, um, I, I did start to get a little bit curious and, and, and, uh, they did raise a few red flags eventually at some point that week I checked out this infrastructure as code and, um I was pretty imm mortified, um to say the least it was a, a massive 15,000 line Python code base. Um, and the more I kind of looked into it and, and tried to see how it worked, I identified a, a huge number of issues um straight away which you can see on, on the screen there. The biggest issues were just how highly abstracted it was. Um the fact that it was unmaintained and the, the infrastructure that it was uh deploying was very rigid. Um, and very standardized. This code base was kind of intended to define all of the ins for infrastructure across VGW, not just for Chumba Casino. And so as a result, it was uh highly standard um, and, and very difficult to change. Um, it was a big ball of mud. Um, but, er, er, in, in, in infrastructure as code terms. So I pretty quickly identified and, and worked with the, the, the seniors and, and engineering lead for chamber um, to say that. Yeah, look, it was pretty clear we need a AAA real infrastructure as code tool pretty quickly. Now, as you've probably guessed already, um that all eventually was Pulumi for us. But I did want to take a brief moment to talk about how Pulumi wasn't actually my first choice uh originally. So as I mentioned, I've got quite a bit of um experience writing infrastructure as code. Um but all of that experience has been using declarative languages. So YAML or, or HCL, um, when I've used a bit of terraform and I've always considered that to be the, the real man's infrastructure as code and, and why would you sort of do it any anywhere? Um, any other way when I first found out about Pulumi, um I was pretty skeptical. Um and uh my, my assumption was that using imperative languages to write a infrastructure as code would be a catalyst to um writing er, similar things to the, the giant Python code base that I'd just seen really highly abstracted complex code bases. But as I used it some more, I, um I, I started to like it and, and very quickly changed my tune and, uh, and so did the rest of the, the squad leads um in chamber casino, some of the main reasons. Um, we chose it over everything else was, uh, we, we, we're pretty deep into typescript already. So 90% of all the active development in Chumba casino happens on typescript. So um being able to write typescript with Pulumi kind of fit right into our workflows and tool chains. The ID integration was great. Um The, the typing, the autocomplete and the the in license and probably my favorite um thing about uh imperative languages and infrastructure is code is actually being able to use real looping constructs. Uh So four loops for example, or um or or or other kinds of loops to really just cut down the, the the amount of code you have to write. But as much as vendors may want us to believe it, um new tools don't just make all your problems just magically disappear. We still needed um some good principles to follow and we still needed to make sure that we weren't going to end up with another massive code based monstrosity uh like we already had. So let's talk about some of those briefly. Now as software engineers, we tend to have uh we're prone to taking abstraction a little bit too far sometimes. So something I've um tried to ensure that we do um with our infrastructure as code moving forward is to uh just keep a handle on that abstraction and and not go overboard. Um It's really important I think to keep it simple. Um Even if it's just so that when you onboard, new engineers, particularly juniors or associate engineers that they don't need to kind of wade through four or five levels of abstraction before they can understand the the various cloud provider resources that are being provisioned by the infrastructure as code. I think it's very easy to go too far with abstraction. Um And like I said, it just, it just muddies the water, but it's also um not necessarily ideal to not go far enough with obstruction if you don't abstract enough, it means there's lots of duplicated code, lots of rework and things of that nature. So it really is um something you've got to find the right balance for one of the other biggest problems with the old infrastructure is code was um it was highly standardized. And uh what that meant was uh we were, the engineering teams were kind of put into a confined in a box with, with how they could architect uh the infrastructure that ran their services with the new code. I've chosen only to standardize some of the really basic building block style resources. Um So for example, I've got a, a Fargate web service module that we use um across chamber at the moment, but it only really defines just a an ECs service, um some tasks, definitions and some roles and things like that. And that's it. We've also got a couple of other small standardized modules, but these are mainly for utility things. So things like LAMBDA to send log streams to our log aggregation tools um and things of that nature, I think, like I said, standardize too much standardization, just limits innovation. Um And if uh if I was hoping for the, the engineering squads to be owning their infrastructure as code, I needed to be able to let them uh do what they needed to do um and solve the problems in the best way that they could come up with. So the other thing, standards sometimes try and do is to uh enforce policy. So as an example, let's say you need uh to ensure that all S3 buckets in your organization are encrypted. What the the old infrastructure of um as code uh chamber would have done is kind of provided you a bunch of prebuilt infrastructure components that only had encrypted buckets. But I think the the better way to achieve that same outcome while still uh kind of unshackling your engineers is to use policy as code for that. So there's a number of different policy as code tools. Um With Pulumi, obviously, we use cross guard, but there's sentinel available for terraform. Um an open policy agent can be used in another um of other contexts. I think when you define constraints and let your engineers just fill in the blanks. That's when you get the best result. If you, like I said, if you're giving prebuilt um uh infrastructure components to engineers, they'll very quickly find the limitations of those uh standards and find it difficult to uh to move around them. It's much better instead to just write policies tell them where the, where the constraints are and, and um, and let them fill in the gaps. So these are just a couple of the principles. Um I've started following with our infrastructure as code. Um But after getting started migrating a lot of this stuff to Pulumi, I quickly found that um it wasn't just infrastructure as code that was holding our deployment uh performance back and that kind of brings me on to uh the, the next topic of the talk and, and that's deployments. So like a lot of companies, um we uh we had Jenkins a Jenkins install. Um And while I don't really have a huge problem with Jenkins in and of itself, um I think there's probably really nothing worse than a Jenkins install that you inherit from, from other people, particularly when you started a new job. Now, the Jenkins install at Chumba was um was a particularly bad case of this. Um Again, it was um just a, a sprawling mess of uh of scripts or what I like to call script. He uh bass scripts that linked to other Bash grips that linked to Python scripts that had various different control flows and configuration in them. Um It was largely unmaintained and unpatched as well, so it, it hadn't been patched in and God knows how long um it was running a very old Jenkins version, the pipelines were very brittle. There were very frequently pipeline failures that you know, required an engineer. Sometimes they just a senior engineer because they had most of the previous experience troubleshooting things to fix it. So it took a lot of time. Um and it just wasn't fun for everyone. It was a, a giant dumpster fire to, to use a an overused um analogy in, in software engineering. So one of the main issues I ran in or one of the main decisions we had to make then were, are we gonna stick with Jenkins um and try and clean it up and, and, and fix things or were we gonna pivot completely and move to a different tool in our particular case, making changes to Jenkins uh were just super high risk. There was no easy way to test things in isolation um without sort of replicating a, a large number of different scripts that were, some were in source control, some weren't. So it, it, it became a very risky operation if we broke things, if we broke a certain pipeline or, or if we accidentally, you know, took out Jenkins for a day or two, that would be a day or two where we couldn't do any deployments, which is, is a pretty big deal as you can imagine. So we pretty quickly made the decision we were gonna um migrate to something else. Um And it was likely not going to be Jenkins, Chumba Casino doesn't really have a lot of uh engineers with operations experience. So we tend to shy away from um managing our own, our own servers and our own deployments and, and definitely prefer managed services. So that's what we started looking for in a new tool. So we ended up choosing code fresh. Um And there are a couple of key reasons for that. The first being, the, the feature set is quite balanced as far as CR CD tools go. What I find is that a lot of tools are either really good at C I or and not so good at CD or vice versa. Codefresh seem to be um kind of the best of both worlds. Um There's still sort of a handful of features that um are missing but are are on the road map. But overall, it was a really good fit for what we were looking for. We needed both um C I and CD features. The other cool thing that attracted us to codefresh was its focus on containers. Um Pretty much our entire stack um is now running on containers. So some of the extra container focus we get from codefresh was always super beneficial. But um again, like I mentioned before, tooling isn't just gonna solve all your problems immediately and and this was no different for a code for us. We needed to approach our deployments differently. Uh And we needed to, to unpick some of the the poor um design decisions we had, we had made in the existing stuff. So most of what I've learned about making deployments work really well has come from the 12 Factor app. This isn't anything particularly new. And, and, and again, I'm sure a lot of you have already heard of it. Um But for those that don't know, the 12 factor app um goes into detail on, on 12 factors of app deve development particularly for cloud based apps. Now, I'm not gonna touch on all these, uh because we don't have time. I'm really just gonna talk about the one that uh I feel the most strongly about and that is configuration. So 12 factor uh defines configuration as everything that's likely to change between deployments. So things that change between your local environment versus the staging environment versus production code is or or should always be the same across those environments. So the things that change are things like the URL S of that environment, um potentially the the instant sizes you use in that enviro environment or maybe uh database secrets, that kind of thing. 12 factor then goes on to say app sometimes store configures constant in the code. Um And we did this a lot in Shambo, but this is a violation of 12 factor which requires strict separation of config from code. Now, it may, it's, it's probably not immediately apparent why this is a bad thing. So I'm gonna go through um a handful of examples of um mixing in config and code and, and why it leads to some problems and why it kind of limits your, your flexibility. So this is one that's particularly common um or, or was particularly common. Um It's also something I've seen in not just at chamber um but in a number of different codebases, I've worked on where certain behavior that you don't want to occur in, in non production environments gets wrapped in, in an if statement like this. Um But it's keyed on, on just the value of the environment variable called environment where obviously it it matches the the the type of environment it is now to, to kind of illustrate why this is bad. I'll ask a few sort of rhetorical questions um to, to help illustrate the the the problems I'm trying to identify. So one problem with this code is um how do you, how do you test the production of do production behavior function in a non production environment? You can't really, I mean if, if, if this, if statement was uh just in one place in your entire code base and this was the only place that this environment variable was used, I guess you probably could, you'd just change the value of that environment variable. But what's typically the case is this is listed all throughout the code base and there's um tens and sometimes hundreds of different places where this same method is used. So when you run this app in non production and you set environment to production, you really don't necessarily know what other behavior you're switching on and it could definitely be other behavior that you really don't want to have occur. So another good question that kind of arises out of this example is why is the app actually behaving differently in prod in the first place? Um Which is also another really good question. I think there's some sort of small examples where, where this is desirable when you're using sort of feature flags for, for either in development or or new features. But for the most case behavior between test and production should be identical. In most of the cases, I've seen this, I implemented, it's usually to wrap things like um email functionality or, or purchasing functionality where you don't necessarily want a real email to go out or you don't necessarily want a real purchase to go through. In these cases, I feel like the behavior should still be the same across all different environments. Um But to prevent real emails or real purchase to go out, they should be connected to mock services instead. Um Instead of doing this, this weird branching. The next example I'm gonna go into is um I guess the most explicit case of of hard coding configuration into code. Um And this again was another pretty common one. throughout services in, in Chumba Casino, we have um uh many of our, of our applications obviously need to know the base URL that they're operating on. Um And so there was um the easiest way in a lot of cases was to write this kind of function where uh again, keying off the environment, environment variable. Um and just returning a very um unchanging list of URL S. But again, um to ask some questions, what if I wanted to run this app locally on a different port one? That's not 80 99. What if I wanted to deploy this app into uh a temporary ephemeral environment? Um Let's say, as the result of APR build, um how would I deploy this to a, a temporary host name? You can't really do that with this code. Um It requires you to actually make code changes first and, and rebuild an artifact um which is obviously gonna revolve, involve a pull request. Um Potentially some unit tests, there'll need to be a review, that kind of thing, which is quite a lot of overhead for just being able to sort of spin up um AAA different environment to test something very specific out. And so this this concept of being able to deploy without changing artifacts is something 12 factor goes into a lot as well. It's kind of um phrased as being uh build once deploy many times and it sort of looks a little bit like this. So regardless of, of the the build artifacts that come out of your build process, whether they're docker containers, um maybe they're tar balls or executables. The idea that 12 factor tries to promote is you should be able to just build your application once and then deploy that to any environment that it needs to go to. So again, uh using the ephemeral stack example, I should be able to take uh the artifact from APR build. I should be able to deploy that to a temporary host name with temporary configuration. I should be able to run that exact same instance locally um and configure it so it will run properly um on the right ports with the right host names and things of that nature. The other cool benefit of this is if you're having a problem in production, you can pull down a cop the an exact copy of the build artifact running in production and troubleshoot that locally with just, you know, a few changes of config. Now one, I guess um uh disadvantage that I've heard talked about um when we're talking about the separation of configure and code is that it removes the actual values of config a bit further away from the developer when they're writing code. But I think um although 12 factor doesn't really go into specific detail on this. I think when we're talking about separating config and code, it's really talking about separating config from the build artifacts and not necessarily the code. I think storing config in source control right next to the code is often the best place to put it. Um So I just wanted to point that out a little bit as well because it sometimes can get misinterpreted. So there's to achieve this, I guess, good separation. There's two small things that I try and get the, the engineers in chumba to do. The first is to use environment variables. Uh For very specific discrete things, there's no longer uh an environment variable called environment. Um That's quite a very ambiguous in into what it enables. And instead it's very specific environment variables like database host name or maybe enable this particular feature flag, that kind of thing. The second thing is to have um a configuration object um built in a central location and I'll show you an example of that now. So in our apps, I've started to encourage our um engineers to uh in a single file um generate this configuration object. Um And, and this is the only place in the code that should really be reaching into environment variables. As you can see, this is a pretty contrived example just with, with two fields, but you can add sort of as many as you want. And it allows you to kind of set doc strings, set up any appropriate defaults if you want to, you can also do uh validation of configuration. And uh the other cool thing is it lets you properly type all the different configuration items. So in this case, I've got two strings. So it's not really um a good example. But if you've got more complex um configuration types coming from environment variables. Instead of having to always um manipulate a string type, you can convert that into whatever type you need to, to make uh things a little bit safer for, for the engineer then to use this, uh you just need to obviously grab that config um and have that happen um at a very nice and early point in the bootstrap of your apps. Again, this is a very small example, just running a an express service. Um But once it's in uh it's been included, nice and early here, the rest of your app can just refer to the config and not have to worry about uh manipulating strings in, in environment variables. Something else I'm gonna try and implement soon is a, is a linting rule. So um once this is set up, we can have a lint rule that checks for access to environment variables outside of configuration uh just to kind of drive that home. So when you're able to achieve this um separation of configuration and code, um you get kind of a lot of benefits. Um So the first one is, as we saw before, you're, you're able to kind of take any artifact, deploy it anywhere and um and test out very specific things under very specific configuration which um is is really good for testing and verification. But the other cool thing you get out of it is, you can start to sort of really reap more of the benefits of, of do a. Now there's a lot to really talk about uh for do a particularly around best practices. Um A again, I'm only gonna go into a small amount, but here's some links to some other um resources that I've personally used to help um level up how we, we use DOCA files and, and do a um at VGW. So next, I'm gonna show you um this pretty basic example of a Docker file, but a lot of our doer files are sort of starting to take a, a very similar shape um at VGW. So the first thing to point out is um we're now making use of multistage builds um and largely to um ensure that we can build the code um in the same uh execution environment as as the resulting image. Um But also stop building and installing dependencies on the host image and then copying them through. The other thing you'll see is we're, we're linting building and running unit tests all inside that Docker build. This is really handy because it kind of helps us um ensure that we can, we can build the app um and build an artifact. Um pretty much on any workstation we want um provided it's running Docker. The other thing uh I I generally recommend to people um is if they've got uh quite a lot of different stages in their multistage Docker builds is to enable build kit. Um It's surprisingly um a, a not that well known feature but it's a new build engine. Um that dock has um I think it's uh close to being um the, the default or being generally available, but it's still something you need to enable with an environment variable. But what it does is allows um better um paralysis paralyzing of um different Docker stages. So um even though this is AAA basic Docker file, we do have um four stages, but these two first stages um have no dependencies. So what build kit will do will run and build these two stages um simultaneously. The next two obviously depend on each other. So they need to be run sealy serially. But you can sort of see um the benefits you might get for a more complex uh do file. The other thing that um good use of um environment variables and do a allows you to do is really make the most out of things like do a compose, being able to spin up a full copy of your, your application with all its dependencies for things like um demoing to, to other developers running integration tests. Um And also having um those integration tests run in an ephemeral environment during your build pipelines. Again, this is another basic example of a do a Docker file, sorry, a Docker compose file that I've got in a in a small um personal project that I use for testing out um stuff. We've got a simple Postgres database, a flyway container that um sets up the schema and contains all our database migrations and then an API um image which is um built from the local docker file. Now, you can see um we've obviously um got good use of environment variables here. So this is able to be run with whatever configuration it needs. Once you've set this up locally, it then be again, like I said, it becomes very easy to, to run integration tests, particularly if your integration tests are running inside a container. Also something um I've used at least in this um hobby project is um running postman uh in a in a Docker container to run a handful of API calls across those apps. But arguably one of the more powerful things is being able to spin up um that Docker compose as part of your build pipeline and running build tests. So this is uh just a quick screen cap of of the build pipeline, the Docker compose image you saw and what this step here does is um it spins up that Docker compose file, runs the integration test. Uh And this happens on every build. Um And it happens quite quickly. Um As you can see, it only sort of took 43 seconds to spin up the app bootstrap the database and run through um a pretty big um heavy suite of, of postman tests. Um And then after this, obviously, um you can then push the image and push it through um a handful of real environments if you need to um or, or put it in front of real testers. So once you get a, a good handle on this, um that's when you sort of start to see uh your deployment frequency kicking off. Um And when you make good use of, of testing, unit testing and integration testing using uh you know, the, the the advantages of do a um your change failure rate should hopefully go down as, as problems get exposed earlier and earlier in the build uh build process. That's all I've really got time for. Um Thanks so much for tuning in. Um It's been a pleasure to, to present at the summit. So big. Thanks to Pulumi for giving me the opportunity. Also wanted to give a quick shout out to, to Lee Campbell who helps uh immensely um helped me immensely put this uh together. Like I said, this is the, the first time I've presented externally. So I'd really like to hear your feedback if you can hit that link on the, on the slide there. Other than that, I hope you enjoy the rest of the summit. Uh I'll see you later.

---
