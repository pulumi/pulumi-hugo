---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Cloud Engineering Summit 2021: Bringing software development practices to your infrastructure"
title: "Cloud Engineering Summit 2021: Bringing software..."
meta_desc: |
    The cloud makes it easier and quicker to provision infrastructure at scale, but there is added complexity with that scale. By bringing practices fr...
url_slug: cloud-engineering-summit-2021-bringing-software-development-practices-your-infrastructure
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Cloud Engineering Summit 2021: Bringing software development practices to your infrastructure"
  description: |
    The cloud makes it easier and quicker to provision infrastructure at scale, but there is added complexity with that scale. By bringing practices from software development like test driven development, automated testing, and continuous integration/deployment to manage complexity at each stage of the pipeline, you can build and manage your cloud resources more effectively, consistently, and more securely.  Talk by: Jenna Pederson
  sortable_date: 2021-10-20T23:01:50Z
  youtube_url: https://www.youtube.com/embed/PgmsiIfbC64
transcript: |
    Hi, everyone. Thank you for joining me today at Cloud Engineering Summit. My name is Jenna Patterson and I'm a software engineer turned developer advocate at Amazon web services. I've been writing software for over 20 years and today I'm excited to talk to you about one of my favorite topics, software development, best practices, or more specifically automated testing. So let's just levels side a little bit. Infrastructure is code, lets you automate deployments of your infrastructure to facil facilitate scaling and quicker repeatable deployments and it's code. So because infrastructure is code is actually code, this means that you can version control it, code, review it, test it, push it through the different stages of AC I CD pipeline. But what happens when something goes wrong? So it might work on your machine or your account or your region. And you've probably already gotten this works on my machine badge. But when it's broken, it's broken at scale, the blast radius is much wider and it impacts more resources, regions, customers and dollars. So in the next 20 minutes, we'll talk about treating your infrastructure as code as code and minimizing that blast radius. We'll talk about the different types of testing using test drive and development to make sure you're building what you need and only what you need. We'll talk about testing your infrastructure directly. So what's provisioned to make sure it was created correctly? And then we'll talk about integrating all of this into AC I CD pipeline. So we know that the cloud makes it easier and quicker to provision infrastructure. But there's complexity with that scale infrastructure as code is one way that we manage that complexity. Automated testing is another way we can manage it by building quality in from the start. Just like we do with our application code, we can have confidence in our infrastructure at scale and at velocity. So when we talk about bringing testing to our infrastructure, it's still really important to consider the different kinds of testing to use just like we do when we build a test strategy for our application code. So this is a variation of the testing pyramid that's been around for years. Tests at the bottom of this pyramid are cheaper and easy, easier to create and they give us quicker feedback as to when something has gone wrong, they're more finely grained and generally should be testing only one thing or a unit tests at the top of the pyramid are more expensive to write to run and they're more brittle and harder to maintain. In the case of infrastructure testing tests towards the top of the pyramid are more complex because it involves spinning up and tearing down cloud resources and tests that have to query that infrastructure. So we really want to balance fast and cheap tests with those that are closer to the real infrastructure and production environment and therefore reflect reality. So if you're test driving your application code, why wouldn't you do the same for your infrastructure code? So remember some of the benefits of test urban development are that we have reduced defect rates. We can improve the overall design of what we're building. We can uh test drive and development. It keeps you focused on requirements. So you only implement what you need and nothing more. It keeps you focused on small chunks. So you make sure that just those chunks work and it can also serve as documentation. So communicating requirements to your team and then finally, it gives you confidence in what you're building. So this is the flow for test driven development. You can follow the same red green refactor that you do. When you write your application code first, you write a failing test, then you write only enough production code to make it pass and then you make it better in the examples that I show in just a little bit, we'll follow this approach. So let's talk a little bit about those cheap and fast. Unit tests a unit test exercises a small part of your application or one unit and it verifies that it's correct unit tests are quick, they can be run frequently and they help us get feedback early on. So we can shorten that feedback loop. They help us communicate requirements to our team as well. They can also be run in your C I CD tool. And then finally, traditionally, unit tests are isolated from other resources like external API S and databases. And this reduces the scope and the number of variables that can affect the results. We can also apply the same process to infrastructure code. We don't need to provision all of our infrastructure or even a little part of it to test that our code configures it correctly. Now, a unit check test checks if a resource will be created with the correct configuration, it checks that the number of resources is created, the correct number of resources is created. It checks if the dependencies between resources are correct and then it checks if interpolated values are correct. So let's see this in action for this first demo. I wanna show you that it's possible to test drive your infrastructure code for context. This is an Aws cloud development kit or CD K app. And we wanna create a private S3 bucket with encryption enabled by default. We're gonna write a failing unit test with the just framework. We'll write our infrastructure code, which is our CD K code and then we'll make sure that our test passes. So the first thing that we're gonna do is write our test. So we've already got this stubbed out. I'm gonna add a code to create the S3 bucket stack that we're gonna write in just a minute. So I give it an identifier as three bucket stag. And then I'm gonna add some expectations on this stack. I wanna make sure that the stack creates an S3 bucket and then I wanna make sure that this bucket has a bucket name and I wanna make sure that bucket encryption is enabled by default. And then lastly, we, we're gonna add this uh import for the stack that we're gonna write in just a minute. So if we go back to the terminal and run our test, we can see that there's actually a compilation error here and that has to do with this import that I just added, it's failing because we haven't created our production code yet. So I'm gonna go ahead and create the S3 bucket stack file. We create the class and we'll implement uh some of the boilerplate code specifically around the constructor. And then inside of this constructor, we're actually gonna, this is where we're gonna create our resources. So we're gonna create a new S3 bucket. We'll give it an identifier and that identifier is for how we reference it in this code, we give it a bucket name and we'll block all public access. And now that we have our test, we can go back and run that again to see if it passes and it turns out it doesn't pass. We can see that it's missing bucket encryption. We forgot to do that. So now we're gonna add that encryption back in to fix our test. So we add properties to indicate that we want bucket encryption to be enabled by default. And then we'll rerun our test and we can see that it's passing now now that we have our infrastructure code and it's tested, we can apply it to create our resources in the cloud. We could go into the AWS console to check on the state of those resources and manually verify that they were created correctly. But how do we know that it's really correct? And how do we know that it's what we wanted to create? And more importantly, how do we do that at scale? Can you imagine having to manually check 100 S3 buckets across across different regions and accounts to make sure that they're set up properly? That's a lot of manual work. And if you remember our test pyramid, manual tests are expensive and time consuming. So if we want to limit them, and this is where integration tests come in. So integration testing is a form of testing where we test the in interactions across different units or modules or in the case of infrastructure testing, we're testing across different cloud resources. They allow you to verify that your provisioned cloud resources are created and configured as you expect them to be. So as I mentioned earlier, the cloud makes it easier to scale but it adds complexity. So integration tests can give you confidence in your infrastructure at scale and at velocity. So in the next example that I'm gonna show you, we'll use chef inspect, which is an open source framework for testing and auditing your infrastructure. You can execute and write tests with an easy to read, domain specific language or DS L on remote systems like servers, containers and cloud resources. These tasks can be used on any machine or resource regardless of whether it's managed by shelf the AWS CD K, Pulumi or even manually by a human, they can be used across teams too. So for instance, your security team can set up their own rules and impact levels. And if tests pa can fail or pass based on that impact level. So in this demo, I wanna show you that it's possible to test your infrastructure directly and you can even test drive those tests along with your unit tests for context. This is another aws CD K app. There's an EC2 instance and some related resources already tested and provisioned. And now we wanna add a database to the app. We're gonna write a failing test with the inspect framework. We'll update the infrastructure code and then we'll make sure both our unit test and infrastructure test pass. And if you're familiar with our spec unit test from Ruby, these in inspect tests will be familiar because inspect is built on top of our spec. So the first thing that we'll look at here is the unit test that we've already written. We are making sure that we have an EC2 instance configured correctly in the stack, an elastic I PC configured correctly in the stack. And then we're also making sure that we have an R DS database and it's configured correctly. Uh The last test that we have here is to make sure that we have outputs from our stack that we can use in our inspect tests. So we go back to the terminal, we run our unit test and we do have a failure specifically on the R DS database instance. And that's because we haven't implemented that in our production code yet. So if we go back and look at our production code, the stack app, we've configured our EC2 instance in here and the related infrastructure, we've added uh a web app security group with different ingress rules, uh the elastic IP address and we've also added some outputs uh the instance ID and we've also added a web security group ID that we'll use in our inspect test later. So we've already created the inspect control and here we're setting the impact to one. We've given it a title, we're importing those outputs from our stack so that we can use them in this test. So I mentioned in instance ID in web security group ID before. And then we're also making sure our EC2 instance is running. It's the right image id and instance type. We've, we're also making sure that the security group uh has the right um allows the right traffic in. So we'll update this, inspect, test to add our database verification. And we've added the instance identifier and database security group id from the outputs. Uh We're gonna make sure that our database security group allows the right traffic in. So Postgres X traffic on port 5432. And then we'll also add a test to make sure that the R DS instance is set up and configured correctly. We wanna make sure that in this case, we're just gonna verify that the engine is correct. The engine version is a specific version and then we've used the right instance class. So we'll go back to the command line, we will run our inspect tests and we can see that we have one failure. And again, this is because we don't have our production code implemented specifically. It doesn't know where those parameters are to use in our test. So we import the AWS R DS library and we're gonna add some um code in here to actually create our database instance in our, in our stack. So we've uh set up the subnet, we've given it an instance identifier, we've set the engine and engine version. We've allocated some storage, we've given a given it a tag. And then we're gonna set up uh the connections or the security group so that it allows traffic on a specific port 5432 is what we're expecting here. And then we also want to add an output for this database instance identifier so that we can run our tests, our inspect tests specifically. In addition to the database identifier, we'll also do the database security group id so that we can uh run some tests against that as well to verify that that's set up correctly. So now that we have our infrastructure code actually written, we'll go back to the terminal and we're gonna run our unit test to make sure that we've implemented our production code correctly and it looks like we have and then we're gonna synth synthesize the CD K app and deploy the CD K APP stack and we'll pass in a couple of parameters here and then we're going to set the outputs file uh to be a specific file that our inspect test will be able to read from later on. And this takes a little bit. So it's sped up. Uh And when it's done here, we'll see that it's successful. It's created our full stack app, it's output that information and now we can run our inspect test. So this test again, it's going directly against our AWS resources and we can see that our R DS database it now exists and it's configured correctly. You might be wondering, Jenna, we've built all these infrastructure tests. Now, what do I do with them? That's a great question. Today. Your process might look like this. If you're not doing any sort of infrastructure testing, you find your issues in production or maybe you don't find them at all and your customers find them infrastructure as code plays a key role in C I CD. And it relies on infrastructure automation to create consistent environments. So you can be confident that what you've built works in each environment and for your customers. When you automate your infrastructure tests, you can also put your infrastructure code through the same C I CD pipeline. You can iterative develop, run these automated tests and then deploy your infrastructure through each environment just like you would your application code by moving our infrastructure testing earlier in the pipeline, by shifting it left and doing it at every stage. You're going to find bugs earlier in the process when they're cheaper and easier to fix. Now, I just wanna leave you with a few parting thoughts. First of all, infrastructure is code, we should be treating it as such. We code, review it version control it, test it, push it through the C IC B pipeline. Second, even if you're not testing in production, your customers certainly are. And last the earlier you catch bugs, the cheaper it's going to be to fix. Thank you all for joining me today. If you have any feedback. Please take the survey at this QR code or send me a message on social media. Um I appreciate any questions and a follow there as well. Uh And I'm looking forward to the fireside chat next. Thank you.

---
