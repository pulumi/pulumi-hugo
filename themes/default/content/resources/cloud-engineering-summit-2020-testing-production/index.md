---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Cloud Engineering Summit 2020: Testing in Production"
title: "Cloud Engineering Summit 2020: Testing in Production"
meta_desc: |
    Testing in production: it's gotten a bad rap. People seem to think it's all about irresponsible YOLO-ing and taking shortcuts around the sacred pro...
url_slug: cloud-engineering-summit-2020-testing-production
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Cloud Engineering Summit 2020: Testing in Production"
  description: |
    Testing in production: it's gotten a bad rap. People seem to think it's all about irresponsible YOLO-ing and taking shortcuts around the sacred processes that you rely on to catch bugs in staging, before they make it to prod. Nice theory: completely wrong. Staging areas and controlled environments will never turn up the interesting bugs: that takes real data, real workloads, real concurrency and real chaos. In other words: production.  But it gets worse! Staging isn't harmless; it's a black hole for limited engineering cycles. By sinking time there you starve yourself of the cycles you should be using engineering tooling and guard rails for production.  Production is quite literally the only environment that matters, so every moment you spend working anywhere else is time spent absorbing the wrong instincts, running the wrong workflows, and gaining more false confidence in your code. Only production is production, and the only way to gain confidence in your code is to bake it in production over time and a range of workloads. So let's talk about how to do this responsibly -- without impacting your users â€” using tools ranging from capture/replay to canaries, production load testing to chaos engineering, and the instrumentation-based observability that must brace and validate every effort if you plan to sleep well at night.
  sortable_date: 2020-11-11T00:29:30Z
  youtube_url: https://www.youtube.com/embed/iULct6-IAFQ
transcript: |
    Um this talk is about testing and production. Um I test in production. So do you, everyone does it, everyone does it um whether they admit it or not. And I actually feel like the problem is not that we do it. It's not that we test in production as a problem. It's the fact that we're too ashamed to admit it, which prevents us from naming what we're doing, identifying it um and improving upon it. Um Things that happen in the dark don't tend to improve. My name is Charity Majors. I am an operations engineer by trade. I am the co-founder of honey. Um The world's first observable tool. Um I have spent a career of being the first infrastructure engineer who comes into a small team of software engineers and helps them grow up. I really enjoy doing that. Uh I do a lot of databases stuff. I wrote the Database Reliability engineering book with Lane and uh list Functions and I have the observable book coming out for o'reilly in the next few months. Prerelease copies are available now. Um And you can tell that I'm from apps because this is how I feel about software. The only good diff is a red, red diff testing and production has really gotten a bad rap. Um I mostly blame this dude. Uh I feel like it's, it's a funny meme, it, it, of course it is. I used to have this poster on my wall. It's hilarious. I don't always test my code, but when I do, I test in production, that's fantastic. Um But there's like, there's implicit dichotomy there where it's like this false implication that testing in production somehow implies that you don't test in any other ways. Um In fact, you can do both and, and you must do both and, and I would argue that testing and production is no less important than unit tests, integration tests. All that jazz. In fact, if I had to choose only one and I do not, let's make that perfectly clear. I do live in a world where I can have both. If I had to choose only one, I would go with the ability to test in production because it is the one that is most embedded and grounded in reality. Uh If I could only have unit tests and integration tests and had no ability to look at my software while I was running, uh I would be worse off than if I could not do unit integration tests. Um But I had full access to a range of rich production testing and stuff. Um But like the, the idea that you can only have one or the other or, or that, you know, good engineers do one or the other is, is wrong, is misleading and it makes energy, it makes people waste energy in the wrong places. Um But like given that we all do it and given that like officially like any time that anyone ships any change, um that change is a test, right? There's a unit there of irreducible complexity made up of that unique and non repeatable intersection of artifact, deploy process, you know, environment system state, everyone does. If you have production, you test in production. So what's the big deal, right? What's what's all this fear and fuss about? Well, when you say test in production, they tend to hear this, you know, they hear cowboy coding, they hear people logging in just getting a root shell in the database and like hand editing the table schema, right? They hear you not giving a shit about your users and to be clear, those things are really bad. It's fine for knees to jerk a little bit over that testing and production, like any powerful thing like can be done really badly um really easily uh pretty much anything you do in production. I could fall under this category. Um I, I would, I I would actually argue that the ability to successfully and safely test in production requires a significant amount of architectural and automation and sophistication. Um firm understanding of the best practices um the ability to, to design systems and tweak them from the ground up to let themselves well, to this form of testing, it's not like you just flip a switch one day or you just buy a tool and suddenly you're testing and prediction. Well, no, that sounds really scary and that is not possible. Um Some caution is wise. Uh And it's also true that in some ways you must be this high to ride this ride, you know, like Sam Newman who famously or Martin Valley who said that about micro services, uh you must have mastered the fundamentals in order to move on to the advanced concepts. Um You must have mastered unit tests and integration tests to be able to move on to actually running, you know, continuous 20% load tests in production on the same hardware as your production services. Um You need to have a really strong background in operations. I I think in order to both build the systems that can do this, to do it successfully, to know how to use them. And then to pass on that knowledge throughout your, your your internal tribe, you know, like each one, each one of our systems is this really complex, wonderful, beautiful little snowflake, right? It's, it is an intrinsically unique complex socio technical system. And what that means is you and I can learn broad principles from each other. We can tell specific stories, but the interpretation of those stories and the application of those techniques is to be left up to, you know, the hearer, the recipient because your system is not my system. I don't know what's best for your system. You don't know what's best for my system. Um So a fair dash of humility is often required too because, you know, we, we can tell you what the rules are all day long, but rules are made to be broken. So and again, it is never a substitute for preproduction testing. You can have both. I always test my code and then I test it to get in production. This, this is the man we need in our life. This I, I started getting, talked about, you know, testing and production uh three or four years ago, mostly I'll be perfectly honest because it made people lose their shit. And I found that hilarious. Um uh it, it seems to push people's buttons a little bit less these days, which is probably good, but it also makes it less fun anyway. Uh I don't think that this is just a fun argument over a provocative phrase though. I think that it is really kind of a struggle for the soul of our industry. And while there is no question in my mind that my side will win, there's quite a lot of variance in like how quickly we can win. How decisively how many engineer, you know out there today, like so many engineers are, are burning themselves out. They're, they're giving their all, they're, you know, they're going through the fire, they're going through hell. And it's not necessary. A lot of it is not necessary. And that's what wakes me up every day is, is the, just this burning anger at how much of our lives, how much of my life was wasted on bullshit that I didn't need to do that. A computer should have been doing or that, you know, this profession can be very inhumane at times. I love it. I can't. People always ask, what would you be doing in tech if you weren't tech? I'm like, I don't fucking know, like obviously I'd be in tech. I was born to be in tech. Um But we need to make it more humane. We need better tools and production itself in general, I think needs a bit of a rebrand. Uh uh You know, we, and we, we were so terrified, you know, of our monoliths going down and any time a bad actor showed up that we became very non welcoming, shall we say? Uh very like stand back my turf, I'll cut you if you tear a step on it. So we've got some, we've got some ground to make up there as well. Um I really feel like we should try to make production less of a glass castle, right? And make it a little bit more of a adult playground, something like that. Software has some pretty big problems. Um I assume you all are familiar with the door reports and, and with accelerate. Um We get the canonical four questions. How often do you deploy? How long they take your code? You go, go live. How many of your deploys fail? How does it take to recover? I would add 1/5. I think every team should be tracking these five, the fifth being. How often are you paged outside of work hours? I think every manager should be graphing these, you should be looking at these at least weekly to, to see if you're headed in the right direction, in the wrong direction. Um And if you haven't read accelerate, I assume all of you have, you seem like smart people, I can't see you but you see like smart people. Uh but like the key finding from accelerate was just that, you know, uh these, these first four metrics could tell you how, how high performing a team you are or roughly for most people. Um And furthermore, you can become a more high performing team by juicing those metrics by, by teaching to the test right by like by making it so that, you know, your deploys go out much more quickly after your code was written, making it so that they, you know, blah, blah, blah. Um I'm gonna skip past the rest of that in order to just show you my, the, the main thing I wanna focus on which is just that there's a big gap between like the quote unquote elite teams and the rest of us. Um And it's getting bigger. Um And if you look at those numbers like deployment time on demand, multiple deploys per day for elite once per week to once per month, from low to medium, that's a lot of wasted hours. That's a lot of time. Some engineers are spending, not doing anything interesting or new, not focusing on learning new skills, not doing anything to move the business forward. They're just fighting against the tyranny of their own internal systems. All, almost all of it is preproduction, spoiler alert. Um It's big and it's getting bigger and we waste a lot of time. This is the Stripe developer report. I recommend spending a few minutes of this if you really want to be shocked, sober or, or whatever the equivalent is for you. We waste so much time on, on stuff that doesn't move the business forward that doesn't move, that doesn't make you learn anything new. It doesn't make you create anything interesting. It's just simply doing the work that you have to do in order to get to the work that you want to do. It's reproducing bugs, errors, figuring out what to do, doing the wrong thing because you couldn't see what you were doing. Having to redo it all dealing with technical debt, orienting yourself in time and space, figuring out what the last people to work on this code base were doing. Um you know, the glasses metaphor comes into play big time here. Like if you can't see where you're going, when you drive down the road, you don't drive very fast, right? When you've, when you've, when you've got full visibility, yeah, you can sit back and cruise. Your feedback loop is gonna be long and lossy and you're gonna spend more time just studying yourself and looking for, you know, evidence that you're still on the right path than actually doing the work. What's messed up is that we think this is normal, that we think that this is just the way it is. If you've got a job doing software, it's not normal and it's not inevitable. And basically the, the whole theme of this talk that what I want to talk about is just how do we get there because, you know, it, there's this enormous shift underway, test, testing and production is, is part of it and we're gonna talk about that a bit, but it's not all of it by any means. And, you know, the delta that you see and the, the elite teams that are just ballooning and reaching escape velocity. These are the teams that are leaning in and adopting all of these new best practices and tools around production. Um These are the, these are the teams that are abandoning all the wasteland of crap that, you know, yeah, we'll get, we'll get to that final takeaway from the stripe report, 42% 42% of the average engineers have the average engineers not even like that. There are people who are way worth it. Half your day, half your week, half your life goes to bullshit. I think we can do better. Um And for individuals like it really pays off to be a high performing team. I I th this is not a question of how good are you as an engineer? That's not the difference between high performing teams and like elite 1000% guarantee. It's not because I've been on the both sides of that. It's about the team, it's about the context of the team. It's about, you know, the hoops that you have to jump through in order to get a pull request accepted. It's about the strength of your C I CD pipeline. How automated it is, how good you have automated error checking, like all the stuff that enables you to move quickly with confidence, that's what makes you a good engineer, right? It's not, it's not that you get to become an an, an elite team by being the best engineer. You get to become an elite engineer by finding one of the best teams and joining it. And what are those elite teams doing? They're investing in production observ ability, instrumentation, picking up the pace shrinking the time to deploy, you know, educating themselves, making sure that every person on the team is production, literate is production capable, can follow, can sit here, you know, writing code knowing what they're building. They've got, you know, that original intent up in their head. It's beautiful and then they hit, they save their code, right? They merge it to, to Maine, they stand up and stretch a couple of minutes later it's in production and they go look at it using the same eyes that they just used to write the code. They go and they look at it through the lens of the instrumentation that they just wrote. Ask themselves, how am I going to know if this is working when it's in production in a few minutes? And then they go and they look and they ask themselves, how can I know if it's doing what I wanted it to do or not? And you know, what does anything else look weird while I'm here? If you can get a team full of people who can do that, who are trained to do that, who have learned to associate dopamine hits with doing that. Um You're going to be doing well by the way, the Honeycomb team um are do and metrics are about an order of magnitude better than that of the elite performers in this bubble. And we did not go out and hire all of the best engineers. We hired good engineers who were good at communication, who were, who like learning new things, who were collaborative and who wanted to pick up this crazy shit. We were trying to sell people on, you know, observ. And now there's some of the best engineers in the world. It didn't start out that way. That's because that's not the direction that, that causal loop goes. If you're on a shitty team, never mind. This is not my excuse to tell everybody to quit their jobs. That's a different topic anyway. Um, there are a few different ways though to talk and think about running in production. There's more than one way when, when I, when I say, you know, get your shit into production, I don't mean make sure everybody sees it immediately after you write it because you're right. That would be stupid. Um There are three ways and I grabbed this from one of Cindy. Cindy's great articles and testing and production because I really liked it and it really maps to the way I've always thought about it, which is, um, oh, and she grabbed, of course from this, some great articles on the dearly departed. Tur Turbine Labs had some great writing about releases. Um So for deploys, here's how they, here's, here's how they defined it. It is the process for installing the new version of your services code and production infrastructure. No, that's not like for reimaging all of your, all of your, you know, everything, everything from scratch. It's your business logic, right? Your code that you're actively developing, um, deployment doesn't have to expose customers to a new version of your service, right? And it probably shouldn't, nevertheless, you're getting that code into production, right? That counts, it totally counts. Um One thing this does very nicely is it minimizes it possibly even entirely eliminates the need to maintain separate DEV test and taking environments um which is then invariably become dependencies that need to be kept in sync with production, which takes up half your engineering time. And is Ila um it also applies a certain like design pressure on engineers to decouple their services in a manner so that the failure of a test run and production on a given instance of a service does not lead to like cascading failures or user impacting failures of other services, right? Um Designing data models and database schemes to be like non ident requests, right? Especially rights um baking all this stuff into your, into your, your tooling and in the way you, you write code is, is it is it is life changing. Um And then there's uh what they had to say about release releases. And often people say deploys when they mean releases and they say releases when they mean deploys less often. But um if you've been around the block a few times and seen some so we get just like deployed a few times. Um You probably have some scars from it, which are legitimate. I would never take that wisdom away from you. Um The ability to like safely release code is one thing. But then the ability to in a, in a, in a controlled manner, like expose like increasing waves of people to it is a different issue and things that come into, into play here would be feature flags, um would be like canary groups, um you know, rolling groups of users. Um and you need to worry about this, both of the front end sake. You know, the UIUX, maybe you want to like start with a canary group that you selected because they're friends of friends and family or, you know, they're internal users or something you want to deploy to them first, see if anybody knows it's anything, then you wanna like roll it out to other users. Um There's also a version of the story though that you need for the back end because, you know, say you're deploying a change that, you know, is gonna be hitting the cashing layer a little bit harder. Um It's not enough to just do a canary of, you know, 10% of your hosts and then like deploy the rest. It's not even enough to like deploy slowly up to 50 then turn the rest, right? No, it's actually that last 10 2030% where you're most likely to encounter any. So, shall we say edge cases? Right. So we're just getting a lot of different kinds of controls here. This has been being referred to um by um Monk chips and others as progressive deployment and it was really itching for our name. So I'm delighted to see that it has acquired one and then there's post release, these are often called experiments and I will not lie. I have uh done a string substitute from test and production to run some experiments more than once to get a buy in from other teams or higher ups. Um And the thing you remember, like after you've shipped your code is that it's broken, it's already broken, it's broken whether you know it is or not, right? Like your distribution system exists in a continuous state of partial partial de degradation. And that's the best case scenario. Uh So this is where we get into stuff like, you know, cast engineering fault injection A B tests, you know, all these different kinds of experiments. Um And Cindy had this really great little uh list that I have kind of copied some stuff from here about just like what we're talking about. So there's a wide range of risk profiles here, right? A a wide range of types of tests. And you can see right, how, how by confining yourself to, you know, everything that happens before you hit merge. Look at this incredibly rich world of powerful tools that you are starving yourself up for. You know, there are so many things you are never going to encounter in staging. You just won't like even the gold standard is what we are, you know, and I will, I will point out that the closer you get to laying bits down in disk, the more paranoid you should be and the more preproduction testing you should do. So, for example, any time you've got a database major version upgrade, you bet your ass, I'm gonna do some offline testing. Um In fact, I have written this particular piece of software not once, not twice but three times um for three different databases for accomplishing major up version upgrade safely where all it does is just sniff 24 hours worth of traffic to the database. Um And then, you know, they've captured it and then it replays it against a snapshot of the database that was taken at the time that you began sniffing the queries and we then just run it all and adjust certain knobs like concurrency and, you know, transactions and number of like, you know, whatever. Um Just to see like is it faster or slower than my old version was for this workload? Nothing else matters for me for my workload, which means that no, like standard off the shelf bench, bench test, benchmark testing tool is ever gonna work, you know, gold. Even if you had that for your entire treated system, it would still not solve the, the Michael Jackson problem where one day Michael Jackson is alive and the next day he's not and you couldn't have predicted it. I I assume you need to not kill Michael Jackson. You could have predicted it. You probably shouldn't try. Like this is where you start to just see like the, the wisdom and just giving up control. Right? Is very Zen. It's very Buddhist. It's also just what you do when you're exhausted from trying. Just like I give up, I can't predict what's going to happen. I officially quit trying. That is, um, and I will just learn to get better at handling whatever the hell does happen, right? Um And therefore, you know, from all that, we got micro services. So you could say it's a blessing. I don't know. Um OK, you know the answer, you should experiment and then you can under controlled expe uh conditions. Um This was Sidney's super cute graphic and I found like the Twitter thread and I was referring to this as like the fourth trimester, which is this term from, you know, evolutionary biology about how human babies are born so weak and helpless and dumb and they just stand there squaw all the time and breaking constantly and they've got all these terrible failure conditions. And so I just got to run around like picking up after them all the time. They grow, they slowly like stand on their own 2 ft and that's your, that's your code is what I'm saying. Your coat is like a newly newborn baby that's shitting itself all the time and needs to run around after it cleaning it up, it would be incredibly rude for you as a new code parrot to just go, ok, have fun. I'll be back with another code baby in you know, a week like that's not cool. They didn't consent to that. You take care of your own code baby until your code baby can sleep through the night and wipe its own ass. I that should have just been the talk right there. That's enough. Um Nevertheless, so that time, so let's talk about some things that people say about staging that drive me bat shit. Um Naive staging questions. Why test in production when you could just be testing and staging? Shouldn't you always like default on the side of adding more confidence by testing and staging though? Isn't that just the mature responsible same thing to do or my favorite? We prefer to find our bugs and staging, not production. OK. Oh grasshoppers, this is like the I I call it the the more sta staging is always better slash safe for bias. Um And it seems to rain unquestioned but very stupid. Sorry. That's not very nice. Um unexamined people live in the unexamined life over there. In fact, anyone who's spent any time at all with staging moments knows that um you can decrease confidence by running it in more staging environments just as well as you can add confidence because very of very of let me, let me emphasize very, very, very very often something will break it, break in production and will not break in staging and just as equally likely things will not break in production and will break in staging. And you can choose to spend the rest of your life chasing down differences between the two environments and realizing every time that it was, oh, the instance type? Oh, it's the network. Oh, it's the fact that I can think file is different. Oh, it's the environment. Oh, it's I ask you to ask yourself, was any of that? Moving the business forward? Yeah. No, no. Uh Another claim that I find naive and laughable is we keep staging and sync with production. It is a representative environment. That's why we taste test and staging so that we can be sure to which I would say no staging is far more incompetent with your laptop than it does with production. Um And if you're a fan of mythical creatures, maybe that explains your devotion to the environments. Staging facts of life, non prod environments will never look fail or behave just like p prod. Each additional environment will surface as many novel bugs as production does and you will have to repro on all of them. Uh The best way to find, assuming what you care about is bugs in production. The best way to find those bugs. The only way to find most of those bugs is to consistently practice observ ability driven development and let slash allow slash force slash, you know, two sides of the same, same coin allow developers to own their software all the way out to watching users run it in production. Nothing to do with stadium performance. But ultimately, you're gonna find most production bugs in production and, and, and here's the thing, I'm not saying staging is worthless. I'm not saying that at all. I'm not, I, I'm not trying to get you to stop using staging. I'm not, I think it has some really valid use cases. What burns me is when I see production get the leftovers, when I see engineers slogging away for days and weeks trying to get these environments to match up, trying to figure out the differences in the environment, trying to bring up another stage environment trying to bring up I should you not a staging cluster for each developer, the quantity the the hundreds of years of developer energy that have gotten into these, these stupid things over my life baffles like bottles the environment, the the imagination and but then like we come down to like building some guard rails into production, building some better tools for production, getting some sweet, sweet software engineering energy to like really tend to production, to shrink that sea, to fulfill the promise of continuous delivery. And it's like, oh no, we don't have the time. Oops, that's not gonna fit into our sprints. That's not one of our goals that we've, we've spent all this time we have lost at gambling the dice on saving. So we've got nothing left to put in our, in our savings account in production. All I'm asking is that you reverse the order of importance. All I'm asking is that you start taking production seriously, that you start putting it first, that you ask yourself, how can we give our engineers what they need to really understand what their code is doing while users are interacting with it in production? What do you need? What kind of visibility do you need? What kind of observ ability do you need? What kind of instrumentation must you do? What kind of tooling must you adopt? What kind of shiny young upstart startup name named after, sorry, I'm doing that really badly, whatever, you know, just like know what you want, have ideas, try them being unafraid to fail, be unafraid to sink that kind of devotion into production. He and feel that it is yours. You know, I feel like sometimes software years haven't really yet made, made the lead to like embodying that personal identification with it being done well, right? Because it's his job, you know, and I actually care less about you actually getting paid and woken up to. So for years and I care more about you feeling that ownership and that concern in your gut. It needs to be your baby, your squalling naked baby on the floor because it is, it's your baby where was I right? Production. Um All I'm asking is that you give the crumbs to staging because if confidence is what you're looking for, production is how you get it. And I just ranted through the entire like second half of that. Like, OK, you have, you are constrained. The engineering cycles is the scarcest resource in your firm. I know it's my scarcest resource too. Um And it can feel galling to spend lots of developer cycles on what feels a little like Nav navel gazing. But it's not, it is an investment account and the glorious inner first National Bank of Technical debt um going faster is safer, right? That's what we learned. So also like Katie mccaffrey gave this great talk of papers we love, there's like there um where she showed that you can catch 80% of the bugs with 20% of the effort and you should, where you're gonna catch him, use your energy and staging. I started writing something here and I realized it was almost a haiku so that I needed into a Haiku staging. It is awful. Um a brief note on observably because the shift from, you know, these tightly controlled staging environments to um you know, the more loosy goosey, you know, production. Also, I I it it, it tracks our ours industry's shift from monitoring to observ ability, which is the direct consequence of our shift from known unknowns to unknown unknowns, right? Um Once our architecture our infrastructure stops looking like that lamp stack on the left and starts looking more like that national electrical grid on the right. Um You're inviting so much chaos to live in your house that you just have to cede control, like you just have to just keep your sanity, right? You just have to go. All right. It's yours. Um It's a, it's a simple function of complexity. Um But that means you need real observ ability, right? To do it. And just like chaos engineering is a form of testing and production. I've been saying for ages like if you don't have observable, all you have is chaos and not the engineering part, just the chaos. The reason that you need observably with these very specific and and I'm trying to be very specific because it's not about this vendor, that vendor that too, it's about can it do the job? And if you can't break down by high cardinality dimensions, if you can have high dimensionality, what you can't do to a level is compare um this test that I just did this experiment that I just ran this cast, they just injected with the baseline, right? You have to be able to compare those exact exact rows with the baseline rows and see exactly what is different. And all of the things are 50 different things different about these errors than, than the base side. I need to know that is one thing different. I need to know that these are the things that will get you that it is life changing. It is a great leap forward. It, it is, it, it is what allows software engineers to speak to systems, the language that they understand the language that they speak all day long, that the language of variables and function names and api end points. You can't expect software engineers to like translate to low level systems and you know, this not, you know, all the stuff in the slash pro and everything. Well, software engineers can't and they shouldn't have to, they shouldn't be able to integrate, interact with their code at the level of observ to be able to ask the simple questions. I just injected this test. What happened? Right. High cardinality is not a nice to have, you must be able to break down by like one in a million things and then break down. Yeah. Right. OK. So you get the picture I've written more about this. Uh I just want to emphasize if you try to do this with a monitoring tool, you will be sad, you will not get the intended effects. So because because because again, you'll just be firing off very sophisticated tests and then driving down the road with the blindfold on because you can't see what he's doing. All right, I made my coin wrapping up testing and production. Why I think you should care about this. Um This is just 11 you know, one side of the elephant, you know, the industry ride shift is is is like the center of gravity, gravity is swinging towards production for everyone. Um It's hard to get right. It is advanced, it is not as easy as running a lamp stack was absolutely will not argue with you there. I will also not argue with you about, you know, you can't just drop things, things on people. It has to be a process, you have to do it step by step, you have to have consent, you have to have buy in, you have to have excitement, you have to have results. But if you can get here, it's so much better for everyone. Like the competitive advantage of being able to move this quickly to, to not have to retrace ground over and over, going back to like fixing bugs and like, you know, redoing work and like refactoring. So, you know, it makes all the difference and it's hard to explain until people have seen it. And so I'm just gonna assume that I made my point and, and move on. Um If you're on a team that you do not, that is not high performing as you know, uh uh according to the door metrics, not according to me, um I would be antsy if I was you, I would be trying to get out of there and find a place that um could bring me up to a higher level because that's how that shit works. I'm sorry, I keep trying to, um do you treat your deploys like the mission critical product that they are? This is another really important thing. Deploy code is production code just like every feature that you write. Every manager should watch your metrics, you accountable. Every software engineer should be on call. That's my personal belief. There are ways to accomplish uh ownership and, you know, responsibility without, without that necessarily they're not as good or like the whole, the whole play is to hook up really tight. Um, feedback loops that are not lossy. Right? So, the people who have the power and the context and the ability to change something are the people who get the alerts and they make the changes just like that and everybody's happy, right? Not, it takes months and gets baked into being the new normal. Um, this is table steaks like, uh, if you don't like this, um, if you're a software engineer don't go work on a 24 7 available service. Easy. Plenty of those. Um, it's also a question of, of, of training, bringing everyone along, right? You don't just drop them in the deep end and go so long. Suckers, right? Just everyone who has commit privileges should know what normal looks like. Uh If you're only looking at your, your metrics and your telemetry when things are bad, you don't know what normal looks like. Everyone should know how to deploy, how to get to a known good state, how to, you know, do this in a controlled way so that you have fine grain, you know, knobs around canaries should know how to debug in production. Should know how to share this knowledge with their coworkers. If you must have stage environments, are you monitoring them? Why do people sink so much time into these environments when they can't even tell if it's OK. Yeah, here's your, you wanna get better at this. This is how to have a, a high performing team, an elite performing team. These are all a good use of, of your time for almost every definition of to collective view. And tonight we get survive. Thank you.

---
