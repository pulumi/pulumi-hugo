---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Kubernetes RBAC with Pulumi"
title: "Kubernetes RBAC with Pulumi"
meta_desc: |
    Pulumi engineer, Mike Metral, shows you the easy path to configure and use application RBAC in Kubernetes, to deploy a Helm chart that uses per-wor...
url_slug: kubernetes-rbac-pulumi
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Kubernetes RBAC with Pulumi"
  description: |
    Pulumi engineer, Mike Metral, shows you the easy path to configure and use application RBAC in Kubernetes, to deploy a Helm chart that uses per-workload identity.   This tutorial covers: 1. How to take a common Helm chart (logging), deploy & manage it 2. Setting up RBAC for use with least-privilege 3. Using cluster and app RBAC to run with per-workload identity.  Code examples are shared on Github so you can follow along:  https://github.com/pulumi/pulumitv/tree/master/kubernetes/aws-ts-helm-rbac  Pulumi makes it easy to get started using Kubernetes on any cloud - public or private - using your favorite languages:  https://www.pulumi.com/docs/get-started/?utm_campaign=PulumiTV&utm_source=youtube.com&utm_medium=video
  sortable_date: 2020-03-26T18:33:22Z
  youtube_url: https://www.youtube.com/embed/7qN9ABgmK9M
transcript: |
    Hello and welcome to Pulumi TV. My name is Mike Matt. In this installment, we'll review how to use a back for Kubernetes apps specifically. How do we associate an identity with the given pod launched in a helm chart. Let's begin on a general level. Assigning identity to workloads is pretty straightforward. You have two general steps, you consume the role with the policies that you need and then you consume that through the service account in a pod. But what is the service account in Kubernetes? A server account is an identity for a given pod and the process he's running within that pod. It allows the cluster to identify who in fact is running this. And with what permissions, as you can imagine working with pods in a Cobern use cluster will vary at this step when it comes to identity, whether it be on aws, GCP, Azure or on prem the implementation details will ultimately fall on the provider enacting the identity piece in this equation. Let's dig deeper into what this looks like in Aws. As we can see, there are a couple more steps to what actually takes place behind the scenes when we have a given pod and a service account for that pod. The first step we have to do is create a given role with a particular STS action. The secure token servers by AWS has created a particular action that allows us to readily identify the servers account within the context of the cluster and within the context of I am in Aws, this role will hold the permissions that we ultimately need. In our example, we're going to review how to actually stand up fluent D cloud watch through a hem chart by leveraging per pod identity. After we've created the role with the necessary permissions to be able to work with Cloudwatch. We're going to get the roles A RN back. This A RN is annotated on the service account because this is the first foray into how we eventually will get tokens with the proper permissions after we've annotated the service account and the pod comes up and it's run time. As you can imagine, the pod will have to communicate with Cloudwatch. How does it do that? Well, given the annotated servers account. The next step actually is for the pod to communicate with an O I DC provider that is attached to the cluster. This O I DC provider allows us to leverage the open ID components that the clusters and communities support and that AWS integrates with. So when we leverage this servers account at the pods runtime, what we're actually doing is that we're authenticating with the O I DC provider that's attached to our cluster. That provider will return a temporary token for us to then follow along with on instantiation. As soon as the pod needs to communicate with Cloudwatch, it'll swap that Oy DC token for an sts roll cred that is temporarily given to it on a timely basis. These credits are then passed along to EKS the service which then in charge leverages a dynamic web hook that mounts these temporary sts credits as a token into the service accounts that a pod will ultimately leverage. Once this is mounted into the service account, the pod has everything it needs to communicate with the service, which leads to our last and final step to use the actual service. No, a couple of references are here for you to review the code that we're going to dive into now is available at our Pulumi TV Repo and there's a couple of links for you to follow along in case you want to on AWS GCP or Azure. The general flow however, will be similar from clapper writer to clapper writer. Implementation details are where they're going to differ. So let's visit how this looks like in Aws. If we jump over to our text fields over here in our in our terminal, this is the basic definition for how we instantiate a cluster on Aws using Eks Pulumi allows us to leverage various components, whether that be components that are created for configuring EKS clusters for deploying workloads into clusters or for manipulating Pulumi as we see fit, we'll stand up an EKS cluster in a couple of lines of code. And specifically, we're going to enable that we create an O I DC provider as this is not the default for EKS clusters. This OY DC provider will ultimately be attached to the cluster as we see in the image on the left After the cluster has successfully come up, we'll expose its cup config file to leverage deployment of resources into the cluster. And then we'll actually leverage the O I DC provider's URL to tie the pieces together as we mentioned earlier. Let's see how this looks like to deploy a fluent D cloudwatch home chart using pod I am. We'll comment out this code as we've done the work already to actually make sure this is a running example as you can see because I have a language at my disposal. In this case, typescript, I have the full capabilities of a language to leverage that is creating new classes, leveraging functions, having the ability to jump into documentation, being able to have my omni completion. Tell me when I miss inadvertently type a property that does not exist. Or if I have a typo in my definition, we are notified by our editor and the TS server of what must be done to correct this after the race is already right. Programming languages allow us to work better with our infrastructure, with our clusters. And for the workloads that go into those clusters as you may have caught wind right here. What we have is a custom component that we've created called Fluent D Cloudwatch that requires a couple of parameters, the cluster and more importantly, the cup, the file to talk to the cluster, the name space in which we will deploy the helm chart and the O I DC providers A N and URL that we will need to configure the pods identity through the service account. Let's jump into what this component actually looks like. Here, we have a custom component resource that we've decided is the proper level of traction for our use. You could easily create components of your own. You can create libraries that expose functions if you choose to do that instead or you can simply export ID values. If you are the one in charge of provisioning the infrastructure and your colleagues are the ones in charge of just consuming that how you divvy this up is going to depend on how your teams operate, how your organizations are operated. And more importantly, how roles and responsibilities are divvied up in the cloud. Writer of your choice. If we dive deeper into the code, there's a couple of generic steps that we have to follow to actually provision the helm chart which we'll get to. In just a second. As we mentioned earlier, the Hunter will launch a pod for flu and D. But it's going to leverage a servers account that provides an identity within the cluster and that's attached to identity within AWS to actually be able to communicate with Cloudwatch. This service account is going to be bound to a certain set of roles in the cluster. And last but not least, we're going to create a new log group in cloudwatch using the Pulumi aws library in a single line of code. This law group will be passed on to our create flu and D constructor rather function that will actually deploy the hum chart for us. Let's look at what the helm chart looks like. Pulumi allows us the ability to instantiate many resources home charts ya files and even direct support for the API resources and TTI such as deployments, secrets, config maps services, et cetera. In this case, I wanted to grab a helm chart off the shelf of fluent Bly Watch. Doing so is as simple as defining a new resource for Helm that takes in the name space that will be deployed into the name of the chart that we're pulling from the given repo. In this case, is the incubator, the version of the chart that we want to leverage and some custom value templating as you would normally do in Helmm by editing the values dot YAML file. In this case, we are doing a couple of necessary steps, we are providing some configuration that fluency needs. We are establishing that the region that we're in is ultimately going to be provided to us by the ambient color given to us in a simple helper method called aws dot get region which leverages the Poli Aws library. Next, it'll forward and aggregate all of the logs and store it in the log group that we created. And last but not least we are going to leverage a service account that we created above. And this part is important as we mentioned earlier. There's two levels of our back at the cluster level to authenticate access into the cluster and then within the cluster to allow it to do certain sort of permissions within the cluster and the services that it may operate such as cloudwatch because it's a helm chart, a lot of the defaults have been taken care of for us in this case with regards to our back of the application. So it'll stand up the proper our back resources that it needs. But we are specifically giving it the parameter of the servers account that we want to use that we know has been authorized to work with the OY DC provider. And more importantly cloudwatch to forward all logs to this step. As far as creating the fluent D helm chart would be very similar to any instantiation of any HEMM chart across aws, GCP, Azure or on prem this particular example will only work on AWS given that the chart is particular to Cloudwatch on AWS. But the details here are analogous to running any other helm chart that needs identity. You simply would spin up the help of your choice and pass it the servers account that we created above and will jump into shortly that allows it to communicate with the identity permissions that it needs. Let's look at what creating the service account looks like. As we prove vision, the helm chart, the servers account is going to require that we assume a particular policy that Aws has allowed us to consume to enable web applications of this kind. In other words, we are able to associate a temporary web identity that has been authorized by the O I DC provider to verify that the service account actually exists. And ultimately, this will be how we exchange the temporary O I DC token for a sts token in Aws with the proper permissions. This format is a default format that we require when working with AWS that actually binds it to the server accounts. In question. In this case, we have to have a perfect match on the string equals that the server's account is coming from this given names space using this given name. This allows us to tie the identity particularly to the server accounts that the fluent de pod will in turn be running the role much like any other role in Aws requires a couple of properties, a name and the policy that I must assume in this case, it is the role with web identity that we've identified above. Once we've actually assumed the policy, we're going to attach additional policies for fluency to proactively be able to work with cloudwatch. In this case, this is a matter as, as little as attaching the given policies we have here that give us the actions to work with read update and create new entries in our log group. If you're familiar working with identity and Aws Im these statements here should look very familiar to the Jason or you're used to working with. The only difference is we are doing this in text script so we can programmatically edit it, reference it and use it. And a perfect example of that is when we take the policy that we just find up here to work with cloudwatch logs and attach it via reference to the role we created that assumes the necessary role with web identity, the Aws requires. So to summarize, we have to assume a default role policy if we want to exchange A O I DC credential for A sts credential, and then we have to do the added benefit of defining the permissions that your pod or application in this case will need once that is created, what we are going to do is take the given role that this function returns in this line and pass it to a new servers account that we're going to create that references that roles A RN let's jump into that method or function rather in this function, we are creating a standard Cotis service account. Once again, we are leveraging the Pulumi Library here to create these resources that are first class citizens in the Pulumi Ktis library. These look and feel just like the same Yaml and Jason you may be used to working with if you've worked in service accounts, the only difference is we're doing this in a real language for a service account to leverage the role that we just created. We are required to annotate it with a given prefixed key and then the roll Erin and it says value. This is ultimately how we are able to connect the dots between the servers account and which permissions will ultimately be granted to it. In this step, the servers account becomes created will take the name of that service account by everything it's metadata. And ultimately, this servers count will be what we provision in our fluent chart when we specify the R back policy to use the servers account in question listed here. So let's retrace our steps. We stood up an EKS cluster that has an O I DC provider attached to it. We're going to deploy a fluent D cloudwatch hem chart which is configured to leverage the O I DC provider in URL that we must work with to get a O I DC token that in turn will eventually become an sts credential. We facilitate that through the ability to create a new role with the given permission that we need. And it takes a new service account with that rolls a RN and then at run time behind the scenes, when flu nd consumes the service account, we're going to see the exchange that we have identified here on the left. So we created the role. We'll annotate the service account when the pod runs and is ready to actually communicate with cloudwatch. It'll off against our O I DC provider. Get that token, swap it for an sts. Credential. Sts will pass that along to the EKS service, which in turn has a dynamic web hook that the EKS control plane service automatically will mount into a service account token that our power consumes. So steps one and two are the main ones that are required for us to describe the permissions that we need and associate those permissions to a given workload. Steps. 3456, all happen in the background in the context of the O I DC provider being stood up. But more so that the IM services and the O I DC provider will communicate for you, given this construct that Aws has made available for us. So after we've created the role and annotated our service account with its A RN transparently, all these steps will happen, they'll issue us a temporary sts credential and ultimately, we'll actually be able to hit step seven and use the Cloudwatch service. Let's go ahead and launch this cluster and its workload on the right. We've taken the liberty of standing up the cluster for the sake of the demo. And we are not going to launch the fluent D hum chart using the properties we've defined on the left with the given role and service account. Let's run a Pulumi up. As we see the helm chart will begin to build out and create its pieces through the Pulumi engine. It will tell us what we plan to actually create if there's anything to remove and if we want to actually execute this update, let's say yes. Within a matter of seconds, this deployment will ultimately complete. Great. It's been stood up. If we look at our Pulumi output, we can see that we've exported the log group name that we'll be using to, to aggregate and push logs to within Cloudwatch. Let's see what that looks like in Cloudwatch. So if we take this log group name, jump over to Cloudwatch and look for this log group, we'll see an empty log group. This is because it'll take a couple of minutes for the pods to actually emit logs and for fluency to collect it. If we look at our cluster and examine the ponds within that cluster, we'll see that we have two copies of flu and D as we have it running as a demon set across both of our nodes. If we jump into the logs of that pod. We can examine a bunch of output from the STD out of fluent D showing its configuration and ultimately aggregating and pushing this off to Cloudwatch. Let's refresh. This may take a couple of minutes as we are also succumbed to potential rate limiting if we happen to go past our initial usage. Uh-huh, as you see, log streams are slowly starting to trickle in. Let's look at this one. This is exactly the same log that we've seen on the right that we are we're treating with Q control except we have this in cloud watch for us to examine analyze and centrally aggregate. Let's see if there's any other pods that I've emitted logs. Not quite, let's let that run for a sec while a couple of more show up. So to revisit, the only necessary steps we have to take are for us to define the role per the requirements to get sts credentials, attach the policies that we need to. That given role in this case, be able to work with cloud watch, attach the two and then associate that A RN with a given annotation on the servers account that will be consumed by the pod. In question. In this case of the Lindy Helm chart. Similarly, we can examine that all of this implementation detail outlined in the service account creation, the role creation and the attachment is going to vary from cloud provider to cloud provider. But generally speaking, no matter the cloud that you're on, there's going to be some capability to create a servers account that is attached to the identity service of that platform. Here are a couple of links to get you started on other cloud writers if you so choose to try them out. Again, this approach is no different. The general stance is we have to create a given identity in the provider of our choice and then consume the identity through a service account. Hopefully, this helps clear up how to leverage APP R back how to associate this with helm charts. And more importantly how to generalize this no matter the cloud that you're running on and last but not least once these logs are in cloudwatch, this allows you to analyze it, examine it and inspect it as you see fit using the rest of the suite of services. The club provider offers, this will continue to take a couple of minutes for us to see a full output of all the logs for all the pods that we'd have. But the premise is the same. There'll be an individual stream associated for each pod that gets output into the log group that we created funneled by fluent D. It facilitated by a service account that leverages im permissions with least privilege and no Y DC provider and the Aws Sts service. That's all the time I have. Hopefully, this was insightful and here are the links in case you want to check out more the code for this example is featured and found on Pulumi TV, on github. Feel free to drop us a note, share this or open up any issues that you may have encountered in your experience. Thank you and have a great day.

---
