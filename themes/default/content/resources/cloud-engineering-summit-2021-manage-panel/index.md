---
preview_image:
hero:
  image: /icons/containers.svg
  title: "Cloud Engineering Summit 2021: Manage Panel"
title: "Cloud Engineering Summit 2021: Manage Panel"
meta_desc: |
    Join Ell Marquez, Niall Murphy, Jeff Smith, and Sasha Rosenbaum as they discuss topics related to Cloud Engineering.
url_slug: cloud-engineering-summit-2021-manage-panel
featured: false
pre_recorded: true
pulumi_tv: false
unlisted: false
gated: false
type: webinars
external: false
no_getting_started: true
block_external_search_index: false
main:
  title: "Cloud Engineering Summit 2021: Manage Panel"
  description: |
    Join Ell Marquez, Niall Murphy, Jeff Smith, and Sasha Rosenbaum as they discuss topics related to Cloud Engineering.
  sortable_date: 2021-10-20T23:00:29Z
  youtube_url: https://www.youtube.com/embed/vzb70EvK51o
transcript: |
    Hello, everybody. Thank you for being with us here today. Um We are at Cloud Engineering Summit hosted by Pulumi and this is a, an amazing panel on the Manage Track. Uh And I'm Sasha Rosenbaum. I work for Red Hat. I'm in technical sales of openshift, which is the best version of COTIS you can find out there. Um And with me today are some very, very awesome people. So I'm gonna let them introduce themselves. Um El would you like to get us started? Uh That's always fun to be the first one. Hey, I'm El Marquez. I am the Linux and security advocate at in which sadly is a little known field of actually talking about Linux security. Um The thing I'm most proud of though is I am an advocate for operation safe escape. We're a 501 C three helping victims of domestic violence being able to escape their abuser when targeted by tech. So just big plug here. If you or if anyone you know is in this situation, please reach out. It's so important that people know they're not alone. Wow. And I'm so glad I met you. I, I won't keep a name in mind for, for those situations because they definitely happen. Um And then Niall, would you like to introduce yourself? Sure. So uh I have um in the soe field, I've been in internet infrastructure since the mid nineties, which dates me as well as the lack of hair. If you have come across my name before. It's probably because of the se books which I was the Instigator and editor and a bunch of other things of. Uh I'm currently a reliability consultant and infrastructure, a space station uh is what my Twitter bio now reads and you can find me on Twitter dot com slash. So you basically do treatments for people's infrastructure, config file, pruning and so on and so forth. That's what we do. All right. And Jeff, would you like to introduce yourself? Sure. Uh My name is Jeff Smith. I'm the director of production operations at a company called Centro. We're a digital advertising software platform and we are hiring which I will obnoxiously remind you of throughout the panel. Um I also recently wrote a book Operations, Anti Patterns Devo Solutions. Feel free to buy 15 copies and hand them out for Christmas presents. It is actually somewhere behind me um buried in that uh Bookshelf. Um But yeah, me and Jeff are here in Chicago, so we actually get to meet in person and I'm, I'm all blurry, but I'm gonna go with this. Uh So let's get started with the first question actually. And the first question since we're in the manage track, we thought that it would be interesting to talk about what do people do in the day two operations? Right. So, like you have launched everything that you have, you've deployed things, you've configured things, you went through all of the pain and then now you're starting to manage that infrastructure as it runs. Um And you have to worry about things like availability and stuff like that. So, um what are the key components needed for day two operations of modern services? And now would you like to get us started? Sure. So uh I think some of the, the fundamental things are, are probably going to fall in line with this theoretical framework called the Dickerson hierarchy, which turns up in the se book uh which is by Dickerson, but is not necessarily a hierarchy. So anyway, some of that model probably needs to be a little bit changed in felt. But basically, it says if you are running a production service, there's some hierarchy of needs a little bit like Maslow's hierarchy of needs. And at the bottom is monitoring, you got to be monitoring your stuff. Otherwise you don't know if it's up or down or what it's doing. And I suppose these days we probably put observable in there as well. Although in theory, you can draw a bright line between the ability to interrogate your systems kind of arbitrarily which what is load observ ability basically means I'm just kind of checking up or down uh kind of relatively simple monitoring. But the things that sit on top of monitoring, I mean, more or less everything sits on top of monitoring in some way needs data. What you're talking about uh incident response, post, incident review, like post mortems and stuff like that capacity planning, looking at performance latency measurement, uh all of that kind of stuff, you basically need to have situational awareness of what your service and systems are doing, what they're talking to, uh how it's being affected, error rates, all of that kind of stuff and and then you need to be able to react to that. So there's this other theoretical construct called an U loop which I think drives from the US military and it's observed orient, decide and act. So basically, looking at uh what's happening to your service by observ ability uh deciding what to do based on that, like maybe there's some error condition or maybe you need to increase your capacity otherwise you'll run out in a month or two and then act on that. And that loop is one way of understanding the the kind of demands that are involved with running any significant online service. So I I think you're talking about like kind of being a very mature state for Buenos Aires, right? And I think, you know, the future is here, but it's not even distributed and we have a lot of companies who are, who are like in a very good state and actually, you know, doing observable and, and are very advanced as in what they're approaching. And we have some companies just trying to catch up from the nineties. Right. And there's a lot of that out there that, like, people are, like, actually their actual availability is like two nines and they're struggling with that. And, um I, I kind of wonder how we get there and, and um the modern expectations are different, right? Like we, we have, you know, we can't, we can't say we're closed down for the weekend for maintenance. Like that's no longer a thing. I still see people do it but it's no longer a thing that you should or could be doing uh with a fair chance of being a modern service. So I, I don't know, Jeff, if you wanna talk about it from the standpoint of like a real world company trying to get to the modern state. Yeah. Uh you know, II, I agree with Niall, you know, in terms of like observer ability being important, but I, you know, I think the day two conversation um really is, it depends, right? Because I think everyone who's launching a new service or migrating to the cloud or anything like that, they're doing it for a particular set of reasons and I think those reasons will inform what the day two stuff is because once you migrate, um you quickly start to realize the pains that you're experiencing because there's much nothing as you do, nothing is like production, right? So then day two comes along and suddenly you've got this list of things that are problematic and causing your organization pain and, and you need to address those first. So for like me, for example, when we were migrating to Aws and migrating a bunch of services there, monitoring was actually part of our day one and we did a lot of work and getting a lot of that observ ability um and that alerting and that incident response process down solid before we went live. And there's a lot of other organizations that feel comfortable, you know, solving that with day two. So I think it's largely gonna depend on what it is that you're optimizing for. So a big thing that we were optimizing for was, was cost, right? So a lot of the work that we did was around environment cleanup, environment management, uh resource exploration, that's a lot of things that bigger organizations are like, you know, what we're gonna deal with that later and we will just continue to spend, right? So that we can empower other um other, other business operations and, and business functionality and not to say that that's wrong. I think it's all a trade off, right. So you may want to say, well, you know, we'll, we'll spend that extra dollars because we know that we're empowering developers to be able to do these other things faster and there's a dollar value to that. So that's a long winded way of saying it depends. Um I think the frameworks that Niall mentioned um are, are super important and, and something that you should consider when you're trying to evaluate that stuff. You know, I love looking at the the loop as a perfect example, right? Because it is this sort of structured way of going about and approaching um incident management. But it's it's also something that you can do outside of incident management and just sort of look at, you know, your overall strategy um in a, in a larger context, right? So what is the day two things that we should be looking at? Well, you know, or and observe, decide and then act, right? Look and figure out what it is that is causing us pain and, and how do we go about addressing that? And I think your pain points will sort of bubble up to the top really fast once you go live. I actually I, I hate to bring it back to, but like cost is the conversation we were having offline, right? And um the the thing that always pops up is like no one unless you're Google, maybe, maybe you don't have unlimited funds to, to throw at your infrastructure, right? And so cost is always a factor and so what happens usually with your management is your management wants the five nines, but they don't want to pay for it. And so this conversation you have to have, right? You have to explain that like there is a cost to every single uh you know, nine that we are a quarter, like a quarter, nine or half a nine that we add to availability. And um I think one of the things that uh kind of the Google SRE um book uh maybe helps us structure a little bit is structure that conversation uh about cost. And I think everyone wants to jump into this actually. So like, uh why, why, why don't you um jump into bad, right? I'm gonna go completely contrary to everything everyone just said. Um you know, and this is gonna sound rude and I don't mean to, but I don't speak the, you know, alphabet soup of, you know, the SRE world, you know, the click deployments world and, you know, that's like all the different models and everything. One thing that I feel that everyone has missed and everyone's gotten short is the whole concept of security anywhere in this, right? We keep talking about cost and, you know, reliability and everything being up. But, you know, it takes a couple of minutes for an attacker to be able to find a mis configuration within an environment. And we're talking about cost and quick deployment that's gonna happen. I mean, historically, we see it and you talk about, you know, this whole concept of mature companies, those are the ones that are the best known attack vectors where I think companies that are just transitioning to the cloud are in the best place of anyone that's there because they already have this information at hand, they can completely build their pipeline with security in mind. So yes, we have, you know, the whole concept of having to have, you know, reliability, right? And having to have everything up, which is great. But if what you have is something that is full of because we tried to cut cost and like it's not worth it, right? All you're doing is inserting something into your rent time, inserting something that can become a target to pivot into everything else, even if it's old infrastructure. And I think the most important thing here is when you're talking about cost is not ensuring that you don't have, you know, 50 web servers or whatever it is that you need. But ensuring that you haven't cut corners when it comes to that, uh when you know the entire security posture of your company. So Jeff first, I, you know, so I've got two things to respond to now. So I'm gonna, I'm gonna start with uh what else said, I completely agree regarding the security conversation, but at the same time, um and this is a super unpopular opinion. I know this, but this is the reality that we live in. Right. Um, security is just another piece of the puzzle that we're trading off against based on the organization and their needs. Right. So I, I can be launching a new product. Right. And the thing is I can have all of the sort of security pipelines and everything in place. But if there's no one that's actually responding to that, right. If I'm not staffed appropriately or, or have the time and, or energy to dedicate to those things, you know, being aware of it is nice but not reacting to it is terrible. And, and that's the thing that you see in a lot of organizations where it's like, oh, we're gonna get the software, we're gonna get vulnerability management, we're gonna get scanning and, and then you get it and you just get bombarded by these emails like, yeah, you haven't passion for you and they're like, yeah, we're gonna get to that, right? Um But from an organization perspective, you may just not be there yet. So, you know, I, I think it also is, is part of the tradeoff paradigm and it's a terrible, terrible thing to trade off of, right? Because it's like, um in no other scenario with security being negotiable, right? It's like, well, you know, I want my kids to wear a seat belt but, you know, it, it, it, I, I think that you 100% just made my argument like what should be part of day two you've already spent that part on day one focusing on it by not having that as a direct, like, the first thing you do in, you know, day two and having that security operations, having somebody monitor it. That, that's exactly what I'm saying. Like that's the issue. Does that make sense? Yeah, it makes sense. I guess the thing is, um, if you have $100. Right. And, um, you're trying to build a new product, right? And 40 of those dollars have to be consumed by security, right? Um That becomes a calculation that you have to make, right? And you go like, well, we're just starting off, we're trying to build a customer base, right? Like maybe we, we take the risk and, and, and you know, we focus on actually building the product out a bit more and then the conversation is always, we'll come back to that later and I'm not saying it's the right decision. I'm just saying those are the, that's the reality of the conversations that I think are, are happening and the question becomes, and this goes back to the original thing that I was talking about is I think it's incumbent on us as leaders and managers is how do we translate this risk into something that's actionable by people that are making decisions? And a lot of time that boils down to uh not only just a financial component but the the likelihood of occurrence, right? So it's this thing where it's like, you know, um, it's easy to say like, well, you know, if we get compromised then it could be expensive. Right? All right. Well, you know, let's quantify that though, right? You know. Uh, ok, there's a 30% chance that we're going to be compromised and in that 30% chance the cost is gonna be between 25,002 0.5 million. Right? If we give it that, go ahead. So sorry, I I just, I thought you were talking but, but I'm gonna jump in and, and I think this, so this is something that came out of Twitter thread because best things come out of Twitter threads. But um we were talking about like we need an SL A for security, right? So, so the way we quantify this cost and availability space is we put an SL A on it and we say we are financially responsible for XYZ. But if we didn't meet our targets, we kind of need a way to put dollars against security risk and say, hey, we quantify this and now, you know Mr Co or Mr Ceo like yes, like there's a 1% chance that you will be in jail tomorrow if we don't patch this. Like I, I mean, like we, we have to put dollars behind it and that's that I think that will be the way to have this conversation in a, in a, in a better fashion you know, I promise I'll let Niall talk. But real world scenario, I swear, real world scenario that I've heard twice is exactly. We talked about Jeff. I have a company that goes, ok, I have to be the first to market like we have to meet this deadline. Ok. But we also need to be secure. Well, if we make, you know, first to market this is how much we'll make. If we get popped, this is how much we'll make. What I hear is if you know what company profits, you know, users, customers, if their data gets breached and it gets out there, uh we'll just have to pay this much the rest they handle on their own. But we, the company can make this much and that's what really bothers me and, and I agree with you completely. I think it, I think there is a moral component to this. Right. But, you know, I, I think realistically companies like, especially larger companies, like it's the cost of doing business. Right. And I think part of it is incumbent on us as users and, and um consumers need to react to that. Right. Like I haven't start stop sharp shopping at Target. I still shop at Target. Right. I'm still giving money to these companies that are like, oh, wow, I cannot believe that they had this terrible security breach. Oh, look a sale, right. Uh So, so I think it's also incumbent on us to to, to show with our dollars that, hey, this stuff is important. Um, and, and not to sort of dismiss it as like, you know, well, you know, they had this breach but everyone's having a breach and I really like that feature. So it's worth, well, that's, that's the thing though. Right? Like this is capitalism and it's like negative externalities. Right? And, and, and we, we keep doing this, not just for security with everything, right? It's like we, we can make this much dollars and these people might, you know, be in a terrible situation if something goes wrong. But like it's not me, so I don't care. So, you know, it, it, it keeps happening with all of our decisions and we kind of keep in, encourage people to, to make these decisions also, like when it comes to everyone who has had a breach, I'm like, we should probably give up on pi I altogether like, I mean, like, like my information is on the internet in so many ways from so many breaches. Like I, I can just be like, you shouldn't be able to verify my identity by like knowing what my my cat's name was like because it's just all out there like, you know what I mean? It's just like um yeah, uh OK, super great. Um But OK, now, finally, finally, OK, go ahead. So you must understand that I live in socialist Europe where there is a regulation which says that I am in control of my data and I get to ask the company to do various things with the data, including deleting it, giving it to me, et cetera, et cetera, et cetera. You all can say your data is flowing around the internet and that's all totally fine. And so pi I is not useful anymore. I am going to sit here in my ivory tower of wonderfulness and say yes, actually solves a lot of problems and actually also creates a lot of problems and the impact of the legislation. Well, like there's a lot of ideological conversations that go on about this people saying it impedes kind of startups. It, it concentrates the power in larger organizations which are able to afford the teams and resources that go towards managing the privacy of data and so on and so forth. It's a very important concentration of economic power argument. But I will say that I think regulation as a tool for managing this is overlooked in the American context and I will leave it there. I, I mean, I completely agree there because the, the problem and, you know, it's funny, I was, I, we gave a talk on, on ethics and I was talking to my CEO about this and, you know, and it's ironic and a guy talking about ethics, but hear me out, um we were talking about ethics in the industry and it's like the, our CEO Sean was so adamant that we need government regulation because with about that it's sort of this race to the bottom. Right. Like, you can be the company that decides I'm gonna, you know, set my foot down and we're gonna do all of this great security stuff or all of this great privacy stuff in the ad tech industry. But if the rest of the industry says, well, we're not gonna do that right. They, they could end up eating your lunch. So I agree, regulation sort of like levels the playing field and sort of sets up like exactly like, ok, this is the standard by which everyone needs to play. And, you know, I, I think making security part of that as well as uh you know, sort of like leveraging the fines in such a way that it's not just the cost of doing business, but like there's, you know, some actual uh uh skin in the game around it because if you can just sort of write it off in a budgetary context, then, you know, yeah, a lot of people are gonna do that. Well, like if you, if you think about the, the mechanism by which economic externalities are turned into internal, these, the mechanism for that is regulation, like the market ain't going to solve this. There's no incentive for the market to solve this because like, partially we continue to shop at Target. Well, I do not continue to shop at Target because Target is thousands of miles away from me. But you get the idea. So, anyway, um, so, ok, I know you have opinions on regulations. So why don't you jump in? I do too. So we're just gonna continue going with that side. I'm desperate to hear him. So, you know, the whole concept of regulations is great in theory, like even when it comes to the eu we recently had them find, what was it? 220 something odd Euros when it comes to whatsapp having their data leaked. Ok, cool. But you know what, my dad is still out there, it's already there. It's already been breached. They had a fine and you know, it's not really doing preventative measures. And I could give example after example. And so this whole concept that regulation will solve everything. It would be that utopian society, right? And don't go into utopian the book, just the concept of utopia. So anyways, that's all I had to say is all of this is great in terms of theoretical and in a perfect world, but that's not what we're actually seeing. So, so I think personally, first of all, regulation is the only way to regulate the market, right? Otherwise we would have mono monopoly in every single you know, um situation because that power concentrates over time, right? So this is a perfect example, like we do regulate a lot of things and it does work when we regulate things like it's not perfect, but it does work. And again, it creates the only incentive companies have to actually invest in something like security compliance and things like that. What I think though, so, like referring to books, there's this book called The Inevitable and, and it's, it's really nice in general, just kind of different take on where the internet is going and like where, where, how it all started and where are we going to end up? I think the from my, my standpoint in what he raised in this book is like this is already happening. It's already happened. Like we can't take back our data, we can't take back our data, not just from breaches, but also like from Facebook or Google or whoever else knows everything I've done since high school, right? Like it just I I cannot not, no GDPR is going to help me get the data back, right? It's already there. So what we have to do is evolve as a society for this new world where everything is out there and you can find pictures of me in, in high school and and use them if I run for president, which I can't do by the way, I'm an immigrant. So, but anyhow, uh it, it like, I think we have to be realistic like I, I'm, I'm always pragmatic, right? So it's the same conversation for security if we live in a wishful thinking world. And we say like we have to secure everything and we have to invest like here it's gonna cost this little company 2 million to have proper security posture. They're not going to do it because they don't have the money realistically, they just can't even if they wanted to, even if they like had the best Russian and hard. So we have to make it easy for them. Right. So like I'm, I'm big fan of trying to automate security as much as we can because like that allows a developer that's writing the code to click on buttons in all like, you know, instrument the code to, to be more secure and like, yes, Jeff, maybe no one's looking at alerts, but maybe we need to automate that too, right? So we have signal to noise ratio that's much better than we have right now. So there's a lot of things we could do if we accept that the reality is what it is and we have to address it in ways that that are doable, quick clarification. Nothing else. I wasn't saying I'm anti regulation. Just put that out there. I wasn't saying that. All right. Go on. We did, we didn't, we didn't think so. Like no, for sure not. Um OK. I I'm gonna move on to the next question because believe it or not, this was the first question we ever talked about. Um So this one actually, I guess is, is interesting because um what do we think everyone gets wrong when trying to run reliable systems. So like what's the biggest mistake you see out there in the industry in your companies or other companies? And Jeff, I'm gonna start with you. Um I would say the biggest thing that people, companies get wrong and I haven't been to every company obviously, but the biggest thing that people get wrong is that reliability is this thing that we slap on at the end. Um You know, it's like we, we go through this phase, we build it, then we're like, ok, now, you know, now that it's in production, let's make it reliable. Um as opposed to thinking about it as a, as a feature of the product, right? Um Same thing with security, honestly, it's like at the very end, we're like, ok, now, you know, let's talk about security. So it's like, how do we, how do we bake these requirements, you know, back into the actual requirements of, of the product? Um Because if we're always at the tail end of this reliability is always gonna be behind. And there's a lot of things that, you know, especially with, you know, modern con practices and things like that, there are things that applications need to take into account to be reliable, they're not things that we can always do just with infrastructure. Um You know, sometimes we end up, um sometimes we end up, you know, uh creating cover for poor applications through infrastructure by saying like, you know, oh well, you know, dynamically scale when these things run out of memory and fall over, right? So that we're not losing traffic or anything like that. But then the other question is like, well, you know, when are we gonna spend time to figure out why we're running out of memory and falling over all the time? Right. Um How do we, how do we build good metrics into uh into the platform so that we're emitting very specific bits of data, right? As opposed to well, memory and CPU look great. Um How are we making sure that the application is emitting metrics that verifies not just error conditions, but that things are actually working the way they're supposed to be working, right? So it's easy to say like, oh this thing broke, but we should also be saying this thing was successful or this message was received and this message was processed, right? As opposed to um just one end of the equation. So I I think it goes back to um getting reliability into the design phase of the product. And and this is gonna sound again, unpopular product needs to be on the hook for that reliability because if product is assuming product is powerful in your organization, different orgs have different product structures. But if the product org is the one that's setting the prioritization that is uh you know, uh responsible for reliability as well, guess where their view on reliability is gonna change. Oh, ok. Now that I'm on the hook for the five nines. Yeah, let's put in that feature into the sprint that is gonna fix this database and stability and things like that. Um, so, you know, it goes back to design and I, you know, I'm, I'm putting product on the hook. I hard to agree with like every word that you said. I, I have a feeling that this will be a question where you just all agree on. I don't know. Now, do you want to jump in? Uh Sure. I mean, we can't give you 95. So you can't give you five nines, we can probably give you five nines, sorry, other way around. Anyway, uh Jeff, I was going to respond to you and say like it's, it's I'm not quite sure who you thought that opinion was going to be unpopular with because I'm not sure it's anyone on this panel. Uh But I, I will say that I think the general point that you're making that concerns about everything other than feature engineering at the moment are peripheral in most kind of product conversations, organizational prioritization conversations, all of those kinds of things, right? There's basically feature engineering for which it is perceived. You know, each next step of feature engineering will bring more money into the company and each next thing which is not feature engineering will not bring money into the company and therefore is a lower priority. So what I see in the industry today when I talk to my clients in a bunch of uh other other folks in the industry is with this right, with this core of future engineering and we have more or less every other priority kind of peripherally around it all petitioning what they imagine, you know, the central team to be to give them the resources in order to do the thing that they're supposed to do. And II, I just think that's a fairly hopeless situation to be in really because you, you can't ever approach it in a meaningful kind of way. Can't ever expect to even get to an 80 20 style ratio of all of the things you need to do in order to make the product reliable, secure, et cetera, et cetera. So to my mind, we really need a new, well, we need a new paradigm, but we also need to understand our current situation a bit better. I think we need a kind of a physics of software or maybe a biology of software. So we understand what the tradeoffs are between the elements in this space. And we're in a position to make a much more informed decision than the really simple Boolean model that a lot of engineering leadership has right now, which is one equals money good and zero equals no money bad. And actually the space is way more like a real, a real number space. Or filled with irrationals or something rather than this model. I honestly think that this is not about biology of software, this is about psychology of humans, right? And, and something that both of you have mentioned is incentives and incentives is what drives the business. And so if you pay some people to, you know, fix the, keep the lights on and some other people to deliver features and you put your focus on the people who deliver features, then guess what's gonna happen, right? I mean, you're gonna accumulate tech debt as you go every single day and like no one's gonna care about it until again it a CEO ends up in jail over a breach or something. I don't know. Um you know, um I do, you want to jump into this one as well? Sure. I mean, to avoid being repetitive because I think, you know, we already established that everybody agrees with this. I think the biggest issue we're having is outsourcing ops. Like we, we are basically getting to the point where like, you know, operation side of the house is just extra amount of money. We can completely outsource this. We're giving almost that responsibility to our doves. We're having that well, it didn't work, just redeploy it without operations. You don't have anyone to look at it and go. Ok. Why are we really hitting these memory caps? You know, is it actually what you're looking at or do you have I mean, to go back to the security mind, but like, do you have a crypto minor that's suddenly gotten in there? Is it actually the software or even if we don't put that concept of security in it? What's actually going on with the metrics? What are you actually seeing? Is it that you're not deploying enough resources or is it that they're not allocated correctly? Like when you have an in house ops team and not something belonging in the cloud, they get to know your environment and kind of what your software is supposed to do. And it's really funny when you talk about like the biology of software because the way that I was taught to look at it when I kind of came to this world is DNA, right? You have your base DNA, which is your original plan of what everything's gonna look like and then you have your run time, what it actually evolved into. So I think without having someone actually look at, well, it was supposed to be this and not, what is it? Actually, you're just setting yourself up for failure. And I think that's AAA huge point because like, you know, we, we, we always tend to latch on to what, what we think we designed and then, you know, not reevaluating for what it actually is. And a lot of us are running systems and still looking at it in that uh that optimistic lens of what we intended instead of, uh, what it actually is doing. And it, it, it's like, it's a common thing with systems. Right. They're like, you know, systems are designed, they, they're doing what they're intended to do, not what they're designed to do. Right. It's like they, they're just sort of, uh, self reinforcing. So, I, I think that's a huge point. I think the other thing too is that if the pandemic has taught us anything is that as humans, we're not good at evaluating risk, right? So I I think part of that is that is our, you know, internalization of risk and getting better at not only presenting the risk but then consuming that and, and uh making intelligent choices and decisions off of it. I think so. I'm gonna pivot just a little bit of this one and like I, I super love everything that everybody said. Also, I will say that like I'm a big believer that there's no perfect architecture, right? Whatever you design a system for is going to evolve over time and so about clean code is not very helpful because you don't know what tomorrow is going to bring you away, right? You can't architect for perfect scale. You don't know what your features are gonna involve you, what your customers are gonna do all that stuff. Um But I think what it, what I keep hearing from everybody is that we, we have to get observable. Right. Right. We have to be able to understand what our code does understand what our, so what our software, like, what issues our software is having and have it consumable by humans. Right? In a way that again, signal to noise ratio, right? We're not drowning in useless alerts about like CPU is over 90%. Well, is that a problem or is it not? Right? All of that stuff. Um So what I want to ask a controversial question related to the previous question, which is who should carry a pager in your company? Yes. Yeah, I always say it starts with the, the person that has the power to make the change. Um, because I feel like if there isn't skin in the game, it's always easy to defer, right? So, um, when, when Dev started getting the pager, suddenly the memory errors went away, right? Because no one wants to be woken up in the middle of the night. No one wants to be at the barbecue and then have to restart a server. Right. So, um, and, and then that was a lot of the frustration of ops where you would get paid and there would be nothing that you could particularly do about this problem. Right? And it's like, well, I, I can't really do anything about it. Um, so I, I think it, the pager should be carried by the person, person that has the power to actually make change. Um And that's something that is in ops that we had to learn that once we started giving the pager to dev, guess what, we had to give them the access too because that's the same argument. Right. Oh, I got paid. I know the service needs to be restarted, but I'm not allowed to restart it because I can't connect to that server or whatever. Right. So, it's a two way street. But, and for me it, it starts with whoever has the power to, to enact change and once that pain starts to get, felt suddenly tickets start showing up in sprints. So, so I think there's a lot of like, you know, I'm gonna, I'm gonna bring the, the, the other side of this conversation though. I don't, I fully believe that de should carry a pager and I'm a Dev. Um, and, you know, um, I fully believe that products should carry a pager periodically, right? Once a month experience, the pain that support goes through. Right. Not, not like you don't have to live that life every day. You have to know what your customers are calling your support about or what's blowing up or, you know, what's paging people in the middle of the night. Um, but there is a lot of conversation about this and every time it comes up there's a lot of people who say, well, I, you know, I, I'm skilled at this. I, I've studied computer science for the last 10 years, whatever. Right. And I know how to write, write C++ code and I shouldn't have to worry about reporting servers or something like that. Right. It's like, it's just like a waste of expertise or something like that. So, is that a concern? Should we listen to that? This is gonna sound like I'm making a joke, but I'm being 100% serious. Who should be paged? Whoever makes enough money to actually care that they're being paged. I've seen too many situations where it's like, oh, I'll get to it. Hold on. And that gets delayed. The best way I ever saw it work and I know it's different for every company is the first page went to that they got on and they're like, ok, I can't do something but this is what I'm seeing. The second page went out to the team. We're talking, uh, you know, the lead architect, we're talking product, we're talking to the Deb, there's a meeting, everybody's involved in it. Everybody's having the discussion with that many people being called into it. You better believe that alerts and issues started dropping because nobody wanted to be the reason that everybody got woken up as well as why they were there? Interesting. Do we need pager too? We're all sort of, I think we're all, you know, every time I hear the word pager, I'm like, do people know what we're talking about? Maybe, maybe pager duty is out there and people actually know what page of duty is out but, like, being on call, right? Responding to, to software, uh, to Jeff, you want to find it? I, I, yeah, II, I was, I was being facetious just because, like, you know, whenever I use the term, like pager or like, you know, oh, I got beeped to people, like, oh, you sound so old. It's like when people call it itunes still instead of Apple Music, for sure, for sure. Um, now, do you want to say anything on the topic? I certainly do. Uh, I have a lot of feelings about on coal, some of which I've recorded in previous talks. I think the first thing to say is that there's, there's this thing called the wisdom of production, which is a thing in necessary theory. It basically says more or less what Jeff was saying at the start that being connected to in a very direct and real way, the consequences of your actions earlier in the SDLC is actually a good thing for the product, for your expertise, for your development as a human being and a designer of software and so on and so forth. The only reason why you wouldn't do it is of course, because it sucks and it's terrible and it has terrible effects on human beings and all of those kinds of things. So it tends to be that the terrible effects bit dominates the discussion as opposed to the better software cross person component of that. Discussion, which I think is something that we need to change in the industry. And there's a lot of things we, we could do about changing some of that, that balance that II I think we're not doing. But the, the other thing I would say about carrying the pager and, and the, the kind of implicit social hierarchies we're talking about here and have talked about earlier in this conversation. There is a kind of uh I'll use the word Marxist, but I actually mean class based analysis of on call, which could take place here, which is to say, feature engineers at the core of an organization bringing money in revenue, et cetera, et cetera, perceived as being a higher social class than others. And so we're all petitioning for attention resources, et cetera, et cetera. From this situation, I, there are a surprising number of analyses of conventional software development and that whole process and how humans, I mean, coming back to your point about human psychology, how humans operate in groups and in, you know, companies and so on. That's missing when we think about what does it mean to be a good software developer, what does it mean to work well in a team? What does it mean to run a service effectively? And I think the fact that there's such a variety of models for how we do on coal, which is like it really is very strongly varied across a lot of the industry and even the fact that uh the Devops folks, you build it, you run it ise like all of this variety in the space about how we handle production concerns is really a reflection of the fact that these, these, these things are in tension when people are, are, are trying to figure out how to live, how to work. And II, I don't think we've got there yet and I think this needs way more attention than it. So I think I completely agree with you on the classic part. Right. And there's a lot of classicism in, in how we run our teams. And it's, it's really interesting because, like, I, so I've been to DEV, I then was what we now call DE UPS engineer maybe, you know, and, and then I, you know, I'm in, I'm in technical sales now. Right? And so every team I, I was in Dev briefly, right? So every team is like, well, I'm not marketing, marketing sucks. I'm not sales sales is like, only invested in money. Like I'm not DEV, like, I'm, I'm better, I like, care about how systems are, like, whatever. Every team has a lot of like swagger and it usually comes at the expense of other teams. Um, and, and then there's this definitely classicism that like devs, like feature devs get the most kind of investment, um from, from the standpoint, you know, of the companies usually, right? I think that the big tech companies are actually doing this right, in a sense of like trying to kind of remediate that stance and make everybody kind of more aligned in terms of incentives so that people, there's not a huge disparity between all of these roles um in terms of pay in terms of like investment that they make into people's careers and stuff like that. Um I think so, this is the conversation, I think and I don't remember Jeff if you were, um, in it. Like, we, we've been running Des in Chicago for the last 78 years. I don't know what this time. Um And at one point I was kind of getting frustrated and I was like, did we actually make any difference in the industry? Like, I, I, you know, I'm dealing with the same stuff every day and like, did we do anything in like the decade that the term Deb ups existed? And actually a lot of people came back to me with like, yes, we did because Ops is now a like Dev ops or SRE, right? We keep this evolution. Those are people that are valued, those are people that do interesting work and those are people that get paid to do interesting work, right? Which was not the case 10, 15 years ago when it was kind of like ops is the janitor of the deaf, right? And so I think we are definitely making progress in, in the right direction in the industry and I don't know if anyone wants to jump into this one. Yeah. No, I, I completely agree. And, uh, you know, we are getting more focus on ops and I, I think part of it as, as terrible as it sounds is a lot of people don't understand what it is, operations is doing and providing for the organization and that's where that sort of resource contention comes from because if you've ever been in an organization where the system becomes unstable and you're having outages, suddenly ops has every resource they need because now people understand what it is that OPS is doing and what they're being provided. And OPS is given a platform, say like we don't have this, we don't have that we need this now suddenly it's like hire three people, right? We've got a war room, here's the DEV team dedicated to this because we've, we've, we've uh felt the impact in a way that, you know, a lot of organizations only understand financially. Um So I think we're definitely making progress in that respect because people are understanding the, the power um that comes from having a solid ops organization because the, the problem with OPS is if you're doing your job, no one notices, right? It's just this sort of invisible background thing that happens and it's not spectacular that the system didn't crash, right? No one gets rewarded for, for the near misses, right? Um So, II, I think I, I definitely think things are getting better. I think operations leaders need to do a better job again of, of quantifying the value that we're providing, um quantifying the risks and the tradeoffs that we're making so that, you know, people understand what, what it is that we're bringing to the organization. So I, I don't know if you wanted to jump in into that. And again, security is also a class of people that get prioritized or de prioritized based on certain circumstances, right? So I don't know if you want to speak to that. Um you know, having worked in the side of house for quite a while, I think because I have some opinions there. But to go back a minute, I thought this was hilarious because I totally get that. It was a joke. But your whole concept on like, I don't know if people know what I mean that, you know, with pager, that's actually one of the the key examples of what I'm talking about when we talk like this whole platform, right? Supposed to be the managed platform in a managed panel. Yet everything has focused around the concept of SRE like there is more to managing a server or a server, an environment depending on where the company goes. And I recently heard a statistic where there are 10,000 developers per one security person. And like I said, basically ops are being pushed out so their numbers aren't any better So the whole concept of, well, they have to quantify it, they have to look at their metrics. OK. Great. How do we keep up with you with our numbers? If we're not involved in the conversation, one of the biggest issues in all of this is communication. If no one speaks the same language, nobody has the visibility or not, everyone has the visibility into it. Like, aren't we putting unfair or unrealistic expectations on everyone else in the inside of the house? I mean, absolutely. Right. Um I, for me though, it, it's, and this may be unsatisfactory, but for me, it's still part of that, you know, how do we quantify it? Right? So, for example, like, you know, security for the longest time was an ops concern amongst the many other things as if it wasn't or, or it couldn't be its own discipline, right? So once we start to quantify that and say like, hey, here are the pain points right? Here are the things that, you know, the security team would inform us on in terms of, you know, uh best practices, policy, uh even, um you know, regulation, right? Um Suddenly, once clients start asking, you know, what is your posture, what is your, you know, what is your regulatory compliance stance? Right? Then suddenly it's like, oh, we need a security team, right? Um Because the value of the team becomes crystallized in a way that we weren't doing before when the value wasn't just about potential new revenue but about risk to existing revenue. And uh you know, there was a term that I heard and now, you know, I've got brain fog. So my mind is, is blanking on the, on the person. But um revenue protection was a term that I heard to define things like maintenance and security and things like that, you know, so that helps to sort of frame it in the sense that like, hey, look, the risk isn't just theoretical. If it happens, there is potential dollars at stake. And II I still just think, you know, we need to do a better job of, of communicating that and it's in most organizations, it starts with the operations teams because we don't start with the security team, which is sort of indicative to the problem you're exactly talking about, right? It's like, you know, we don't even have this thing that is super important even in the mind, even in the smallest capacity. Um so it starts with the operations team and then, you know, we'll continue as the security organization grows. So, so how, how do we make it better again? Real world, right? Like we, we are, we don't have unlimited budgets and in the statistics uh that lu quoted, I used to quote it too when we were talking about why we should automate security, right? Because that's, that's how bad the situation is. Like we have so many devs working on features that have never heard of security again. If you look at my personal example, like the first time I played the CTF, I was like, oh, ok. I've done all of these, like all of them, like, you know what I mean? And no one ever told me anything and I, you know, I did a computer science degree. No one ever taught me about this. Like, where did we all miss the training while trying to kind of on board people? Um So, so is there a way for us to, to make it better to, to, to make the situation better for ops for security for including all the, for observable to, for including all of the things we should care about. Um, when we're developing software, I, I know that my, my answer is gonna seem like, ok, really, we can't do this, but it's a long term plan and it's the whole concept I got told to, you know, keep it PG 13. So Screw Dese ops, we are one team, we have one goal and in the end we need to have. And this is a whole another topic which maybe we can, uh get into on a different panel, but we need to have like one set of tools to begin with. And that's, hey, you keep talking about, you know, adding security from the beginning. How much security, you know, training have you had? There are 50 CV ES that come out per day are you expected to have? So, if we have, even from the beginning, we've got ops in the conversation, we've got security in the conversation. Everybody is going to learn from each other. So it's not a quick solution. But in the long run, debs will be able to automate security. Better security teams will be able to give you insights as it's automated. So we can't just put everything on one side of the house when it comes to buildings. And to that point too. Another thing that is that I see a lot in, in organizations when I talk to people is like, especially in security, the organization has zero knowledge about security. And what I mean by that is so often we rely on the engineers and the network of their engineers to know about CV ES, right? To know about critical vulnerabilities and things like that. And it's like, oh, we know to patch because I'm up on Twitter, right? And I see people talking about it, but does the company have a way to know about these things and make the appropriate, take the appropriate action? Right. What are the systems in place that allow that to happen? And a lot of times when you ask that there's a lot of blank stares, right? There is no tooling, there is no uh uh process around surfacing that stuff. So, you know, II I think uh one of the things we can do is like, you know, start with what does the organization know, minus some superstar engineer leaving? Right. And because she's gone, all of the knowledge about, you know, potential vulnerabilities is gone with her. Um How do we embed that in the organization? Um The other thing I was thinking about was um one thing we've experimented with a bit is like confidence intervals in terms of um quantifying risk, right? So when someone says, what's the risk of us not patching this thing? You know, I say, well, between $25,007 million and they're like, whoa, why such a huge range? And it's like, well, because we're not sure. So that represents how, you know, how we have a lack of confidence about how big this impact is, we can spend a little time and if we spend time and energy, I can narrow that range for you, right? Um But do we want to make that investment? So we did that um specifically we did that with um looking at going multi region active, active, right. So I say, well, you know, um I don't know how much it's gonna cost, but I know it's gonna be between like 250 grand and like 3 million a year, right? That very quickly could get evaluated and be like, well, all of those numbers are higher than anything we might have to pay out for the sl A, right? So maybe we don't do it now and we table it till later, you know, and that evaluation took me, you know, maybe a couple days worth of work. But once we did that, we, we had enough data to say like, ok, we don't even need to know more of a specific range because we already know that this ludicrous for us right now, but we might come back and revisit it. So how do we do that with security as well? Like, you know, oh, what's the cost of this vulnerability? Well, it's, you know, a remote access exploit. So, you know, um it could be everything right? Or it could be nothing. We can look into it more or we can spend, you know, the, the two days stop feature work and patch this thing. So, quantifying risk is a recurrent theme. Now, do you wanna jump into this? Sorry, I'll call back. Yeah. And I, I just want to say two things, I suppose I can't hear you now. There's like a ton of stan, you're breaking up super badly. I, I think we have to put you on mute unless you could change your speaker. Um While he's doing that, I can throw out a statistic that I wanted to give you, which I think Jeff you'll love right now with the current process, it takes 280 days to actually detect a breach and that's not even to react to it. And I think part of it is we keep talking about patching. How long does it take for a patch to come out? How long does it take for the issue to be found? This is all this added time that we can't really just focus on. So I thought that, you know, as you know, the Deb op side of the house or the DEV side of the house, y'all might be interested on how long it actually takes to get there. Yeah, that is a, that is a uh yeah, that is a, I can't even get my words together. I'm so kind of like about that stat. Uh oh now, cool. And, and again, we're, we're, we're living in the reality where, where breaches are fact of life, right? You have been breached, your company have been breached like it's breached right now. There's some malicious actor inside your infrastructure. You just haven't found them yet like that, that's the case for everybody um all the time. And we, and again, that actually also maybe devalues the conversation, right? Because when people realize that there's two ways you can react to it, you know, we just say like, OK, that's fine or, or like we try to fix it, which is almost undoable. And so as Jeff said, we're bad as humans at evaluating risk. So it, it's an interesting conversation. Now, do, do you want to try to speak again? Is this better? Uh Actually not, maybe your speaker is still going through the wrong, um There's a gear icon that you can click on to see. And so we're, we're kind of getting to the end of the panel, but it's been super fun. And I just, like, I really, um I've, I've really enjoyed this and uh I wish we could have in person conferences which we starting to go back to and like, actually have this conversation in person, which would be fantastic. Uh But I'm glad that technology affords us a way to like, actually do this remotely and, and um you know, keep, keep talking to each other because I think the best things that are born in conversations. Now, do you want to try again? 321. Yes, you're fine. Yes, very quickly. I just want to make the point. We've been talking a lot about economics, externalities, incentives and so on the insurance pricing model of figuring out how much it's appropriate to spend in the case of risk, et cetera actually doesn't capture like the full extent of what's going on. So you say like this thing is a million dollars, there's a 1% chance of being uh unreliable or exploited or whatever. Therefore, we spend 1% of a million dollars actually, that probably doesn't capture either the rising value of what you're doing, the long term value of the escape of the data and a whole bunch of other things. Like it's a very instantaneous kind of point of time model, which I don't think captures the holistic value. And the more I think about where the industry has to go, the more I think about holistic understandings whole life cycle understandings and how that's really the key to attacking any of these problems. The other thing I want to say is that I think reliability and security and other domains as well are very, very similar in terms of how they're approached. I mean, even on a technical basis, a lack of reliability can often be proceed into a lack of security in some sense. And I, I think that rather than accepting the fate by which we are kind of milled down into separate groups which have our own separate ways of being incentive structures, don't talk to each other. We need to aggregate ourselves in order to have any kind of realistic chance of addressing these problems. That's my soapbox. All right. So I actually, I wanted to ask everyone in the last couple of minutes that we have to, to kind of give us a parting sentence, right? So like leave us with something and advice or, you know AAA complaint or um something that people can do and can find or a book you should read like whatever it is that you fancy today. Uh So I'm going to start with Jeff oh II, I guess I would start with um Iter, right? Like we talk about a lot of things and where you are in your journey could be radically different and don't feel that you have to fast forward to the end or to the perfect state, right? Um For a lot of the things that we're talking about, these are big changes, these are big organizational changes um that are gonna take time. So don't be afraid to bite a piece off because here's the thing about progress. Um it is addictive, right? So the thing that you do today that makes life a little bit better is gonna make you hungrier to make that thing a little bit better. And then that thing a little bit better. So you could quickly go from, we have uh zero security awareness to, oh, now we have CV ES reporting but we don't have the time to fix them, but sooner or later you're gonna be all right. Now let's talk about fixing them right? Then it's gonna move to, well, how do we make sure that we just don't have them? And these fixes are happening automatically. So just starting small will sort of uh wet the appetite to get better and better and better. So if you're sort of stuck in this paralysis, just start biting something off small. And then that will be the thing that fuels that addiction and you'll continue to improve. All right, Nile, but you have to stick to one sentence because we have a minute. Read the book. Accelerate. All right. And l it's all about run time, whether it's automating and deploying, whether it's your software or whether it's malicious or, you know, unauthorized code and attack. That's exactly where you need to start, you need to start with your run time. And so my parting thoughts will be be kind to other humans and examine the incentives, right. Go and examine what people get paid on and you will find where problems come from. Um And this has been super fun. I'm super glad that we did this um very exciting. So this has been a part of Cloud Engineering summit and I lose my voice um hosted by Pulumi. And thank you so much to Jeff and El and Niall. It's been my pleasure. And again, I'm Sasha. You can find me on Twitter if you want to. Bye everybody.

---
